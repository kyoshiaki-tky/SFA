{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e922a9-0b6c-4240-b40b-e43219919418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3806e7-35eb-436c-95a5-d48a8f1fcaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ENSG</th>\n",
       "      <th>hgnc_symbol</th>\n",
       "      <th>gene_length</th>\n",
       "      <th>C_0002</th>\n",
       "      <th>C_0003</th>\n",
       "      <th>C_0004</th>\n",
       "      <th>C_0005</th>\n",
       "      <th>C_0006</th>\n",
       "      <th>C_0008</th>\n",
       "      <th>...</th>\n",
       "      <th>H_0740</th>\n",
       "      <th>H_0750</th>\n",
       "      <th>H_0513</th>\n",
       "      <th>H_0601</th>\n",
       "      <th>H_0656</th>\n",
       "      <th>H_0689</th>\n",
       "      <th>H_0709</th>\n",
       "      <th>H_0723</th>\n",
       "      <th>H_1104</th>\n",
       "      <th>H_1105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>TSPAN6</td>\n",
       "      <td>12883</td>\n",
       "      <td>2.703162</td>\n",
       "      <td>4.679815</td>\n",
       "      <td>3.827170</td>\n",
       "      <td>3.940771</td>\n",
       "      <td>3.956139</td>\n",
       "      <td>4.749555</td>\n",
       "      <td>...</td>\n",
       "      <td>4.799810</td>\n",
       "      <td>8.733498</td>\n",
       "      <td>3.666497</td>\n",
       "      <td>4.563176</td>\n",
       "      <td>2.492904</td>\n",
       "      <td>2.949728</td>\n",
       "      <td>3.314066</td>\n",
       "      <td>6.985665</td>\n",
       "      <td>3.947979</td>\n",
       "      <td>3.784485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>TNMD</td>\n",
       "      <td>14949</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.088121</td>\n",
       "      <td>0.036995</td>\n",
       "      <td>0.053272</td>\n",
       "      <td>0.108531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024476</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0.078651</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.028001</td>\n",
       "      <td>0.138079</td>\n",
       "      <td>0.031214</td>\n",
       "      <td>0.064583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>DPM1</td>\n",
       "      <td>24273</td>\n",
       "      <td>2.625862</td>\n",
       "      <td>4.387499</td>\n",
       "      <td>4.450224</td>\n",
       "      <td>5.390720</td>\n",
       "      <td>3.707350</td>\n",
       "      <td>5.356800</td>\n",
       "      <td>...</td>\n",
       "      <td>4.100151</td>\n",
       "      <td>6.470481</td>\n",
       "      <td>5.783705</td>\n",
       "      <td>6.878268</td>\n",
       "      <td>3.167153</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>6.380522</td>\n",
       "      <td>8.912018</td>\n",
       "      <td>6.420788</td>\n",
       "      <td>9.267549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>SCYL3</td>\n",
       "      <td>44636</td>\n",
       "      <td>0.896318</td>\n",
       "      <td>1.025353</td>\n",
       "      <td>1.568379</td>\n",
       "      <td>1.315815</td>\n",
       "      <td>1.617599</td>\n",
       "      <td>1.350063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610696</td>\n",
       "      <td>0.892573</td>\n",
       "      <td>1.098204</td>\n",
       "      <td>1.589228</td>\n",
       "      <td>0.708180</td>\n",
       "      <td>0.416006</td>\n",
       "      <td>0.628301</td>\n",
       "      <td>1.156094</td>\n",
       "      <td>1.317197</td>\n",
       "      <td>2.011547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>C1orf112</td>\n",
       "      <td>192073</td>\n",
       "      <td>0.033732</td>\n",
       "      <td>0.123724</td>\n",
       "      <td>0.065645</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>0.063574</td>\n",
       "      <td>0.114637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.052817</td>\n",
       "      <td>0.036344</td>\n",
       "      <td>0.091820</td>\n",
       "      <td>0.025015</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>0.060181</td>\n",
       "      <td>0.072882</td>\n",
       "      <td>0.070371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21858</th>\n",
       "      <td>26560</td>\n",
       "      <td>ENSG00000273372</td>\n",
       "      <td>SFTPD-AS1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.680299</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>0.715117</td>\n",
       "      <td>1.061834</td>\n",
       "      <td>1.061811</td>\n",
       "      <td>1.437003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311009</td>\n",
       "      <td>0.202893</td>\n",
       "      <td>0.201662</td>\n",
       "      <td>1.018982</td>\n",
       "      <td>0.050577</td>\n",
       "      <td>0.647750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247696</td>\n",
       "      <td>0.559947</td>\n",
       "      <td>0.096546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21859</th>\n",
       "      <td>26565</td>\n",
       "      <td>ENSG00000273396</td>\n",
       "      <td>LINC01396</td>\n",
       "      <td>6639</td>\n",
       "      <td>0.036596</td>\n",
       "      <td>0.066286</td>\n",
       "      <td>0.226767</td>\n",
       "      <td>0.049981</td>\n",
       "      <td>0.119952</td>\n",
       "      <td>0.139644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>0.027783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21860</th>\n",
       "      <td>26570</td>\n",
       "      <td>ENSG00000273409</td>\n",
       "      <td>LINC02712</td>\n",
       "      <td>66004</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.068428</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.036196</td>\n",
       "      <td>0.017558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>0.054055</td>\n",
       "      <td>0.065315</td>\n",
       "      <td>0.015325</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.028278</td>\n",
       "      <td>0.058509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861</th>\n",
       "      <td>26571</td>\n",
       "      <td>ENSG00000273415</td>\n",
       "      <td>LINC02725</td>\n",
       "      <td>87913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21862</th>\n",
       "      <td>26591</td>\n",
       "      <td>ENSG00000273492</td>\n",
       "      <td>APP-DT</td>\n",
       "      <td>46510</td>\n",
       "      <td>0.417913</td>\n",
       "      <td>0.416324</td>\n",
       "      <td>0.716177</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>0.388106</td>\n",
       "      <td>0.294017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709995</td>\n",
       "      <td>0.362869</td>\n",
       "      <td>0.411909</td>\n",
       "      <td>0.564575</td>\n",
       "      <td>0.402350</td>\n",
       "      <td>0.102132</td>\n",
       "      <td>0.890978</td>\n",
       "      <td>0.781096</td>\n",
       "      <td>0.642094</td>\n",
       "      <td>0.332128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21863 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             ENSG hgnc_symbol  gene_length    C_0002  \\\n",
       "0               1  ENSG00000000003      TSPAN6        12883  2.703162   \n",
       "1               2  ENSG00000000005        TNMD        14949  0.005418   \n",
       "2               3  ENSG00000000419        DPM1        24273  2.625862   \n",
       "3               4  ENSG00000000457       SCYL3        44636  0.896318   \n",
       "4               5  ENSG00000000460    C1orf112       192073  0.033732   \n",
       "...           ...              ...         ...          ...       ...   \n",
       "21858       26560  ENSG00000273372   SFTPD-AS1         5000  0.680299   \n",
       "21859       26565  ENSG00000273396   LINC01396         6639  0.036596   \n",
       "21860       26570  ENSG00000273409   LINC02712        66004  0.019632   \n",
       "21861       26571  ENSG00000273415   LINC02725        87913  0.000000   \n",
       "21862       26591  ENSG00000273492      APP-DT        46510  0.417913   \n",
       "\n",
       "         C_0003    C_0004    C_0005    C_0006    C_0008  ...    H_0740  \\\n",
       "0      4.679815  3.827170  3.940771  3.956139  4.749555  ...  4.799810   \n",
       "1      0.029438  0.088121  0.036995  0.053272  0.108531  ...  0.024476   \n",
       "2      4.387499  4.450224  5.390720  3.707350  5.356800  ...  4.100151   \n",
       "3      1.025353  1.568379  1.315815  1.617599  1.350063  ...  0.610696   \n",
       "4      0.123724  0.065645  0.074862  0.063574  0.114637  ...  0.030003   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "21858  0.616103  0.715117  1.061834  1.061811  1.437003  ...  0.311009   \n",
       "21859  0.066286  0.226767  0.049981  0.119952  0.139644  ...  0.013778   \n",
       "21860  0.040004  0.068428  0.016758  0.036196  0.017558  ...  0.005544   \n",
       "21861  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "21862  0.416324  0.716177  0.516058  0.388106  0.294017  ...  0.709995   \n",
       "\n",
       "         H_0750    H_0513    H_0601    H_0656    H_0689    H_0709    H_0723  \\\n",
       "0      8.733498  3.666497  4.563176  2.492904  2.949728  3.314066  6.985665   \n",
       "1      0.086370  0.083015  0.078651  0.050749  0.014444  0.028001  0.138079   \n",
       "2      6.470481  5.783705  6.878268  3.167153  1.530000  6.380522  8.912018   \n",
       "3      0.892573  1.098204  1.589228  0.708180  0.416006  0.628301  1.156094   \n",
       "4      0.052817  0.036344  0.091820  0.025015  0.042717  0.034868  0.060181   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21858  0.202893  0.201662  1.018982  0.050577  0.647750  0.000000  0.247696   \n",
       "21859  0.027783  0.000000  0.000000  0.038090  0.000000  0.000000  0.000000   \n",
       "21860  0.027945  0.054055  0.065315  0.015325  0.009814  0.000000  0.012509   \n",
       "21861  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "21862  0.362869  0.411909  0.564575  0.402350  0.102132  0.890978  0.781096   \n",
       "\n",
       "         H_1104    H_1105  \n",
       "0      3.947979  3.784485  \n",
       "1      0.031214  0.064583  \n",
       "2      6.420788  9.267549  \n",
       "3      1.317197  2.011547  \n",
       "4      0.072882  0.070371  \n",
       "...         ...       ...  \n",
       "21858  0.559947  0.096546  \n",
       "21859  0.000000  0.000000  \n",
       "21860  0.028278  0.058509  \n",
       "21861  0.000000  0.000000  \n",
       "21862  0.642094  0.332128  \n",
       "\n",
       "[21863 rows x 112 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"tpm_data.csv\", header=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1736a8-e834-4b25-957e-5d42f8dc3ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.621517048846005e-05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX_pre=data.iloc[:,4:]\n",
    "dataX=dataX_pre.T\n",
    "dataX_min=np.min(dataX.values[dataX.values>0])\n",
    "dataX_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9668ea1b-bcd8-448e-abbf-0fe151393b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 0 into minimized number which cannot affect analysis\n",
    "dataX[dataX==0]=8.621517048846005e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a93e66-5463-4d18-8337-d0fd83828de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX_copy=dataX.copy()\n",
    "dataX_copy_log=dataX_copy.apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7dcc867-484f-4b07-ad5c-db8d78f32af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0002</th>\n",
       "      <td>2.703162</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>2.625862</td>\n",
       "      <td>0.896318</td>\n",
       "      <td>0.033732</td>\n",
       "      <td>1.520210</td>\n",
       "      <td>0.668186</td>\n",
       "      <td>2.390171</td>\n",
       "      <td>1.079804</td>\n",
       "      <td>1.846578</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024701</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>12.989309</td>\n",
       "      <td>2.596021</td>\n",
       "      <td>0.680299</td>\n",
       "      <td>0.036596</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.417913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0003</th>\n",
       "      <td>4.679815</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>4.387499</td>\n",
       "      <td>1.025353</td>\n",
       "      <td>0.123724</td>\n",
       "      <td>2.417254</td>\n",
       "      <td>0.541779</td>\n",
       "      <td>6.715102</td>\n",
       "      <td>2.762668</td>\n",
       "      <td>5.757188</td>\n",
       "      <td>...</td>\n",
       "      <td>3.380591</td>\n",
       "      <td>0.400795</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>42.426011</td>\n",
       "      <td>2.992243</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>0.066286</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.416324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0004</th>\n",
       "      <td>3.827170</td>\n",
       "      <td>0.088121</td>\n",
       "      <td>4.450224</td>\n",
       "      <td>1.568379</td>\n",
       "      <td>0.065645</td>\n",
       "      <td>1.855760</td>\n",
       "      <td>0.840779</td>\n",
       "      <td>4.118158</td>\n",
       "      <td>1.709962</td>\n",
       "      <td>3.075835</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955870</td>\n",
       "      <td>0.171392</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>24.410100</td>\n",
       "      <td>2.010758</td>\n",
       "      <td>0.715117</td>\n",
       "      <td>0.226767</td>\n",
       "      <td>0.068428</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.716177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0005</th>\n",
       "      <td>3.940771</td>\n",
       "      <td>0.036995</td>\n",
       "      <td>5.390720</td>\n",
       "      <td>1.315815</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>1.803517</td>\n",
       "      <td>1.254086</td>\n",
       "      <td>5.239934</td>\n",
       "      <td>2.649874</td>\n",
       "      <td>4.998753</td>\n",
       "      <td>...</td>\n",
       "      <td>3.698587</td>\n",
       "      <td>0.201471</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>24.525642</td>\n",
       "      <td>3.975217</td>\n",
       "      <td>1.061834</td>\n",
       "      <td>0.049981</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.516058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0006</th>\n",
       "      <td>3.956139</td>\n",
       "      <td>0.053272</td>\n",
       "      <td>3.707350</td>\n",
       "      <td>1.617599</td>\n",
       "      <td>0.063574</td>\n",
       "      <td>1.354761</td>\n",
       "      <td>0.569268</td>\n",
       "      <td>4.474453</td>\n",
       "      <td>2.367638</td>\n",
       "      <td>4.753598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719709</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>33.152522</td>\n",
       "      <td>1.418155</td>\n",
       "      <td>1.061811</td>\n",
       "      <td>0.119952</td>\n",
       "      <td>0.036196</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.388106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0689</th>\n",
       "      <td>2.949728</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>0.416006</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>4.108964</td>\n",
       "      <td>1.871441</td>\n",
       "      <td>2.094295</td>\n",
       "      <td>0.747223</td>\n",
       "      <td>2.215735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487837</td>\n",
       "      <td>0.196645</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>9.461733</td>\n",
       "      <td>2.411892</td>\n",
       "      <td>0.647750</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.102132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0709</th>\n",
       "      <td>3.314066</td>\n",
       "      <td>0.028001</td>\n",
       "      <td>6.380522</td>\n",
       "      <td>0.628301</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>1.158647</td>\n",
       "      <td>0.860249</td>\n",
       "      <td>3.787714</td>\n",
       "      <td>1.060191</td>\n",
       "      <td>1.706804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945729</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>31.182523</td>\n",
       "      <td>3.252682</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.890978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0723</th>\n",
       "      <td>6.985665</td>\n",
       "      <td>0.138079</td>\n",
       "      <td>8.912018</td>\n",
       "      <td>1.156094</td>\n",
       "      <td>0.060181</td>\n",
       "      <td>1.946203</td>\n",
       "      <td>1.799320</td>\n",
       "      <td>4.370479</td>\n",
       "      <td>1.842778</td>\n",
       "      <td>3.689338</td>\n",
       "      <td>...</td>\n",
       "      <td>2.425103</td>\n",
       "      <td>1.503924</td>\n",
       "      <td>0.018520</td>\n",
       "      <td>57.708965</td>\n",
       "      <td>6.215465</td>\n",
       "      <td>0.247696</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.781096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1104</th>\n",
       "      <td>3.947979</td>\n",
       "      <td>0.031214</td>\n",
       "      <td>6.420788</td>\n",
       "      <td>1.317197</td>\n",
       "      <td>0.072882</td>\n",
       "      <td>2.361264</td>\n",
       "      <td>1.357402</td>\n",
       "      <td>3.256530</td>\n",
       "      <td>1.497821</td>\n",
       "      <td>3.361442</td>\n",
       "      <td>...</td>\n",
       "      <td>2.319405</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>24.742013</td>\n",
       "      <td>3.172758</td>\n",
       "      <td>0.559947</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.028278</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.642094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1105</th>\n",
       "      <td>3.784485</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>9.267549</td>\n",
       "      <td>2.011547</td>\n",
       "      <td>0.070371</td>\n",
       "      <td>3.758100</td>\n",
       "      <td>0.637426</td>\n",
       "      <td>7.137567</td>\n",
       "      <td>1.807773</td>\n",
       "      <td>3.100193</td>\n",
       "      <td>...</td>\n",
       "      <td>5.671453</td>\n",
       "      <td>0.439643</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>57.538120</td>\n",
       "      <td>5.157850</td>\n",
       "      <td>0.096546</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.058509</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.332128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 21862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "C_0002  2.703162  0.005418  2.625862  0.896318  0.033732  1.520210  0.668186   \n",
       "C_0003  4.679815  0.029438  4.387499  1.025353  0.123724  2.417254  0.541779   \n",
       "C_0004  3.827170  0.088121  4.450224  1.568379  0.065645  1.855760  0.840779   \n",
       "C_0005  3.940771  0.036995  5.390720  1.315815  0.074862  1.803517  1.254086   \n",
       "C_0006  3.956139  0.053272  3.707350  1.617599  0.063574  1.354761  0.569268   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "H_0689  2.949728  0.014444  1.530000  0.416006  0.042717  4.108964  1.871441   \n",
       "H_0709  3.314066  0.028001  6.380522  0.628301  0.034868  1.158647  0.860249   \n",
       "H_0723  6.985665  0.138079  8.912018  1.156094  0.060181  1.946203  1.799320   \n",
       "H_1104  3.947979  0.031214  6.420788  1.317197  0.072882  2.361264  1.357402   \n",
       "H_1105  3.784485  0.064583  9.267549  2.011547  0.070371  3.758100  0.637426   \n",
       "\n",
       "           7         8         9      ...     21853     21854     21855  \\\n",
       "C_0002  2.390171  1.079804  1.846578  ...  1.024701  0.000009  0.007266   \n",
       "C_0003  6.715102  2.762668  5.757188  ...  3.380591  0.400795  0.000009   \n",
       "C_0004  4.118158  1.709962  3.075835  ...  1.955870  0.171392  0.008442   \n",
       "C_0005  5.239934  2.649874  4.998753  ...  3.698587  0.201471  0.000009   \n",
       "C_0006  4.474453  2.367638  4.753598  ...  0.719709  0.000009  0.000009   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "H_0689  2.094295  0.747223  2.215735  ...  0.487837  0.196645  0.009686   \n",
       "H_0709  3.787714  1.060191  1.706804  ...  0.945729  0.000009  0.000009   \n",
       "H_0723  4.370479  1.842778  3.689338  ...  2.425103  1.503924  0.018520   \n",
       "H_1104  3.256530  1.497821  3.361442  ...  2.319405  0.000009  0.000009   \n",
       "H_1105  7.137567  1.807773  3.100193  ...  5.671453  0.439643  0.021656   \n",
       "\n",
       "            21856     21857     21858     21859     21860     21861     21862  \n",
       "C_0002  12.989309  2.596021  0.680299  0.036596  0.019632  0.000009  0.417913  \n",
       "C_0003  42.426011  2.992243  0.616103  0.066286  0.040004  0.000009  0.416324  \n",
       "C_0004  24.410100  2.010758  0.715117  0.226767  0.068428  0.000009  0.716177  \n",
       "C_0005  24.525642  3.975217  1.061834  0.049981  0.016758  0.000009  0.516058  \n",
       "C_0006  33.152522  1.418155  1.061811  0.119952  0.036196  0.000009  0.388106  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "H_0689   9.461733  2.411892  0.647750  0.000009  0.009814  0.000009  0.102132  \n",
       "H_0709  31.182523  3.252682  0.000009  0.000009  0.000009  0.000009  0.890978  \n",
       "H_0723  57.708965  6.215465  0.247696  0.000009  0.012509  0.000009  0.781096  \n",
       "H_1104  24.742013  3.172758  0.559947  0.000009  0.028278  0.000009  0.642094  \n",
       "H_1105  57.538120  5.157850  0.096546  0.000009  0.058509  0.000009  0.332128  \n",
       "\n",
       "[108 rows x 21862 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete a column which has a smallest std (deleting LINC02694)\n",
    "dataX_after_del=dataX_copy.drop(dataX_copy.columns[13609],axis=1)\n",
    "dataX_after_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cedb01a-45f4-4af5-889e-5307f2081f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0002</th>\n",
       "      <td>2.703162</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>2.625862</td>\n",
       "      <td>0.896318</td>\n",
       "      <td>0.033732</td>\n",
       "      <td>1.520210</td>\n",
       "      <td>0.668186</td>\n",
       "      <td>2.390171</td>\n",
       "      <td>1.079804</td>\n",
       "      <td>1.846578</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024701</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>12.989309</td>\n",
       "      <td>2.596021</td>\n",
       "      <td>0.680299</td>\n",
       "      <td>0.036596</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.417913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0003</th>\n",
       "      <td>4.679815</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>4.387499</td>\n",
       "      <td>1.025353</td>\n",
       "      <td>0.123724</td>\n",
       "      <td>2.417254</td>\n",
       "      <td>0.541779</td>\n",
       "      <td>6.715102</td>\n",
       "      <td>2.762668</td>\n",
       "      <td>5.757188</td>\n",
       "      <td>...</td>\n",
       "      <td>3.380591</td>\n",
       "      <td>0.400795</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>42.426011</td>\n",
       "      <td>2.992243</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>0.066286</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.416324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0004</th>\n",
       "      <td>3.827170</td>\n",
       "      <td>0.088121</td>\n",
       "      <td>4.450224</td>\n",
       "      <td>1.568379</td>\n",
       "      <td>0.065645</td>\n",
       "      <td>1.855760</td>\n",
       "      <td>0.840779</td>\n",
       "      <td>4.118158</td>\n",
       "      <td>1.709962</td>\n",
       "      <td>3.075835</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955870</td>\n",
       "      <td>0.171392</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>24.410100</td>\n",
       "      <td>2.010758</td>\n",
       "      <td>0.715117</td>\n",
       "      <td>0.226767</td>\n",
       "      <td>0.068428</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.716177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0005</th>\n",
       "      <td>3.940771</td>\n",
       "      <td>0.036995</td>\n",
       "      <td>5.390720</td>\n",
       "      <td>1.315815</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>1.803517</td>\n",
       "      <td>1.254086</td>\n",
       "      <td>5.239934</td>\n",
       "      <td>2.649874</td>\n",
       "      <td>4.998753</td>\n",
       "      <td>...</td>\n",
       "      <td>3.698587</td>\n",
       "      <td>0.201471</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>24.525642</td>\n",
       "      <td>3.975217</td>\n",
       "      <td>1.061834</td>\n",
       "      <td>0.049981</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.516058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0006</th>\n",
       "      <td>3.956139</td>\n",
       "      <td>0.053272</td>\n",
       "      <td>3.707350</td>\n",
       "      <td>1.617599</td>\n",
       "      <td>0.063574</td>\n",
       "      <td>1.354761</td>\n",
       "      <td>0.569268</td>\n",
       "      <td>4.474453</td>\n",
       "      <td>2.367638</td>\n",
       "      <td>4.753598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719709</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>33.152522</td>\n",
       "      <td>1.418155</td>\n",
       "      <td>1.061811</td>\n",
       "      <td>0.119952</td>\n",
       "      <td>0.036196</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.388106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0689</th>\n",
       "      <td>2.949728</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>0.416006</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>4.108964</td>\n",
       "      <td>1.871441</td>\n",
       "      <td>2.094295</td>\n",
       "      <td>0.747223</td>\n",
       "      <td>2.215735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487837</td>\n",
       "      <td>0.196645</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>9.461733</td>\n",
       "      <td>2.411892</td>\n",
       "      <td>0.647750</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.102132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0709</th>\n",
       "      <td>3.314066</td>\n",
       "      <td>0.028001</td>\n",
       "      <td>6.380522</td>\n",
       "      <td>0.628301</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>1.158647</td>\n",
       "      <td>0.860249</td>\n",
       "      <td>3.787714</td>\n",
       "      <td>1.060191</td>\n",
       "      <td>1.706804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945729</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>31.182523</td>\n",
       "      <td>3.252682</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.890978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0723</th>\n",
       "      <td>6.985665</td>\n",
       "      <td>0.138079</td>\n",
       "      <td>8.912018</td>\n",
       "      <td>1.156094</td>\n",
       "      <td>0.060181</td>\n",
       "      <td>1.946203</td>\n",
       "      <td>1.799320</td>\n",
       "      <td>4.370479</td>\n",
       "      <td>1.842778</td>\n",
       "      <td>3.689338</td>\n",
       "      <td>...</td>\n",
       "      <td>2.425103</td>\n",
       "      <td>1.503924</td>\n",
       "      <td>0.018520</td>\n",
       "      <td>57.708965</td>\n",
       "      <td>6.215465</td>\n",
       "      <td>0.247696</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.781096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1104</th>\n",
       "      <td>3.947979</td>\n",
       "      <td>0.031214</td>\n",
       "      <td>6.420788</td>\n",
       "      <td>1.317197</td>\n",
       "      <td>0.072882</td>\n",
       "      <td>2.361264</td>\n",
       "      <td>1.357402</td>\n",
       "      <td>3.256530</td>\n",
       "      <td>1.497821</td>\n",
       "      <td>3.361442</td>\n",
       "      <td>...</td>\n",
       "      <td>2.319405</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>24.742013</td>\n",
       "      <td>3.172758</td>\n",
       "      <td>0.559947</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.028278</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.642094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1105</th>\n",
       "      <td>3.784485</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>9.267549</td>\n",
       "      <td>2.011547</td>\n",
       "      <td>0.070371</td>\n",
       "      <td>3.758100</td>\n",
       "      <td>0.637426</td>\n",
       "      <td>7.137567</td>\n",
       "      <td>1.807773</td>\n",
       "      <td>3.100193</td>\n",
       "      <td>...</td>\n",
       "      <td>5.671453</td>\n",
       "      <td>0.439643</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>57.538120</td>\n",
       "      <td>5.157850</td>\n",
       "      <td>0.096546</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.058509</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.332128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 21861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "C_0002  2.703162  0.005418  2.625862  0.896318  0.033732  1.520210  0.668186   \n",
       "C_0003  4.679815  0.029438  4.387499  1.025353  0.123724  2.417254  0.541779   \n",
       "C_0004  3.827170  0.088121  4.450224  1.568379  0.065645  1.855760  0.840779   \n",
       "C_0005  3.940771  0.036995  5.390720  1.315815  0.074862  1.803517  1.254086   \n",
       "C_0006  3.956139  0.053272  3.707350  1.617599  0.063574  1.354761  0.569268   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "H_0689  2.949728  0.014444  1.530000  0.416006  0.042717  4.108964  1.871441   \n",
       "H_0709  3.314066  0.028001  6.380522  0.628301  0.034868  1.158647  0.860249   \n",
       "H_0723  6.985665  0.138079  8.912018  1.156094  0.060181  1.946203  1.799320   \n",
       "H_1104  3.947979  0.031214  6.420788  1.317197  0.072882  2.361264  1.357402   \n",
       "H_1105  3.784485  0.064583  9.267549  2.011547  0.070371  3.758100  0.637426   \n",
       "\n",
       "           7         8         9      ...     21853     21854     21855  \\\n",
       "C_0002  2.390171  1.079804  1.846578  ...  1.024701  0.000009  0.007266   \n",
       "C_0003  6.715102  2.762668  5.757188  ...  3.380591  0.400795  0.000009   \n",
       "C_0004  4.118158  1.709962  3.075835  ...  1.955870  0.171392  0.008442   \n",
       "C_0005  5.239934  2.649874  4.998753  ...  3.698587  0.201471  0.000009   \n",
       "C_0006  4.474453  2.367638  4.753598  ...  0.719709  0.000009  0.000009   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "H_0689  2.094295  0.747223  2.215735  ...  0.487837  0.196645  0.009686   \n",
       "H_0709  3.787714  1.060191  1.706804  ...  0.945729  0.000009  0.000009   \n",
       "H_0723  4.370479  1.842778  3.689338  ...  2.425103  1.503924  0.018520   \n",
       "H_1104  3.256530  1.497821  3.361442  ...  2.319405  0.000009  0.000009   \n",
       "H_1105  7.137567  1.807773  3.100193  ...  5.671453  0.439643  0.021656   \n",
       "\n",
       "            21856     21857     21858     21859     21860     21861     21862  \n",
       "C_0002  12.989309  2.596021  0.680299  0.036596  0.019632  0.000009  0.417913  \n",
       "C_0003  42.426011  2.992243  0.616103  0.066286  0.040004  0.000009  0.416324  \n",
       "C_0004  24.410100  2.010758  0.715117  0.226767  0.068428  0.000009  0.716177  \n",
       "C_0005  24.525642  3.975217  1.061834  0.049981  0.016758  0.000009  0.516058  \n",
       "C_0006  33.152522  1.418155  1.061811  0.119952  0.036196  0.000009  0.388106  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "H_0689   9.461733  2.411892  0.647750  0.000009  0.009814  0.000009  0.102132  \n",
       "H_0709  31.182523  3.252682  0.000009  0.000009  0.000009  0.000009  0.890978  \n",
       "H_0723  57.708965  6.215465  0.247696  0.000009  0.012509  0.000009  0.781096  \n",
       "H_1104  24.742013  3.172758  0.559947  0.000009  0.028278  0.000009  0.642094  \n",
       "H_1105  57.538120  5.157850  0.096546  0.000009  0.058509  0.000009  0.332128  \n",
       "\n",
       "[108 rows x 21861 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete a column which has a smallest std\n",
    "dataX_after_del2=dataX_after_del.drop(dataX_copy.columns[19081],axis=1)\n",
    "dataX_after_del2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081f04fb-e229-491f-b774-cd4afad19c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0002</th>\n",
       "      <td>0.994422</td>\n",
       "      <td>-5.218099</td>\n",
       "      <td>0.965409</td>\n",
       "      <td>-0.109460</td>\n",
       "      <td>-3.389303</td>\n",
       "      <td>0.418849</td>\n",
       "      <td>-0.403189</td>\n",
       "      <td>0.871365</td>\n",
       "      <td>0.076779</td>\n",
       "      <td>0.613334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024401</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-4.924490</td>\n",
       "      <td>2.564127</td>\n",
       "      <td>0.953980</td>\n",
       "      <td>-0.385223</td>\n",
       "      <td>-3.307803</td>\n",
       "      <td>-3.930581</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-0.872483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0003</th>\n",
       "      <td>1.543259</td>\n",
       "      <td>-3.525458</td>\n",
       "      <td>1.478759</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>-2.089705</td>\n",
       "      <td>0.882632</td>\n",
       "      <td>-0.612896</td>\n",
       "      <td>1.904359</td>\n",
       "      <td>1.016197</td>\n",
       "      <td>1.750449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.218051</td>\n",
       "      <td>-0.914304</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>3.747762</td>\n",
       "      <td>1.096023</td>\n",
       "      <td>-0.484341</td>\n",
       "      <td>-2.713775</td>\n",
       "      <td>-3.218770</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-0.876291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0004</th>\n",
       "      <td>1.342126</td>\n",
       "      <td>-2.429044</td>\n",
       "      <td>1.492955</td>\n",
       "      <td>0.450043</td>\n",
       "      <td>-2.723493</td>\n",
       "      <td>0.618294</td>\n",
       "      <td>-0.173427</td>\n",
       "      <td>1.415406</td>\n",
       "      <td>0.536471</td>\n",
       "      <td>1.123576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670835</td>\n",
       "      <td>-1.763801</td>\n",
       "      <td>-4.774493</td>\n",
       "      <td>3.194997</td>\n",
       "      <td>0.698512</td>\n",
       "      <td>-0.335309</td>\n",
       "      <td>-1.483830</td>\n",
       "      <td>-2.681972</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-0.333828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0005</th>\n",
       "      <td>1.371376</td>\n",
       "      <td>-3.296972</td>\n",
       "      <td>1.684679</td>\n",
       "      <td>0.274456</td>\n",
       "      <td>-2.592106</td>\n",
       "      <td>0.589739</td>\n",
       "      <td>0.226407</td>\n",
       "      <td>1.656309</td>\n",
       "      <td>0.974512</td>\n",
       "      <td>1.609188</td>\n",
       "      <td>...</td>\n",
       "      <td>1.307951</td>\n",
       "      <td>-1.602108</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>3.199719</td>\n",
       "      <td>1.380079</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>-2.996114</td>\n",
       "      <td>-4.088895</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-0.661535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0006</th>\n",
       "      <td>1.375269</td>\n",
       "      <td>-2.932350</td>\n",
       "      <td>1.310317</td>\n",
       "      <td>0.480943</td>\n",
       "      <td>-2.755552</td>\n",
       "      <td>0.303625</td>\n",
       "      <td>-0.563404</td>\n",
       "      <td>1.498384</td>\n",
       "      <td>0.861893</td>\n",
       "      <td>1.558902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328908</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>3.501119</td>\n",
       "      <td>0.349357</td>\n",
       "      <td>0.059976</td>\n",
       "      <td>-2.120667</td>\n",
       "      <td>-3.318809</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-0.946478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0689</th>\n",
       "      <td>1.081713</td>\n",
       "      <td>-4.237507</td>\n",
       "      <td>0.425267</td>\n",
       "      <td>-0.877056</td>\n",
       "      <td>-3.153152</td>\n",
       "      <td>1.413171</td>\n",
       "      <td>0.626709</td>\n",
       "      <td>0.739217</td>\n",
       "      <td>-0.291392</td>\n",
       "      <td>0.795584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.717774</td>\n",
       "      <td>-1.626353</td>\n",
       "      <td>-4.637045</td>\n",
       "      <td>2.247256</td>\n",
       "      <td>0.880411</td>\n",
       "      <td>-0.434250</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-4.623965</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-2.281487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0709</th>\n",
       "      <td>1.198176</td>\n",
       "      <td>-3.575533</td>\n",
       "      <td>1.853250</td>\n",
       "      <td>-0.464737</td>\n",
       "      <td>-3.356175</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>-0.150534</td>\n",
       "      <td>1.331763</td>\n",
       "      <td>0.058449</td>\n",
       "      <td>0.534623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055800</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>3.439858</td>\n",
       "      <td>1.179480</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-0.115436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0723</th>\n",
       "      <td>1.943860</td>\n",
       "      <td>-1.979933</td>\n",
       "      <td>2.187401</td>\n",
       "      <td>0.145047</td>\n",
       "      <td>-2.810397</td>\n",
       "      <td>0.665880</td>\n",
       "      <td>0.587409</td>\n",
       "      <td>1.474873</td>\n",
       "      <td>0.611274</td>\n",
       "      <td>1.305447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885874</td>\n",
       "      <td>0.408078</td>\n",
       "      <td>-3.988909</td>\n",
       "      <td>4.055413</td>\n",
       "      <td>1.827040</td>\n",
       "      <td>-1.395552</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-4.381294</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-0.247057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1104</th>\n",
       "      <td>1.373204</td>\n",
       "      <td>-3.466880</td>\n",
       "      <td>1.859541</td>\n",
       "      <td>0.275506</td>\n",
       "      <td>-2.618914</td>\n",
       "      <td>0.859197</td>\n",
       "      <td>0.305573</td>\n",
       "      <td>1.180662</td>\n",
       "      <td>0.404012</td>\n",
       "      <td>1.212370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841311</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>3.208503</td>\n",
       "      <td>1.154601</td>\n",
       "      <td>-0.579914</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-3.565657</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-0.443020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1105</th>\n",
       "      <td>1.330910</td>\n",
       "      <td>-2.739799</td>\n",
       "      <td>2.226519</td>\n",
       "      <td>0.698904</td>\n",
       "      <td>-2.653973</td>\n",
       "      <td>1.323913</td>\n",
       "      <td>-0.450317</td>\n",
       "      <td>1.965372</td>\n",
       "      <td>0.592096</td>\n",
       "      <td>1.131464</td>\n",
       "      <td>...</td>\n",
       "      <td>1.735445</td>\n",
       "      <td>-0.821792</td>\n",
       "      <td>-3.832485</td>\n",
       "      <td>4.052448</td>\n",
       "      <td>1.640520</td>\n",
       "      <td>-2.337740</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-2.838576</td>\n",
       "      <td>-11.661249</td>\n",
       "      <td>-1.102234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 21861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "C_0002  0.994422 -5.218099  0.965409 -0.109460 -3.389303  0.418849 -0.403189   \n",
       "C_0003  1.543259 -3.525458  1.478759  0.025037 -2.089705  0.882632 -0.612896   \n",
       "C_0004  1.342126 -2.429044  1.492955  0.450043 -2.723493  0.618294 -0.173427   \n",
       "C_0005  1.371376 -3.296972  1.684679  0.274456 -2.592106  0.589739  0.226407   \n",
       "C_0006  1.375269 -2.932350  1.310317  0.480943 -2.755552  0.303625 -0.563404   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "H_0689  1.081713 -4.237507  0.425267 -0.877056 -3.153152  1.413171  0.626709   \n",
       "H_0709  1.198176 -3.575533  1.853250 -0.464737 -3.356175  0.147253 -0.150534   \n",
       "H_0723  1.943860 -1.979933  2.187401  0.145047 -2.810397  0.665880  0.587409   \n",
       "H_1104  1.373204 -3.466880  1.859541  0.275506 -2.618914  0.859197  0.305573   \n",
       "H_1105  1.330910 -2.739799  2.226519  0.698904 -2.653973  1.323913 -0.450317   \n",
       "\n",
       "           7         8         9      ...     21853      21854      21855  \\\n",
       "C_0002  0.871365  0.076779  0.613334  ...  0.024401 -11.661249  -4.924490   \n",
       "C_0003  1.904359  1.016197  1.750449  ...  1.218051  -0.914304 -11.661249   \n",
       "C_0004  1.415406  0.536471  1.123576  ...  0.670835  -1.763801  -4.774493   \n",
       "C_0005  1.656309  0.974512  1.609188  ...  1.307951  -1.602108 -11.661249   \n",
       "C_0006  1.498384  0.861893  1.558902  ... -0.328908 -11.661249 -11.661249   \n",
       "...          ...       ...       ...  ...       ...        ...        ...   \n",
       "H_0689  0.739217 -0.291392  0.795584  ... -0.717774  -1.626353  -4.637045   \n",
       "H_0709  1.331763  0.058449  0.534623  ... -0.055800 -11.661249 -11.661249   \n",
       "H_0723  1.474873  0.611274  1.305447  ...  0.885874   0.408078  -3.988909   \n",
       "H_1104  1.180662  0.404012  1.212370  ...  0.841311 -11.661249 -11.661249   \n",
       "H_1105  1.965372  0.592096  1.131464  ...  1.735445  -0.821792  -3.832485   \n",
       "\n",
       "           21856     21857      21858      21859      21860      21861  \\\n",
       "C_0002  2.564127  0.953980  -0.385223  -3.307803  -3.930581 -11.661249   \n",
       "C_0003  3.747762  1.096023  -0.484341  -2.713775  -3.218770 -11.661249   \n",
       "C_0004  3.194997  0.698512  -0.335309  -1.483830  -2.681972 -11.661249   \n",
       "C_0005  3.199719  1.380079   0.059998  -2.996114  -4.088895 -11.661249   \n",
       "C_0006  3.501119  0.349357   0.059976  -2.120667  -3.318809 -11.661249   \n",
       "...          ...       ...        ...        ...        ...        ...   \n",
       "H_0689  2.247256  0.880411  -0.434250 -11.661249  -4.623965 -11.661249   \n",
       "H_0709  3.439858  1.179480 -11.661249 -11.661249 -11.661249 -11.661249   \n",
       "H_0723  4.055413  1.827040  -1.395552 -11.661249  -4.381294 -11.661249   \n",
       "H_1104  3.208503  1.154601  -0.579914 -11.661249  -3.565657 -11.661249   \n",
       "H_1105  4.052448  1.640520  -2.337740 -11.661249  -2.838576 -11.661249   \n",
       "\n",
       "           21862  \n",
       "C_0002 -0.872483  \n",
       "C_0003 -0.876291  \n",
       "C_0004 -0.333828  \n",
       "C_0005 -0.661535  \n",
       "C_0006 -0.946478  \n",
       "...          ...  \n",
       "H_0689 -2.281487  \n",
       "H_0709 -0.115436  \n",
       "H_0723 -0.247057  \n",
       "H_1104 -0.443020  \n",
       "H_1105 -1.102234  \n",
       "\n",
       "[108 rows x 21861 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log conversion of Dataframe\n",
    "dataX_log_del2=dataX_after_del2.apply(np.log)\n",
    "dataX_log_del2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49ea5a8-1d44-473c-8659-c8caff87571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresToScale=dataX_log_del2.columns\n",
    "sX=pp.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "dataX_log_del2.loc[:, featuresToScale]=sX.fit_transform(dataX_log_del2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e4a87f3-bb18-4037-a317-e8fc7e0c36b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0002</th>\n",
       "      <td>-1.238669</td>\n",
       "      <td>-0.489755</td>\n",
       "      <td>-1.404819</td>\n",
       "      <td>-0.661768</td>\n",
       "      <td>-1.214104</td>\n",
       "      <td>-0.438326</td>\n",
       "      <td>-0.542205</td>\n",
       "      <td>-1.549951</td>\n",
       "      <td>-1.144974</td>\n",
       "      <td>-1.361823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.794664</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.737597</td>\n",
       "      <td>-1.819190</td>\n",
       "      <td>-0.178338</td>\n",
       "      <td>0.264969</td>\n",
       "      <td>0.721004</td>\n",
       "      <td>-0.094753</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.142859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0003</th>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.128294</td>\n",
       "      <td>-0.400562</td>\n",
       "      <td>-0.392906</td>\n",
       "      <td>0.908731</td>\n",
       "      <td>0.454217</td>\n",
       "      <td>-0.792399</td>\n",
       "      <td>0.733360</td>\n",
       "      <td>0.611638</td>\n",
       "      <td>0.953743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>0.814752</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.719449</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.220818</td>\n",
       "      <td>0.859050</td>\n",
       "      <td>0.298774</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.149023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0004</th>\n",
       "      <td>-0.513695</td>\n",
       "      <td>0.528638</td>\n",
       "      <td>-0.372793</td>\n",
       "      <td>0.456696</td>\n",
       "      <td>-0.126533</td>\n",
       "      <td>-0.054497</td>\n",
       "      <td>-0.268084</td>\n",
       "      <td>-0.347413</td>\n",
       "      <td>-0.285398</td>\n",
       "      <td>-0.322790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051075</td>\n",
       "      <td>0.649930</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>-0.466111</td>\n",
       "      <td>-0.596202</td>\n",
       "      <td>0.287203</td>\n",
       "      <td>1.144874</td>\n",
       "      <td>0.595544</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.728854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0005</th>\n",
       "      <td>-0.452707</td>\n",
       "      <td>0.211724</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.105692</td>\n",
       "      <td>0.088081</td>\n",
       "      <td>-0.109452</td>\n",
       "      <td>0.208944</td>\n",
       "      <td>0.185074</td>\n",
       "      <td>0.533692</td>\n",
       "      <td>0.666086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884624</td>\n",
       "      <td>0.681302</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.455983</td>\n",
       "      <td>0.518626</td>\n",
       "      <td>0.463286</td>\n",
       "      <td>0.793437</td>\n",
       "      <td>-0.182278</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.198520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0006</th>\n",
       "      <td>-0.444591</td>\n",
       "      <td>0.344861</td>\n",
       "      <td>-0.730082</td>\n",
       "      <td>0.518467</td>\n",
       "      <td>-0.178900</td>\n",
       "      <td>-0.660072</td>\n",
       "      <td>-0.733352</td>\n",
       "      <td>-0.164000</td>\n",
       "      <td>0.323106</td>\n",
       "      <td>0.563685</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.256904</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.190454</td>\n",
       "      <td>-1.167309</td>\n",
       "      <td>0.463277</td>\n",
       "      <td>0.996881</td>\n",
       "      <td>0.243467</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.262606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0008</th>\n",
       "      <td>-0.063484</td>\n",
       "      <td>0.604704</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>0.157058</td>\n",
       "      <td>0.784126</td>\n",
       "      <td>0.523687</td>\n",
       "      <td>0.705062</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.650657</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626894</td>\n",
       "      <td>0.690349</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.357423</td>\n",
       "      <td>0.598058</td>\n",
       "      <td>1.032206</td>\n",
       "      <td>-0.156499</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.711918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0009</th>\n",
       "      <td>-1.014420</td>\n",
       "      <td>0.027920</td>\n",
       "      <td>0.485191</td>\n",
       "      <td>1.511839</td>\n",
       "      <td>2.342554</td>\n",
       "      <td>-0.059718</td>\n",
       "      <td>-0.901242</td>\n",
       "      <td>2.952803</td>\n",
       "      <td>3.037081</td>\n",
       "      <td>1.972919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056384</td>\n",
       "      <td>1.073685</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>2.372708</td>\n",
       "      <td>1.781837</td>\n",
       "      <td>-4.757775</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>1.391432</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-3.818267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0010</th>\n",
       "      <td>-1.071431</td>\n",
       "      <td>0.484398</td>\n",
       "      <td>-0.933368</td>\n",
       "      <td>-0.658817</td>\n",
       "      <td>-0.998986</td>\n",
       "      <td>-0.943378</td>\n",
       "      <td>-1.362364</td>\n",
       "      <td>-0.970939</td>\n",
       "      <td>-0.853908</td>\n",
       "      <td>-0.605820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.555258</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.785608</td>\n",
       "      <td>-0.303165</td>\n",
       "      <td>0.070641</td>\n",
       "      <td>0.277815</td>\n",
       "      <td>0.669304</td>\n",
       "      <td>0.071529</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.462936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0011</th>\n",
       "      <td>-0.921800</td>\n",
       "      <td>0.182561</td>\n",
       "      <td>-2.304816</td>\n",
       "      <td>-1.383902</td>\n",
       "      <td>-1.199928</td>\n",
       "      <td>-0.621190</td>\n",
       "      <td>-1.538195</td>\n",
       "      <td>-1.155816</td>\n",
       "      <td>-0.558486</td>\n",
       "      <td>-0.865617</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.144206</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.399549</td>\n",
       "      <td>-1.752028</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>0.774877</td>\n",
       "      <td>0.128418</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.916628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0012</th>\n",
       "      <td>0.370489</td>\n",
       "      <td>0.568469</td>\n",
       "      <td>0.573826</td>\n",
       "      <td>1.847973</td>\n",
       "      <td>2.247641</td>\n",
       "      <td>-1.047992</td>\n",
       "      <td>-1.840582</td>\n",
       "      <td>2.485153</td>\n",
       "      <td>2.363211</td>\n",
       "      <td>2.430353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.381163</td>\n",
       "      <td>0.671095</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>1.425060</td>\n",
       "      <td>0.034088</td>\n",
       "      <td>0.766789</td>\n",
       "      <td>0.848066</td>\n",
       "      <td>0.465206</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.968155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0013</th>\n",
       "      <td>0.237404</td>\n",
       "      <td>0.468118</td>\n",
       "      <td>-0.328469</td>\n",
       "      <td>0.401016</td>\n",
       "      <td>0.664377</td>\n",
       "      <td>-0.110870</td>\n",
       "      <td>1.175788</td>\n",
       "      <td>0.527173</td>\n",
       "      <td>0.230430</td>\n",
       "      <td>0.598487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245687</td>\n",
       "      <td>0.782167</td>\n",
       "      <td>0.773910</td>\n",
       "      <td>0.154829</td>\n",
       "      <td>0.823008</td>\n",
       "      <td>0.794247</td>\n",
       "      <td>0.658943</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.089385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0014</th>\n",
       "      <td>-0.043427</td>\n",
       "      <td>0.164883</td>\n",
       "      <td>-0.241251</td>\n",
       "      <td>-0.231408</td>\n",
       "      <td>-0.153178</td>\n",
       "      <td>0.290115</td>\n",
       "      <td>-0.123583</td>\n",
       "      <td>-0.380659</td>\n",
       "      <td>-0.117571</td>\n",
       "      <td>-0.196329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203878</td>\n",
       "      <td>0.699708</td>\n",
       "      <td>1.132509</td>\n",
       "      <td>-0.447637</td>\n",
       "      <td>-0.504793</td>\n",
       "      <td>0.158031</td>\n",
       "      <td>0.882336</td>\n",
       "      <td>0.306069</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.752933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0015</th>\n",
       "      <td>-0.159249</td>\n",
       "      <td>0.653677</td>\n",
       "      <td>0.067769</td>\n",
       "      <td>0.653778</td>\n",
       "      <td>-0.451082</td>\n",
       "      <td>-1.435228</td>\n",
       "      <td>-1.653990</td>\n",
       "      <td>-0.421961</td>\n",
       "      <td>-0.142727</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>...</td>\n",
       "      <td>1.742628</td>\n",
       "      <td>0.581885</td>\n",
       "      <td>0.973181</td>\n",
       "      <td>-0.168088</td>\n",
       "      <td>-0.960749</td>\n",
       "      <td>0.403107</td>\n",
       "      <td>1.090746</td>\n",
       "      <td>-0.082349</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.371974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0016</th>\n",
       "      <td>-0.313939</td>\n",
       "      <td>0.505943</td>\n",
       "      <td>-0.474605</td>\n",
       "      <td>0.395045</td>\n",
       "      <td>-0.454325</td>\n",
       "      <td>0.768875</td>\n",
       "      <td>1.061524</td>\n",
       "      <td>-0.027705</td>\n",
       "      <td>-0.504156</td>\n",
       "      <td>0.133814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959270</td>\n",
       "      <td>0.802266</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.934674</td>\n",
       "      <td>-0.521819</td>\n",
       "      <td>0.304097</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.469263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0017</th>\n",
       "      <td>0.617328</td>\n",
       "      <td>-2.842400</td>\n",
       "      <td>-0.042863</td>\n",
       "      <td>0.876221</td>\n",
       "      <td>0.948050</td>\n",
       "      <td>-0.556515</td>\n",
       "      <td>-0.586851</td>\n",
       "      <td>1.194970</td>\n",
       "      <td>1.516010</td>\n",
       "      <td>1.081449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927239</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.039801</td>\n",
       "      <td>0.731721</td>\n",
       "      <td>0.243670</td>\n",
       "      <td>0.670608</td>\n",
       "      <td>0.733369</td>\n",
       "      <td>0.427240</td>\n",
       "      <td>2.775695</td>\n",
       "      <td>-0.883431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0018</th>\n",
       "      <td>-0.841823</td>\n",
       "      <td>-2.842400</td>\n",
       "      <td>0.611775</td>\n",
       "      <td>2.342445</td>\n",
       "      <td>2.457968</td>\n",
       "      <td>-1.436767</td>\n",
       "      <td>-1.273134</td>\n",
       "      <td>1.043109</td>\n",
       "      <td>0.310334</td>\n",
       "      <td>2.145601</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039750</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.883744</td>\n",
       "      <td>2.903385</td>\n",
       "      <td>-0.352164</td>\n",
       "      <td>0.753175</td>\n",
       "      <td>0.917304</td>\n",
       "      <td>-0.170010</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.633091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0019</th>\n",
       "      <td>-0.536535</td>\n",
       "      <td>0.282387</td>\n",
       "      <td>-0.669082</td>\n",
       "      <td>-0.261382</td>\n",
       "      <td>-0.587647</td>\n",
       "      <td>-0.113586</td>\n",
       "      <td>0.768471</td>\n",
       "      <td>-0.019680</td>\n",
       "      <td>-0.749318</td>\n",
       "      <td>0.085651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.683476</td>\n",
       "      <td>0.928697</td>\n",
       "      <td>-1.103343</td>\n",
       "      <td>-0.071915</td>\n",
       "      <td>0.273526</td>\n",
       "      <td>0.796041</td>\n",
       "      <td>-0.234333</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.359326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0020</th>\n",
       "      <td>-1.286744</td>\n",
       "      <td>0.683392</td>\n",
       "      <td>-0.230312</td>\n",
       "      <td>0.520323</td>\n",
       "      <td>-0.197100</td>\n",
       "      <td>-1.564600</td>\n",
       "      <td>-1.281168</td>\n",
       "      <td>-0.488723</td>\n",
       "      <td>-0.260558</td>\n",
       "      <td>0.360519</td>\n",
       "      <td>...</td>\n",
       "      <td>1.246719</td>\n",
       "      <td>0.644466</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.094803</td>\n",
       "      <td>-0.970501</td>\n",
       "      <td>0.396902</td>\n",
       "      <td>0.910396</td>\n",
       "      <td>0.320131</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.042961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0021</th>\n",
       "      <td>0.526197</td>\n",
       "      <td>-2.842400</td>\n",
       "      <td>-0.390967</td>\n",
       "      <td>0.445794</td>\n",
       "      <td>0.184534</td>\n",
       "      <td>-1.203421</td>\n",
       "      <td>-1.145355</td>\n",
       "      <td>0.687426</td>\n",
       "      <td>0.684889</td>\n",
       "      <td>0.804522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987853</td>\n",
       "      <td>0.836414</td>\n",
       "      <td>1.029127</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>-1.018371</td>\n",
       "      <td>0.330028</td>\n",
       "      <td>0.723915</td>\n",
       "      <td>0.062511</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.227033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0022</th>\n",
       "      <td>-1.362488</td>\n",
       "      <td>0.307889</td>\n",
       "      <td>-0.984365</td>\n",
       "      <td>-1.156695</td>\n",
       "      <td>-1.288870</td>\n",
       "      <td>-0.259354</td>\n",
       "      <td>-0.329153</td>\n",
       "      <td>-1.661139</td>\n",
       "      <td>-1.751085</td>\n",
       "      <td>-1.280175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.299670</td>\n",
       "      <td>0.732401</td>\n",
       "      <td>0.706613</td>\n",
       "      <td>-0.743866</td>\n",
       "      <td>-2.689368</td>\n",
       "      <td>0.031758</td>\n",
       "      <td>0.760415</td>\n",
       "      <td>-0.233864</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.712032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0023</th>\n",
       "      <td>-1.226360</td>\n",
       "      <td>-0.380853</td>\n",
       "      <td>-2.068576</td>\n",
       "      <td>-1.459295</td>\n",
       "      <td>-2.173385</td>\n",
       "      <td>-1.454016</td>\n",
       "      <td>-1.745151</td>\n",
       "      <td>-1.424173</td>\n",
       "      <td>-1.924884</td>\n",
       "      <td>-1.365756</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.136616</td>\n",
       "      <td>0.678694</td>\n",
       "      <td>0.997710</td>\n",
       "      <td>-0.693899</td>\n",
       "      <td>-2.348000</td>\n",
       "      <td>-0.091542</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.313074</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.879198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0024</th>\n",
       "      <td>0.218499</td>\n",
       "      <td>0.742546</td>\n",
       "      <td>-0.366158</td>\n",
       "      <td>0.410088</td>\n",
       "      <td>-0.554448</td>\n",
       "      <td>-0.343820</td>\n",
       "      <td>-0.535454</td>\n",
       "      <td>-0.260692</td>\n",
       "      <td>-0.020393</td>\n",
       "      <td>0.194022</td>\n",
       "      <td>...</td>\n",
       "      <td>1.626982</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.048342</td>\n",
       "      <td>-0.461180</td>\n",
       "      <td>0.103370</td>\n",
       "      <td>0.875968</td>\n",
       "      <td>0.238226</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.705871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0025</th>\n",
       "      <td>-0.525737</td>\n",
       "      <td>0.242389</td>\n",
       "      <td>0.106966</td>\n",
       "      <td>0.424007</td>\n",
       "      <td>0.286912</td>\n",
       "      <td>-0.878035</td>\n",
       "      <td>-1.127625</td>\n",
       "      <td>0.521370</td>\n",
       "      <td>0.787054</td>\n",
       "      <td>0.509760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186735</td>\n",
       "      <td>0.740892</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.404844</td>\n",
       "      <td>-0.157597</td>\n",
       "      <td>0.652556</td>\n",
       "      <td>1.144599</td>\n",
       "      <td>0.312478</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.480518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0026</th>\n",
       "      <td>-1.102176</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>-1.320566</td>\n",
       "      <td>-0.620084</td>\n",
       "      <td>-1.046110</td>\n",
       "      <td>-0.585962</td>\n",
       "      <td>-0.764696</td>\n",
       "      <td>-0.931632</td>\n",
       "      <td>-0.883488</td>\n",
       "      <td>-0.745137</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.254419</td>\n",
       "      <td>0.617929</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.567240</td>\n",
       "      <td>-1.194215</td>\n",
       "      <td>0.164191</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.037894</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.236674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0029</th>\n",
       "      <td>-1.437548</td>\n",
       "      <td>-0.297698</td>\n",
       "      <td>-1.784748</td>\n",
       "      <td>-1.028572</td>\n",
       "      <td>-1.752626</td>\n",
       "      <td>0.407274</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>-0.784135</td>\n",
       "      <td>-1.550076</td>\n",
       "      <td>-1.090772</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.328883</td>\n",
       "      <td>0.857367</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.160892</td>\n",
       "      <td>-0.607662</td>\n",
       "      <td>-0.239373</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.291046</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.386633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0060</th>\n",
       "      <td>1.016182</td>\n",
       "      <td>0.544289</td>\n",
       "      <td>-0.468397</td>\n",
       "      <td>-0.756485</td>\n",
       "      <td>-0.454883</td>\n",
       "      <td>-0.032562</td>\n",
       "      <td>0.310191</td>\n",
       "      <td>-1.481712</td>\n",
       "      <td>-0.330176</td>\n",
       "      <td>-1.178254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.717043</td>\n",
       "      <td>0.766825</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.787432</td>\n",
       "      <td>-1.118817</td>\n",
       "      <td>-0.086020</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.220998</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.530488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0061</th>\n",
       "      <td>-0.473287</td>\n",
       "      <td>0.056637</td>\n",
       "      <td>0.117051</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>0.056609</td>\n",
       "      <td>-0.557902</td>\n",
       "      <td>-0.201168</td>\n",
       "      <td>-0.439586</td>\n",
       "      <td>0.132665</td>\n",
       "      <td>-0.769386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141075</td>\n",
       "      <td>0.875788</td>\n",
       "      <td>1.023826</td>\n",
       "      <td>0.292035</td>\n",
       "      <td>0.637192</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>-0.417092</td>\n",
       "      <td>2.371024</td>\n",
       "      <td>-1.178913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0062</th>\n",
       "      <td>0.745442</td>\n",
       "      <td>0.616147</td>\n",
       "      <td>1.085803</td>\n",
       "      <td>0.833815</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>-0.484330</td>\n",
       "      <td>0.229278</td>\n",
       "      <td>0.747268</td>\n",
       "      <td>0.973920</td>\n",
       "      <td>0.660299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880805</td>\n",
       "      <td>0.883678</td>\n",
       "      <td>0.986659</td>\n",
       "      <td>0.537345</td>\n",
       "      <td>0.138341</td>\n",
       "      <td>0.284933</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.463572</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.086073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0065</th>\n",
       "      <td>4.464034</td>\n",
       "      <td>0.193050</td>\n",
       "      <td>1.630309</td>\n",
       "      <td>1.204508</td>\n",
       "      <td>1.248069</td>\n",
       "      <td>-0.647544</td>\n",
       "      <td>0.895345</td>\n",
       "      <td>2.280033</td>\n",
       "      <td>2.542494</td>\n",
       "      <td>1.493681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648056</td>\n",
       "      <td>1.039465</td>\n",
       "      <td>1.362254</td>\n",
       "      <td>2.228318</td>\n",
       "      <td>1.156093</td>\n",
       "      <td>0.712185</td>\n",
       "      <td>0.806037</td>\n",
       "      <td>1.366535</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.422842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0069</th>\n",
       "      <td>0.348975</td>\n",
       "      <td>0.462294</td>\n",
       "      <td>1.085377</td>\n",
       "      <td>0.647411</td>\n",
       "      <td>-1.216716</td>\n",
       "      <td>-1.487006</td>\n",
       "      <td>-0.768889</td>\n",
       "      <td>0.030915</td>\n",
       "      <td>-0.054809</td>\n",
       "      <td>-0.638935</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164933</td>\n",
       "      <td>0.779073</td>\n",
       "      <td>1.085613</td>\n",
       "      <td>0.088204</td>\n",
       "      <td>0.281165</td>\n",
       "      <td>-0.110367</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.255357</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.438022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0071</th>\n",
       "      <td>1.644933</td>\n",
       "      <td>0.098840</td>\n",
       "      <td>0.919072</td>\n",
       "      <td>1.045445</td>\n",
       "      <td>1.664938</td>\n",
       "      <td>-0.048870</td>\n",
       "      <td>0.641201</td>\n",
       "      <td>1.740010</td>\n",
       "      <td>1.594438</td>\n",
       "      <td>1.463288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622412</td>\n",
       "      <td>0.664615</td>\n",
       "      <td>0.796809</td>\n",
       "      <td>1.809818</td>\n",
       "      <td>-0.077944</td>\n",
       "      <td>0.215619</td>\n",
       "      <td>0.934529</td>\n",
       "      <td>0.536589</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.677777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0075</th>\n",
       "      <td>-0.655847</td>\n",
       "      <td>0.101901</td>\n",
       "      <td>-0.216873</td>\n",
       "      <td>-1.024741</td>\n",
       "      <td>-0.981342</td>\n",
       "      <td>0.315110</td>\n",
       "      <td>-0.255794</td>\n",
       "      <td>-0.916104</td>\n",
       "      <td>-0.796130</td>\n",
       "      <td>-1.089311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.355271</td>\n",
       "      <td>0.800728</td>\n",
       "      <td>1.039417</td>\n",
       "      <td>-0.704558</td>\n",
       "      <td>-1.319216</td>\n",
       "      <td>-0.153142</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-1.114976</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.983068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0076</th>\n",
       "      <td>-0.310756</td>\n",
       "      <td>0.693401</td>\n",
       "      <td>1.007125</td>\n",
       "      <td>0.964734</td>\n",
       "      <td>-0.202587</td>\n",
       "      <td>-1.844818</td>\n",
       "      <td>-0.896235</td>\n",
       "      <td>-0.697784</td>\n",
       "      <td>0.181026</td>\n",
       "      <td>0.569351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868714</td>\n",
       "      <td>0.862941</td>\n",
       "      <td>0.958617</td>\n",
       "      <td>-0.126775</td>\n",
       "      <td>-1.118319</td>\n",
       "      <td>0.262785</td>\n",
       "      <td>0.916767</td>\n",
       "      <td>0.052875</td>\n",
       "      <td>2.609635</td>\n",
       "      <td>0.057696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0081</th>\n",
       "      <td>0.291229</td>\n",
       "      <td>0.286913</td>\n",
       "      <td>0.724079</td>\n",
       "      <td>0.436671</td>\n",
       "      <td>0.206326</td>\n",
       "      <td>-0.243124</td>\n",
       "      <td>0.625176</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.202261</td>\n",
       "      <td>0.767037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673424</td>\n",
       "      <td>0.630064</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.061468</td>\n",
       "      <td>-1.003477</td>\n",
       "      <td>0.538467</td>\n",
       "      <td>1.011856</td>\n",
       "      <td>0.731500</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.429805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0082</th>\n",
       "      <td>-0.370661</td>\n",
       "      <td>0.739036</td>\n",
       "      <td>1.271797</td>\n",
       "      <td>0.726100</td>\n",
       "      <td>0.766660</td>\n",
       "      <td>-1.076300</td>\n",
       "      <td>-0.679681</td>\n",
       "      <td>1.173660</td>\n",
       "      <td>0.952265</td>\n",
       "      <td>0.059237</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384673</td>\n",
       "      <td>0.901840</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>-0.047370</td>\n",
       "      <td>-0.184204</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>1.046076</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.261577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0083</th>\n",
       "      <td>0.388913</td>\n",
       "      <td>0.232071</td>\n",
       "      <td>1.041605</td>\n",
       "      <td>0.902932</td>\n",
       "      <td>0.923106</td>\n",
       "      <td>-1.479170</td>\n",
       "      <td>-0.725972</td>\n",
       "      <td>0.561737</td>\n",
       "      <td>1.005341</td>\n",
       "      <td>0.631400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753887</td>\n",
       "      <td>0.656740</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.344238</td>\n",
       "      <td>-0.614887</td>\n",
       "      <td>0.347417</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.130942</td>\n",
       "      <td>3.000866</td>\n",
       "      <td>0.672039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0031</th>\n",
       "      <td>-0.173575</td>\n",
       "      <td>0.559403</td>\n",
       "      <td>1.404774</td>\n",
       "      <td>0.862172</td>\n",
       "      <td>-0.182821</td>\n",
       "      <td>-0.912828</td>\n",
       "      <td>-1.302345</td>\n",
       "      <td>1.019318</td>\n",
       "      <td>0.738750</td>\n",
       "      <td>-0.484735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.864565</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>1.135026</td>\n",
       "      <td>-0.832697</td>\n",
       "      <td>-4.757775</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.263231</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.020141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0032</th>\n",
       "      <td>1.363014</td>\n",
       "      <td>0.852724</td>\n",
       "      <td>1.620287</td>\n",
       "      <td>1.712404</td>\n",
       "      <td>1.276279</td>\n",
       "      <td>0.174185</td>\n",
       "      <td>0.437325</td>\n",
       "      <td>1.204032</td>\n",
       "      <td>1.578419</td>\n",
       "      <td>1.610603</td>\n",
       "      <td>...</td>\n",
       "      <td>1.564273</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.916243</td>\n",
       "      <td>1.594664</td>\n",
       "      <td>-1.017494</td>\n",
       "      <td>0.866281</td>\n",
       "      <td>1.040314</td>\n",
       "      <td>0.346796</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.727455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0033</th>\n",
       "      <td>0.004265</td>\n",
       "      <td>0.846777</td>\n",
       "      <td>1.335345</td>\n",
       "      <td>0.400130</td>\n",
       "      <td>0.469740</td>\n",
       "      <td>-0.250658</td>\n",
       "      <td>-0.528948</td>\n",
       "      <td>0.849011</td>\n",
       "      <td>0.816911</td>\n",
       "      <td>0.121975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370601</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.024995</td>\n",
       "      <td>0.610686</td>\n",
       "      <td>0.834647</td>\n",
       "      <td>-4.757775</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.510835</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.217325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0034</th>\n",
       "      <td>1.169427</td>\n",
       "      <td>0.556844</td>\n",
       "      <td>0.808415</td>\n",
       "      <td>0.667631</td>\n",
       "      <td>0.581447</td>\n",
       "      <td>0.060103</td>\n",
       "      <td>0.540228</td>\n",
       "      <td>0.516714</td>\n",
       "      <td>0.714247</td>\n",
       "      <td>0.972676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120977</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.938123</td>\n",
       "      <td>-0.844161</td>\n",
       "      <td>0.578631</td>\n",
       "      <td>0.970715</td>\n",
       "      <td>0.564428</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.950002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0035</th>\n",
       "      <td>-0.360567</td>\n",
       "      <td>0.846949</td>\n",
       "      <td>0.979596</td>\n",
       "      <td>0.268736</td>\n",
       "      <td>0.448585</td>\n",
       "      <td>-0.310850</td>\n",
       "      <td>-0.422807</td>\n",
       "      <td>-0.655380</td>\n",
       "      <td>0.036763</td>\n",
       "      <td>-0.277446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262686</td>\n",
       "      <td>0.833449</td>\n",
       "      <td>1.131501</td>\n",
       "      <td>0.188816</td>\n",
       "      <td>-1.644843</td>\n",
       "      <td>0.195078</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.131956</td>\n",
       "      <td>3.609404</td>\n",
       "      <td>1.375492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0036</th>\n",
       "      <td>-0.064681</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>1.326424</td>\n",
       "      <td>1.318422</td>\n",
       "      <td>0.348091</td>\n",
       "      <td>-0.331799</td>\n",
       "      <td>-1.112680</td>\n",
       "      <td>0.753750</td>\n",
       "      <td>0.474937</td>\n",
       "      <td>0.662958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854944</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>1.463038</td>\n",
       "      <td>1.332991</td>\n",
       "      <td>-0.539399</td>\n",
       "      <td>0.473270</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.443274</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.807493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0037</th>\n",
       "      <td>-0.031287</td>\n",
       "      <td>-0.020087</td>\n",
       "      <td>1.275895</td>\n",
       "      <td>0.788813</td>\n",
       "      <td>0.389590</td>\n",
       "      <td>-2.367784</td>\n",
       "      <td>-1.431053</td>\n",
       "      <td>0.742751</td>\n",
       "      <td>0.413208</td>\n",
       "      <td>0.224323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156028</td>\n",
       "      <td>0.870393</td>\n",
       "      <td>0.893215</td>\n",
       "      <td>0.189604</td>\n",
       "      <td>-0.610693</td>\n",
       "      <td>-0.209467</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.945151</td>\n",
       "      <td>2.847851</td>\n",
       "      <td>-0.032311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0038</th>\n",
       "      <td>0.127102</td>\n",
       "      <td>0.735821</td>\n",
       "      <td>0.962326</td>\n",
       "      <td>1.252127</td>\n",
       "      <td>1.027538</td>\n",
       "      <td>-1.468612</td>\n",
       "      <td>-0.540858</td>\n",
       "      <td>1.084620</td>\n",
       "      <td>0.898749</td>\n",
       "      <td>1.476899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902514</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>1.325798</td>\n",
       "      <td>0.474221</td>\n",
       "      <td>0.154646</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.909238</td>\n",
       "      <td>3.778292</td>\n",
       "      <td>1.619436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0039</th>\n",
       "      <td>0.076393</td>\n",
       "      <td>0.369525</td>\n",
       "      <td>0.262198</td>\n",
       "      <td>-0.434926</td>\n",
       "      <td>-0.641064</td>\n",
       "      <td>-0.367527</td>\n",
       "      <td>-0.258453</td>\n",
       "      <td>-0.416765</td>\n",
       "      <td>-0.246040</td>\n",
       "      <td>-0.748481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543181</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.039146</td>\n",
       "      <td>0.081579</td>\n",
       "      <td>-1.086837</td>\n",
       "      <td>-0.351680</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.517124</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.052990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0050</th>\n",
       "      <td>1.048922</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>1.692505</td>\n",
       "      <td>1.645615</td>\n",
       "      <td>0.750238</td>\n",
       "      <td>-0.066897</td>\n",
       "      <td>-0.130413</td>\n",
       "      <td>1.106432</td>\n",
       "      <td>1.015931</td>\n",
       "      <td>1.764417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333553</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.216004</td>\n",
       "      <td>0.990117</td>\n",
       "      <td>-0.753045</td>\n",
       "      <td>0.618545</td>\n",
       "      <td>1.050514</td>\n",
       "      <td>0.563625</td>\n",
       "      <td>2.764119</td>\n",
       "      <td>1.325121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0053</th>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>1.198284</td>\n",
       "      <td>0.221591</td>\n",
       "      <td>0.145348</td>\n",
       "      <td>-0.039695</td>\n",
       "      <td>0.745301</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.749415</td>\n",
       "      <td>-0.464770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274710</td>\n",
       "      <td>0.532431</td>\n",
       "      <td>1.088167</td>\n",
       "      <td>0.843921</td>\n",
       "      <td>1.440228</td>\n",
       "      <td>0.082751</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>1.027156</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.287373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0070</th>\n",
       "      <td>-1.309004</td>\n",
       "      <td>0.213414</td>\n",
       "      <td>-0.418802</td>\n",
       "      <td>-1.097679</td>\n",
       "      <td>-1.892068</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>-1.458774</td>\n",
       "      <td>-2.380129</td>\n",
       "      <td>-1.965949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788725</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-2.301812</td>\n",
       "      <td>-1.832232</td>\n",
       "      <td>-0.425255</td>\n",
       "      <td>0.830336</td>\n",
       "      <td>-1.228546</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.297272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0077</th>\n",
       "      <td>0.308685</td>\n",
       "      <td>0.423766</td>\n",
       "      <td>1.251951</td>\n",
       "      <td>1.631973</td>\n",
       "      <td>1.143059</td>\n",
       "      <td>-1.097219</td>\n",
       "      <td>0.168213</td>\n",
       "      <td>0.915839</td>\n",
       "      <td>1.162923</td>\n",
       "      <td>1.594137</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098347</td>\n",
       "      <td>0.702783</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.351349</td>\n",
       "      <td>0.462246</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>1.047099</td>\n",
       "      <td>0.768713</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.443454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0087</th>\n",
       "      <td>0.262581</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>0.801761</td>\n",
       "      <td>0.796105</td>\n",
       "      <td>0.392620</td>\n",
       "      <td>-0.952609</td>\n",
       "      <td>0.115493</td>\n",
       "      <td>0.295912</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.749829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412925</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.797906</td>\n",
       "      <td>0.189569</td>\n",
       "      <td>-1.457010</td>\n",
       "      <td>0.273234</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>0.341713</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.079904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 21861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "C_0002 -1.238669 -0.489755 -1.404819 -0.661768 -1.214104 -0.438326 -0.542205   \n",
       "C_0003 -0.094326  0.128294 -0.400562 -0.392906  0.908731  0.454217 -0.792399   \n",
       "C_0004 -0.513695  0.528638 -0.372793  0.456696 -0.126533 -0.054497 -0.268084   \n",
       "C_0005 -0.452707  0.211724  0.002274  0.105692  0.088081 -0.109452  0.208944   \n",
       "C_0006 -0.444591  0.344861 -0.730082  0.518467 -0.178900 -0.660072 -0.733352   \n",
       "C_0008 -0.063484  0.604704 -0.010074  0.157058  0.784126  0.523687  0.705062   \n",
       "C_0009 -1.014420  0.027920  0.485191  1.511839  2.342554 -0.059718 -0.901242   \n",
       "C_0010 -1.071431  0.484398 -0.933368 -0.658817 -0.998986 -0.943378 -1.362364   \n",
       "C_0011 -0.921800  0.182561 -2.304816 -1.383902 -1.199928 -0.621190 -1.538195   \n",
       "C_0012  0.370489  0.568469  0.573826  1.847973  2.247641 -1.047992 -1.840582   \n",
       "C_0013  0.237404  0.468118 -0.328469  0.401016  0.664377 -0.110870  1.175788   \n",
       "C_0014 -0.043427  0.164883 -0.241251 -0.231408 -0.153178  0.290115 -0.123583   \n",
       "C_0015 -0.159249  0.653677  0.067769  0.653778 -0.451082 -1.435228 -1.653990   \n",
       "C_0016 -0.313939  0.505943 -0.474605  0.395045 -0.454325  0.768875  1.061524   \n",
       "C_0017  0.617328 -2.842400 -0.042863  0.876221  0.948050 -0.556515 -0.586851   \n",
       "C_0018 -0.841823 -2.842400  0.611775  2.342445  2.457968 -1.436767 -1.273134   \n",
       "C_0019 -0.536535  0.282387 -0.669082 -0.261382 -0.587647 -0.113586  0.768471   \n",
       "C_0020 -1.286744  0.683392 -0.230312  0.520323 -0.197100 -1.564600 -1.281168   \n",
       "C_0021  0.526197 -2.842400 -0.390967  0.445794  0.184534 -1.203421 -1.145355   \n",
       "C_0022 -1.362488  0.307889 -0.984365 -1.156695 -1.288870 -0.259354 -0.329153   \n",
       "C_0023 -1.226360 -0.380853 -2.068576 -1.459295 -2.173385 -1.454016 -1.745151   \n",
       "C_0024  0.218499  0.742546 -0.366158  0.410088 -0.554448 -0.343820 -0.535454   \n",
       "C_0025 -0.525737  0.242389  0.106966  0.424007  0.286912 -0.878035 -1.127625   \n",
       "C_0026 -1.102176  0.412127 -1.320566 -0.620084 -1.046110 -0.585962 -0.764696   \n",
       "C_0029 -1.437548 -0.297698 -1.784748 -1.028572 -1.752626  0.407274  0.008234   \n",
       "C_0060  1.016182  0.544289 -0.468397 -0.756485 -0.454883 -0.032562  0.310191   \n",
       "C_0061 -0.473287  0.056637  0.117051 -0.359745  0.056609 -0.557902 -0.201168   \n",
       "C_0062  0.745442  0.616147  1.085803  0.833815  0.022261 -0.484330  0.229278   \n",
       "C_0065  4.464034  0.193050  1.630309  1.204508  1.248069 -0.647544  0.895345   \n",
       "C_0069  0.348975  0.462294  1.085377  0.647411 -1.216716 -1.487006 -0.768889   \n",
       "C_0071  1.644933  0.098840  0.919072  1.045445  1.664938 -0.048870  0.641201   \n",
       "C_0075 -0.655847  0.101901 -0.216873 -1.024741 -0.981342  0.315110 -0.255794   \n",
       "C_0076 -0.310756  0.693401  1.007125  0.964734 -0.202587 -1.844818 -0.896235   \n",
       "C_0081  0.291229  0.286913  0.724079  0.436671  0.206326 -0.243124  0.625176   \n",
       "C_0082 -0.370661  0.739036  1.271797  0.726100  0.766660 -1.076300 -0.679681   \n",
       "C_0083  0.388913  0.232071  1.041605  0.902932  0.923106 -1.479170 -0.725972   \n",
       "C_0031 -0.173575  0.559403  1.404774  0.862172 -0.182821 -0.912828 -1.302345   \n",
       "C_0032  1.363014  0.852724  1.620287  1.712404  1.276279  0.174185  0.437325   \n",
       "C_0033  0.004265  0.846777  1.335345  0.400130  0.469740 -0.250658 -0.528948   \n",
       "C_0034  1.169427  0.556844  0.808415  0.667631  0.581447  0.060103  0.540228   \n",
       "C_0035 -0.360567  0.846949  0.979596  0.268736  0.448585 -0.310850 -0.422807   \n",
       "C_0036 -0.064681  0.223731  1.326424  1.318422  0.348091 -0.331799 -1.112680   \n",
       "C_0037 -0.031287 -0.020087  1.275895  0.788813  0.389590 -2.367784 -1.431053   \n",
       "C_0038  0.127102  0.735821  0.962326  1.252127  1.027538 -1.468612 -0.540858   \n",
       "C_0039  0.076393  0.369525  0.262198 -0.434926 -0.641064 -0.367527 -0.258453   \n",
       "C_0050  1.048922  0.577184  1.692505  1.645615  0.750238 -0.066897 -0.130413   \n",
       "C_0053  0.433121  0.560606  1.198284  0.221591  0.145348 -0.039695  0.745301   \n",
       "C_0070 -1.309004  0.213414 -0.418802 -1.097679 -1.892068  0.063291  0.524590   \n",
       "C_0077  0.308685  0.423766  1.251951  1.631973  1.143059 -1.097219  0.168213   \n",
       "C_0087  0.262581  0.557800  0.801761  0.796105  0.392620 -0.952609  0.115493   \n",
       "\n",
       "           7         8         9      ...     21853     21854     21855  \\\n",
       "C_0002 -1.549951 -1.144974 -1.361823  ... -0.794664 -1.270403  0.737597   \n",
       "C_0003  0.733360  0.611638  0.953743  ...  0.767006  0.814752 -1.029937   \n",
       "C_0004 -0.347413 -0.285398 -0.322790  ...  0.051075  0.649930  0.776952   \n",
       "C_0005  0.185074  0.533692  0.666086  ...  0.884624  0.681302 -1.029937   \n",
       "C_0006 -0.164000  0.323106  0.563685  ... -1.256904 -1.270403 -1.029937   \n",
       "C_0008  0.107073  0.650657  0.591910  ...  0.626894  0.690349 -1.029937   \n",
       "C_0009  2.952803  3.037081  1.972919  ...  0.056384  1.073685 -1.029937   \n",
       "C_0010 -0.970939 -0.853908 -0.605820  ... -0.555258 -1.270403  0.785608   \n",
       "C_0011 -1.155816 -0.558486 -0.865617  ... -1.144206 -1.270403 -1.029937   \n",
       "C_0012  2.485153  2.363211  2.430353  ...  1.381163  0.671095  0.987434   \n",
       "C_0013  0.527173  0.230430  0.598487  ...  0.245687  0.782167  0.773910   \n",
       "C_0014 -0.380659 -0.117571 -0.196329  ...  0.203878  0.699708  1.132509   \n",
       "C_0015 -0.421961 -0.142727  0.361802  ...  1.742628  0.581885  0.973181   \n",
       "C_0016 -0.027705 -0.504156  0.133814  ...  0.959270  0.802266 -1.029937   \n",
       "C_0017  1.194970  1.516010  1.081449  ...  0.927239 -1.270403  1.039801   \n",
       "C_0018  1.043109  0.310334  2.145601  ...  2.039750 -1.270403  0.883744   \n",
       "C_0019 -0.019680 -0.749318  0.085651  ...  0.332958  0.683476  0.928697   \n",
       "C_0020 -0.488723 -0.260558  0.360519  ...  1.246719  0.644466 -1.029937   \n",
       "C_0021  0.687426  0.684889  0.804522  ...  0.987853  0.836414  1.029127   \n",
       "C_0022 -1.661139 -1.751085 -1.280175  ... -0.299670  0.732401  0.706613   \n",
       "C_0023 -1.424173 -1.924884 -1.365756  ... -1.136616  0.678694  0.997710   \n",
       "C_0024 -0.260692 -0.020393  0.194022  ...  1.626982 -1.270403 -1.029937   \n",
       "C_0025  0.521370  0.787054  0.509760  ... -0.186735  0.740892 -1.029937   \n",
       "C_0026 -0.931632 -0.883488 -0.745137  ... -1.254419  0.617929 -1.029937   \n",
       "C_0029 -0.784135 -1.550076 -1.090772  ... -1.328883  0.857367 -1.029937   \n",
       "C_0060 -1.481712 -0.330176 -1.178254  ... -0.717043  0.766825 -1.029937   \n",
       "C_0061 -0.439586  0.132665 -0.769386  ... -0.141075  0.875788  1.023826   \n",
       "C_0062  0.747268  0.973920  0.660299  ...  0.880805  0.883678  0.986659   \n",
       "C_0065  2.280033  2.542494  1.493681  ...  0.648056  1.039465  1.362254   \n",
       "C_0069  0.030915 -0.054809 -0.638935  ... -1.164933  0.779073  1.085613   \n",
       "C_0071  1.740010  1.594438  1.463288  ...  0.622412  0.664615  0.796809   \n",
       "C_0075 -0.916104 -0.796130 -1.089311  ... -0.355271  0.800728  1.039417   \n",
       "C_0076 -0.697784  0.181026  0.569351  ...  0.868714  0.862941  0.958617   \n",
       "C_0081  0.001589  0.202261  0.767037  ...  0.673424  0.630064 -1.029937   \n",
       "C_0082  1.173660  0.952265  0.059237  ...  1.384673  0.901840 -1.029937   \n",
       "C_0083  0.561737  1.005341  0.631400  ...  0.753887  0.656740 -1.029937   \n",
       "C_0031  1.019318  0.738750 -0.484735  ... -0.864565 -1.270403 -1.029937   \n",
       "C_0032  1.204032  1.578419  1.610603  ...  1.564273 -1.270403  0.916243   \n",
       "C_0033  0.849011  0.816911  0.121975  ...  1.370601 -1.270403  1.024995   \n",
       "C_0034  0.516714  0.714247  0.972676  ... -0.120977 -1.270403 -1.029937   \n",
       "C_0035 -0.655380  0.036763 -0.277446  ...  0.262686  0.833449  1.131501   \n",
       "C_0036  0.753750  0.474937  0.662958  ...  0.854944  0.999951  1.463038   \n",
       "C_0037  0.742751  0.413208  0.224323  ...  0.156028  0.870393  0.893215   \n",
       "C_0038  1.084620  0.898749  1.476899  ...  0.902514 -1.270403 -1.029937   \n",
       "C_0039 -0.416765 -0.246040 -0.748481  ...  0.543181 -1.270403  1.039146   \n",
       "C_0050  1.106432  1.015931  1.764417  ...  1.333553 -1.270403  1.216004   \n",
       "C_0053  0.947575  0.749415 -0.464770  ...  0.274710  0.532431  1.088167   \n",
       "C_0070 -1.458774 -2.380129 -1.965949  ... -0.788725 -1.270403 -1.029937   \n",
       "C_0077  0.915839  1.162923  1.594137  ...  1.098347  0.702783 -1.029937   \n",
       "C_0087  0.295912  0.798726  0.749829  ...  0.412925 -1.270403  0.797906   \n",
       "\n",
       "           21856     21857     21858     21859     21860     21861     21862  \n",
       "C_0002 -1.819190 -0.178338  0.264969  0.721004 -0.094753 -0.349492 -0.142859  \n",
       "C_0003  0.719449  0.054000  0.220818  0.859050  0.298774 -0.349492 -0.149023  \n",
       "C_0004 -0.466111 -0.596202  0.287203  1.144874  0.595544 -0.349492  0.728854  \n",
       "C_0005 -0.455983  0.518626  0.463286  0.793437 -0.182278 -0.349492  0.198520  \n",
       "C_0006  0.190454 -1.167309  0.463277  0.996881  0.243467 -0.349492 -0.262606  \n",
       "C_0008 -0.004865  0.357423  0.598058  1.032206 -0.156499 -0.349492 -0.711918  \n",
       "C_0009  2.372708  1.781837 -4.757775 -1.220236  1.391432 -0.349492 -3.818267  \n",
       "C_0010 -0.303165  0.070641  0.277815  0.669304  0.071529 -0.349492 -0.462936  \n",
       "C_0011 -1.399549 -1.752028 -0.121130  0.774877  0.128418 -0.349492 -0.916628  \n",
       "C_0012  1.425060  0.034088  0.766789  0.848066  0.465206 -0.349492  0.968155  \n",
       "C_0013  0.154829  0.823008  0.794247  0.658943  0.046881 -0.349492 -0.089385  \n",
       "C_0014 -0.447637 -0.504793  0.158031  0.882336  0.306069 -0.349492  0.752933  \n",
       "C_0015 -0.168088 -0.960749  0.403107  1.090746 -0.082349 -0.349492  1.371974  \n",
       "C_0016 -0.934674 -0.521819  0.304097 -1.220236 -0.120013 -0.349492 -0.469263  \n",
       "C_0017  0.731721  0.243670  0.670608  0.733369  0.427240  2.775695 -0.883431  \n",
       "C_0018  2.903385 -0.352164  0.753175  0.917304 -0.170010 -0.349492  1.633091  \n",
       "C_0019 -1.103343 -0.071915  0.273526  0.796041 -0.234333 -0.349492  0.359326  \n",
       "C_0020 -0.094803 -0.970501  0.396902  0.910396  0.320131 -0.349492 -0.042961  \n",
       "C_0021  0.380531 -1.018371  0.330028  0.723915  0.062511 -0.349492 -0.227033  \n",
       "C_0022 -0.743866 -2.689368  0.031758  0.760415 -0.233864 -0.349492 -0.712032  \n",
       "C_0023 -0.693899 -2.348000 -0.091542 -1.220236 -0.313074 -0.349492 -0.879198  \n",
       "C_0024 -0.048342 -0.461180  0.103370  0.875968  0.238226 -0.349492 -0.705871  \n",
       "C_0025  0.404844 -0.157597  0.652556  1.144599  0.312478 -0.349492  0.480518  \n",
       "C_0026 -0.567240 -1.194215  0.164191 -1.220236 -0.037894 -0.349492  0.236674  \n",
       "C_0029 -1.160892 -0.607662 -0.239373 -1.220236  0.291046 -0.349492 -0.386633  \n",
       "C_0060 -0.787432 -1.118817 -0.086020 -1.220236 -0.220998 -0.349492 -0.530488  \n",
       "C_0061  0.292035  0.637192  0.554100  0.558140 -0.417092  2.371024 -1.178913  \n",
       "C_0062  0.537345  0.138341  0.284933 -1.220236  0.463572 -0.349492  0.086073  \n",
       "C_0065  2.228318  1.156093  0.712185  0.806037  1.366535 -0.349492  1.422842  \n",
       "C_0069  0.088204  0.281165 -0.110367 -1.220236  0.255357 -0.349492  1.438022  \n",
       "C_0071  1.809818 -0.077944  0.215619  0.934529  0.536589 -0.349492  0.677777  \n",
       "C_0075 -0.704558 -1.319216 -0.153142 -1.220236 -1.114976 -0.349492 -0.983068  \n",
       "C_0076 -0.126775 -1.118319  0.262785  0.916767  0.052875  2.609635  0.057696  \n",
       "C_0081 -0.061468 -1.003477  0.538467  1.011856  0.731500 -0.349492  0.429805  \n",
       "C_0082  0.644238 -0.047370 -0.184204 -1.220236  1.046076 -0.349492  0.261577  \n",
       "C_0083  0.344238 -0.614887  0.347417 -1.220236  0.130942  3.000866  0.672039  \n",
       "C_0031  1.135026 -0.832697 -4.757775 -1.220236 -0.263231 -0.349492  0.020141  \n",
       "C_0032  1.594664 -1.017494  0.866281  1.040314  0.346796 -0.349492  0.727455  \n",
       "C_0033  0.610686  0.834647 -4.757775 -1.220236  0.510835 -0.349492  1.217325  \n",
       "C_0034  0.938123 -0.844161  0.578631  0.970715  0.564428 -0.349492  0.950002  \n",
       "C_0035  0.188816 -1.644843  0.195078 -1.220236 -0.131956  3.609404  1.375492  \n",
       "C_0036  1.332991 -0.539399  0.473270 -1.220236  0.443274 -0.349492  1.807493  \n",
       "C_0037  0.189604 -0.610693 -0.209467 -1.220236  0.945151  2.847851 -0.032311  \n",
       "C_0038  1.325798  0.474221  0.154646 -1.220236  0.909238  3.778292  1.619436  \n",
       "C_0039  0.081579 -1.086837 -0.351680 -1.220236  0.517124 -0.349492 -1.052990  \n",
       "C_0050  0.990117 -0.753045  0.618545  1.050514  0.563625  2.764119  1.325121  \n",
       "C_0053  0.843921  1.440228  0.082751 -1.220236  1.027156 -0.349492  1.287373  \n",
       "C_0070 -2.301812 -1.832232 -0.425255  0.830336 -1.228546 -0.349492 -0.297272  \n",
       "C_0077  0.351349  0.462246  0.408542  1.047099  0.768713 -0.349492  0.443454  \n",
       "C_0087  0.189569 -1.457010  0.273234  0.680197  0.341713 -0.349492  1.079904  \n",
       "\n",
       "[50 rows x 21861 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX_C=dataX_log_del2.filter(like='C', axis=0)\n",
    "dataX_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba61fcf6-fe27-4389-a876-2cc3041c0cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3362802/805336276.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataX_C['cluster']=1\n",
      "/tmp/ipykernel_3362802/805336276.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataX_P['cluster']=0\n",
      "/tmp/ipykernel_3362802/805336276.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataX_H['cluster']=2\n"
     ]
    }
   ],
   "source": [
    "dataX_C['cluster']=1\n",
    "dataX_P=dataX_log_del2.filter(like='P', axis=0)\n",
    "dataX_P['cluster']=0\n",
    "dataX_H=dataX_log_del2.filter(like='H',axis=0)\n",
    "dataX_H['cluster']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37378dac-825f-4084-9b40-2c4e35a8ef52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0002</th>\n",
       "      <td>-1.238669</td>\n",
       "      <td>-0.489755</td>\n",
       "      <td>-1.404819</td>\n",
       "      <td>-0.661768</td>\n",
       "      <td>-1.214104</td>\n",
       "      <td>-0.438326</td>\n",
       "      <td>-0.542205</td>\n",
       "      <td>-1.549951</td>\n",
       "      <td>-1.144974</td>\n",
       "      <td>-1.361823</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.737597</td>\n",
       "      <td>-1.819190</td>\n",
       "      <td>-0.178338</td>\n",
       "      <td>0.264969</td>\n",
       "      <td>0.721004</td>\n",
       "      <td>-0.094753</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.142859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0003</th>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.128294</td>\n",
       "      <td>-0.400562</td>\n",
       "      <td>-0.392906</td>\n",
       "      <td>0.908731</td>\n",
       "      <td>0.454217</td>\n",
       "      <td>-0.792399</td>\n",
       "      <td>0.733360</td>\n",
       "      <td>0.611638</td>\n",
       "      <td>0.953743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814752</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.719449</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.220818</td>\n",
       "      <td>0.859050</td>\n",
       "      <td>0.298774</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.149023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0004</th>\n",
       "      <td>-0.513695</td>\n",
       "      <td>0.528638</td>\n",
       "      <td>-0.372793</td>\n",
       "      <td>0.456696</td>\n",
       "      <td>-0.126533</td>\n",
       "      <td>-0.054497</td>\n",
       "      <td>-0.268084</td>\n",
       "      <td>-0.347413</td>\n",
       "      <td>-0.285398</td>\n",
       "      <td>-0.322790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649930</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>-0.466111</td>\n",
       "      <td>-0.596202</td>\n",
       "      <td>0.287203</td>\n",
       "      <td>1.144874</td>\n",
       "      <td>0.595544</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.728854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0005</th>\n",
       "      <td>-0.452707</td>\n",
       "      <td>0.211724</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.105692</td>\n",
       "      <td>0.088081</td>\n",
       "      <td>-0.109452</td>\n",
       "      <td>0.208944</td>\n",
       "      <td>0.185074</td>\n",
       "      <td>0.533692</td>\n",
       "      <td>0.666086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681302</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.455983</td>\n",
       "      <td>0.518626</td>\n",
       "      <td>0.463286</td>\n",
       "      <td>0.793437</td>\n",
       "      <td>-0.182278</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.198520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0006</th>\n",
       "      <td>-0.444591</td>\n",
       "      <td>0.344861</td>\n",
       "      <td>-0.730082</td>\n",
       "      <td>0.518467</td>\n",
       "      <td>-0.178900</td>\n",
       "      <td>-0.660072</td>\n",
       "      <td>-0.733352</td>\n",
       "      <td>-0.164000</td>\n",
       "      <td>0.323106</td>\n",
       "      <td>0.563685</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.190454</td>\n",
       "      <td>-1.167309</td>\n",
       "      <td>0.463277</td>\n",
       "      <td>0.996881</td>\n",
       "      <td>0.243467</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.262606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0689</th>\n",
       "      <td>-1.056665</td>\n",
       "      <td>-0.131702</td>\n",
       "      <td>-2.461487</td>\n",
       "      <td>-2.196218</td>\n",
       "      <td>-0.828361</td>\n",
       "      <td>1.475229</td>\n",
       "      <td>0.686531</td>\n",
       "      <td>-1.842048</td>\n",
       "      <td>-1.833416</td>\n",
       "      <td>-0.990698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676598</td>\n",
       "      <td>0.813014</td>\n",
       "      <td>-2.498809</td>\n",
       "      <td>-0.298672</td>\n",
       "      <td>0.243131</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.478093</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-2.423072</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0709</th>\n",
       "      <td>-0.813836</td>\n",
       "      <td>0.110010</td>\n",
       "      <td>0.332046</td>\n",
       "      <td>-1.371978</td>\n",
       "      <td>-1.159991</td>\n",
       "      <td>-0.961007</td>\n",
       "      <td>-0.240771</td>\n",
       "      <td>-0.532297</td>\n",
       "      <td>-1.179250</td>\n",
       "      <td>-1.522107</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.059062</td>\n",
       "      <td>0.190509</td>\n",
       "      <td>-4.757775</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-4.368677</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.082281</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0723</th>\n",
       "      <td>0.740941</td>\n",
       "      <td>0.692626</td>\n",
       "      <td>0.985739</td>\n",
       "      <td>-0.153001</td>\n",
       "      <td>-0.268487</td>\n",
       "      <td>0.037081</td>\n",
       "      <td>0.639643</td>\n",
       "      <td>-0.215969</td>\n",
       "      <td>-0.145524</td>\n",
       "      <td>0.047562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.071325</td>\n",
       "      <td>0.983066</td>\n",
       "      <td>1.379293</td>\n",
       "      <td>1.249711</td>\n",
       "      <td>-0.185067</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.343931</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.869277</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1104</th>\n",
       "      <td>-0.448897</td>\n",
       "      <td>0.149684</td>\n",
       "      <td>0.344353</td>\n",
       "      <td>0.107790</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>0.409116</td>\n",
       "      <td>0.303394</td>\n",
       "      <td>-0.866286</td>\n",
       "      <td>-0.533084</td>\n",
       "      <td>-0.141975</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.437144</td>\n",
       "      <td>0.149815</td>\n",
       "      <td>0.178247</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.106997</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1105</th>\n",
       "      <td>-0.537081</td>\n",
       "      <td>0.415169</td>\n",
       "      <td>1.062265</td>\n",
       "      <td>0.954178</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>1.303455</td>\n",
       "      <td>-0.598432</td>\n",
       "      <td>0.868221</td>\n",
       "      <td>-0.181386</td>\n",
       "      <td>-0.306728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832702</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>1.372934</td>\n",
       "      <td>0.944623</td>\n",
       "      <td>-0.604752</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.508965</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.514668</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 21862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "C_0002 -1.238669 -0.489755 -1.404819 -0.661768 -1.214104 -0.438326 -0.542205   \n",
       "C_0003 -0.094326  0.128294 -0.400562 -0.392906  0.908731  0.454217 -0.792399   \n",
       "C_0004 -0.513695  0.528638 -0.372793  0.456696 -0.126533 -0.054497 -0.268084   \n",
       "C_0005 -0.452707  0.211724  0.002274  0.105692  0.088081 -0.109452  0.208944   \n",
       "C_0006 -0.444591  0.344861 -0.730082  0.518467 -0.178900 -0.660072 -0.733352   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "H_0689 -1.056665 -0.131702 -2.461487 -2.196218 -0.828361  1.475229  0.686531   \n",
       "H_0709 -0.813836  0.110010  0.332046 -1.371978 -1.159991 -0.961007 -0.240771   \n",
       "H_0723  0.740941  0.692626  0.985739 -0.153001 -0.268487  0.037081  0.639643   \n",
       "H_1104 -0.448897  0.149684  0.344353  0.107790  0.044293  0.409116  0.303394   \n",
       "H_1105 -0.537081  0.415169  1.062265  0.954178 -0.012975  1.303455 -0.598432   \n",
       "\n",
       "               7         8         9  ...     21854     21855     21856  \\\n",
       "C_0002 -1.549951 -1.144974 -1.361823  ... -1.270403  0.737597 -1.819190   \n",
       "C_0003  0.733360  0.611638  0.953743  ...  0.814752 -1.029937  0.719449   \n",
       "C_0004 -0.347413 -0.285398 -0.322790  ...  0.649930  0.776952 -0.466111   \n",
       "C_0005  0.185074  0.533692  0.666086  ...  0.681302 -1.029937 -0.455983   \n",
       "C_0006 -0.164000  0.323106  0.563685  ... -1.270403 -1.029937  0.190454   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "H_0689 -1.842048 -1.833416 -0.990698  ...  0.676598  0.813014 -2.498809   \n",
       "H_0709 -0.532297 -1.179250 -1.522107  ... -1.270403 -1.029937  0.059062   \n",
       "H_0723 -0.215969 -0.145524  0.047562  ...  1.071325  0.983066  1.379293   \n",
       "H_1104 -0.866286 -0.533084 -0.141975  ... -1.270403 -1.029937 -0.437144   \n",
       "H_1105  0.868221 -0.181386 -0.306728  ...  0.832702  1.024108  1.372934   \n",
       "\n",
       "           21857     21858     21859     21860     21861     21862  cluster  \n",
       "C_0002 -0.178338  0.264969  0.721004 -0.094753 -0.349492 -0.142859        1  \n",
       "C_0003  0.054000  0.220818  0.859050  0.298774 -0.349492 -0.149023        1  \n",
       "C_0004 -0.596202  0.287203  1.144874  0.595544 -0.349492  0.728854        1  \n",
       "C_0005  0.518626  0.463286  0.793437 -0.182278 -0.349492  0.198520        1  \n",
       "C_0006 -1.167309  0.463277  0.996881  0.243467 -0.349492 -0.262606        1  \n",
       "...          ...       ...       ...       ...       ...       ...      ...  \n",
       "H_0689 -0.298672  0.243131 -1.220236 -0.478093 -0.349492 -2.423072        2  \n",
       "H_0709  0.190509 -4.757775 -1.220236 -4.368677 -0.349492  1.082281        2  \n",
       "H_0723  1.249711 -0.185067 -1.220236 -0.343931 -0.349492  0.869277        2  \n",
       "H_1104  0.149815  0.178247 -1.220236  0.106997 -0.349492  0.552147        2  \n",
       "H_1105  0.944623 -0.604752 -1.220236  0.508965 -0.349492 -0.514668        2  \n",
       "\n",
       "[108 rows x 21862 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX_cluster=pd.concat([dataX_C, dataX_P, dataX_H], ignore_index=False)\n",
    "dataX_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29fffb55-84ef-4280-850e-87826cc44026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0002</th>\n",
       "      <td>-1.238669</td>\n",
       "      <td>-0.489755</td>\n",
       "      <td>-1.404819</td>\n",
       "      <td>-0.661768</td>\n",
       "      <td>-1.214104</td>\n",
       "      <td>-0.438326</td>\n",
       "      <td>-0.542205</td>\n",
       "      <td>-1.549951</td>\n",
       "      <td>-1.144974</td>\n",
       "      <td>-1.361823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.794664</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.737597</td>\n",
       "      <td>-1.819190</td>\n",
       "      <td>-0.178338</td>\n",
       "      <td>0.264969</td>\n",
       "      <td>0.721004</td>\n",
       "      <td>-0.094753</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.142859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0003</th>\n",
       "      <td>-0.094326</td>\n",
       "      <td>0.128294</td>\n",
       "      <td>-0.400562</td>\n",
       "      <td>-0.392906</td>\n",
       "      <td>0.908731</td>\n",
       "      <td>0.454217</td>\n",
       "      <td>-0.792399</td>\n",
       "      <td>0.733360</td>\n",
       "      <td>0.611638</td>\n",
       "      <td>0.953743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>0.814752</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.719449</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.220818</td>\n",
       "      <td>0.859050</td>\n",
       "      <td>0.298774</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.149023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0004</th>\n",
       "      <td>-0.513695</td>\n",
       "      <td>0.528638</td>\n",
       "      <td>-0.372793</td>\n",
       "      <td>0.456696</td>\n",
       "      <td>-0.126533</td>\n",
       "      <td>-0.054497</td>\n",
       "      <td>-0.268084</td>\n",
       "      <td>-0.347413</td>\n",
       "      <td>-0.285398</td>\n",
       "      <td>-0.322790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051075</td>\n",
       "      <td>0.649930</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>-0.466111</td>\n",
       "      <td>-0.596202</td>\n",
       "      <td>0.287203</td>\n",
       "      <td>1.144874</td>\n",
       "      <td>0.595544</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.728854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0005</th>\n",
       "      <td>-0.452707</td>\n",
       "      <td>0.211724</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.105692</td>\n",
       "      <td>0.088081</td>\n",
       "      <td>-0.109452</td>\n",
       "      <td>0.208944</td>\n",
       "      <td>0.185074</td>\n",
       "      <td>0.533692</td>\n",
       "      <td>0.666086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884624</td>\n",
       "      <td>0.681302</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.455983</td>\n",
       "      <td>0.518626</td>\n",
       "      <td>0.463286</td>\n",
       "      <td>0.793437</td>\n",
       "      <td>-0.182278</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.198520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0006</th>\n",
       "      <td>-0.444591</td>\n",
       "      <td>0.344861</td>\n",
       "      <td>-0.730082</td>\n",
       "      <td>0.518467</td>\n",
       "      <td>-0.178900</td>\n",
       "      <td>-0.660072</td>\n",
       "      <td>-0.733352</td>\n",
       "      <td>-0.164000</td>\n",
       "      <td>0.323106</td>\n",
       "      <td>0.563685</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.256904</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.190454</td>\n",
       "      <td>-1.167309</td>\n",
       "      <td>0.463277</td>\n",
       "      <td>0.996881</td>\n",
       "      <td>0.243467</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.262606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0689</th>\n",
       "      <td>-1.056665</td>\n",
       "      <td>-0.131702</td>\n",
       "      <td>-2.461487</td>\n",
       "      <td>-2.196218</td>\n",
       "      <td>-0.828361</td>\n",
       "      <td>1.475229</td>\n",
       "      <td>0.686531</td>\n",
       "      <td>-1.842048</td>\n",
       "      <td>-1.833416</td>\n",
       "      <td>-0.990698</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.765663</td>\n",
       "      <td>0.676598</td>\n",
       "      <td>0.813014</td>\n",
       "      <td>-2.498809</td>\n",
       "      <td>-0.298672</td>\n",
       "      <td>0.243131</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.478093</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-2.423072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0709</th>\n",
       "      <td>-0.813836</td>\n",
       "      <td>0.110010</td>\n",
       "      <td>0.332046</td>\n",
       "      <td>-1.371978</td>\n",
       "      <td>-1.159991</td>\n",
       "      <td>-0.961007</td>\n",
       "      <td>-0.240771</td>\n",
       "      <td>-0.532297</td>\n",
       "      <td>-1.179250</td>\n",
       "      <td>-1.522107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.899592</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.059062</td>\n",
       "      <td>0.190509</td>\n",
       "      <td>-4.757775</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-4.368677</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.082281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0723</th>\n",
       "      <td>0.740941</td>\n",
       "      <td>0.692626</td>\n",
       "      <td>0.985739</td>\n",
       "      <td>-0.153001</td>\n",
       "      <td>-0.268487</td>\n",
       "      <td>0.037081</td>\n",
       "      <td>0.639643</td>\n",
       "      <td>-0.215969</td>\n",
       "      <td>-0.145524</td>\n",
       "      <td>0.047562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332414</td>\n",
       "      <td>1.071325</td>\n",
       "      <td>0.983066</td>\n",
       "      <td>1.379293</td>\n",
       "      <td>1.249711</td>\n",
       "      <td>-0.185067</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.343931</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.869277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1104</th>\n",
       "      <td>-0.448897</td>\n",
       "      <td>0.149684</td>\n",
       "      <td>0.344353</td>\n",
       "      <td>0.107790</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>0.409116</td>\n",
       "      <td>0.303394</td>\n",
       "      <td>-0.866286</td>\n",
       "      <td>-0.533084</td>\n",
       "      <td>-0.141975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274111</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.437144</td>\n",
       "      <td>0.149815</td>\n",
       "      <td>0.178247</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.106997</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.552147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_1105</th>\n",
       "      <td>-0.537081</td>\n",
       "      <td>0.415169</td>\n",
       "      <td>1.062265</td>\n",
       "      <td>0.954178</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>1.303455</td>\n",
       "      <td>-0.598432</td>\n",
       "      <td>0.868221</td>\n",
       "      <td>-0.181386</td>\n",
       "      <td>-0.306728</td>\n",
       "      <td>...</td>\n",
       "      <td>1.443922</td>\n",
       "      <td>0.832702</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>1.372934</td>\n",
       "      <td>0.944623</td>\n",
       "      <td>-0.604752</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.508965</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.514668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 21861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "C_0002 -1.238669 -0.489755 -1.404819 -0.661768 -1.214104 -0.438326 -0.542205   \n",
       "C_0003 -0.094326  0.128294 -0.400562 -0.392906  0.908731  0.454217 -0.792399   \n",
       "C_0004 -0.513695  0.528638 -0.372793  0.456696 -0.126533 -0.054497 -0.268084   \n",
       "C_0005 -0.452707  0.211724  0.002274  0.105692  0.088081 -0.109452  0.208944   \n",
       "C_0006 -0.444591  0.344861 -0.730082  0.518467 -0.178900 -0.660072 -0.733352   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "H_0689 -1.056665 -0.131702 -2.461487 -2.196218 -0.828361  1.475229  0.686531   \n",
       "H_0709 -0.813836  0.110010  0.332046 -1.371978 -1.159991 -0.961007 -0.240771   \n",
       "H_0723  0.740941  0.692626  0.985739 -0.153001 -0.268487  0.037081  0.639643   \n",
       "H_1104 -0.448897  0.149684  0.344353  0.107790  0.044293  0.409116  0.303394   \n",
       "H_1105 -0.537081  0.415169  1.062265  0.954178 -0.012975  1.303455 -0.598432   \n",
       "\n",
       "           7         8         9      ...     21853     21854     21855  \\\n",
       "C_0002 -1.549951 -1.144974 -1.361823  ... -0.794664 -1.270403  0.737597   \n",
       "C_0003  0.733360  0.611638  0.953743  ...  0.767006  0.814752 -1.029937   \n",
       "C_0004 -0.347413 -0.285398 -0.322790  ...  0.051075  0.649930  0.776952   \n",
       "C_0005  0.185074  0.533692  0.666086  ...  0.884624  0.681302 -1.029937   \n",
       "C_0006 -0.164000  0.323106  0.563685  ... -1.256904 -1.270403 -1.029937   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "H_0689 -1.842048 -1.833416 -0.990698  ... -1.765663  0.676598  0.813014   \n",
       "H_0709 -0.532297 -1.179250 -1.522107  ... -0.899592 -1.270403 -1.029937   \n",
       "H_0723 -0.215969 -0.145524  0.047562  ...  0.332414  1.071325  0.983066   \n",
       "H_1104 -0.866286 -0.533084 -0.141975  ...  0.274111 -1.270403 -1.029937   \n",
       "H_1105  0.868221 -0.181386 -0.306728  ...  1.443922  0.832702  1.024108   \n",
       "\n",
       "           21856     21857     21858     21859     21860     21861     21862  \n",
       "C_0002 -1.819190 -0.178338  0.264969  0.721004 -0.094753 -0.349492 -0.142859  \n",
       "C_0003  0.719449  0.054000  0.220818  0.859050  0.298774 -0.349492 -0.149023  \n",
       "C_0004 -0.466111 -0.596202  0.287203  1.144874  0.595544 -0.349492  0.728854  \n",
       "C_0005 -0.455983  0.518626  0.463286  0.793437 -0.182278 -0.349492  0.198520  \n",
       "C_0006  0.190454 -1.167309  0.463277  0.996881  0.243467 -0.349492 -0.262606  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "H_0689 -2.498809 -0.298672  0.243131 -1.220236 -0.478093 -0.349492 -2.423072  \n",
       "H_0709  0.059062  0.190509 -4.757775 -1.220236 -4.368677 -0.349492  1.082281  \n",
       "H_0723  1.379293  1.249711 -0.185067 -1.220236 -0.343931 -0.349492  0.869277  \n",
       "H_1104 -0.437144  0.149815  0.178247 -1.220236  0.106997 -0.349492  0.552147  \n",
       "H_1105  1.372934  0.944623 -0.604752 -1.220236  0.508965 -0.349492 -0.514668  \n",
       "\n",
       "[108 rows x 21861 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX_log_del2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f291f6-3579-49a6-ba3d-2f85fdff8261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_num=dataX_cluster['cluster']\n",
    "patient_num_array=patient_num.values\n",
    "patient_num_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28e55feb-d53b-4e50-98e4-f2c1411fc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patient_num, test_patient_num=train_test_split(patient_num_array, test_size=0.05, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a09cab1-eb6b-497d-acc5-67d3081f2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_del2,X_test_del2=train_test_split(dataX_log_del2,test_size=0.05,random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f10ddaf6-10b7-4ad7-af65-8345803d7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(dataX_cluster, test_size=0.05,random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6282db67-869d-4428-8dc4-e183df9b2266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0083</th>\n",
       "      <td>0.388913</td>\n",
       "      <td>0.232071</td>\n",
       "      <td>1.041605</td>\n",
       "      <td>0.902932</td>\n",
       "      <td>0.923106</td>\n",
       "      <td>-1.479170</td>\n",
       "      <td>-0.725972</td>\n",
       "      <td>0.561737</td>\n",
       "      <td>1.005341</td>\n",
       "      <td>0.631400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753887</td>\n",
       "      <td>0.656740</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.344238</td>\n",
       "      <td>-0.614887</td>\n",
       "      <td>0.347417</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.130942</td>\n",
       "      <td>3.000866</td>\n",
       "      <td>0.672039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0031</th>\n",
       "      <td>0.599252</td>\n",
       "      <td>0.517350</td>\n",
       "      <td>-0.696765</td>\n",
       "      <td>-0.421019</td>\n",
       "      <td>0.050207</td>\n",
       "      <td>1.220664</td>\n",
       "      <td>1.151044</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>-1.110864</td>\n",
       "      <td>-0.437187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183169</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.097530</td>\n",
       "      <td>0.200089</td>\n",
       "      <td>0.739144</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.232364</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.365384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0006</th>\n",
       "      <td>1.007862</td>\n",
       "      <td>0.051293</td>\n",
       "      <td>0.647164</td>\n",
       "      <td>-0.520091</td>\n",
       "      <td>0.337481</td>\n",
       "      <td>1.187124</td>\n",
       "      <td>0.750467</td>\n",
       "      <td>-0.115304</td>\n",
       "      <td>-0.631415</td>\n",
       "      <td>-0.789085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340969</td>\n",
       "      <td>0.852506</td>\n",
       "      <td>1.126368</td>\n",
       "      <td>0.267152</td>\n",
       "      <td>0.448367</td>\n",
       "      <td>-0.559285</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.912924</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.014469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0008</th>\n",
       "      <td>-0.063484</td>\n",
       "      <td>0.604704</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>0.157058</td>\n",
       "      <td>0.784126</td>\n",
       "      <td>0.523687</td>\n",
       "      <td>0.705062</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.650657</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626894</td>\n",
       "      <td>0.690349</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.357423</td>\n",
       "      <td>0.598058</td>\n",
       "      <td>1.032206</td>\n",
       "      <td>-0.156499</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.711918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0050</th>\n",
       "      <td>1.048922</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>1.692505</td>\n",
       "      <td>1.645615</td>\n",
       "      <td>0.750238</td>\n",
       "      <td>-0.066897</td>\n",
       "      <td>-0.130413</td>\n",
       "      <td>1.106432</td>\n",
       "      <td>1.015931</td>\n",
       "      <td>1.764417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333553</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.216004</td>\n",
       "      <td>0.990117</td>\n",
       "      <td>-0.753045</td>\n",
       "      <td>0.618545</td>\n",
       "      <td>1.050514</td>\n",
       "      <td>0.563625</td>\n",
       "      <td>2.764119</td>\n",
       "      <td>1.325121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0012</th>\n",
       "      <td>-1.521997</td>\n",
       "      <td>0.067175</td>\n",
       "      <td>-0.349465</td>\n",
       "      <td>-1.227161</td>\n",
       "      <td>-1.159223</td>\n",
       "      <td>0.147176</td>\n",
       "      <td>0.480327</td>\n",
       "      <td>-1.637841</td>\n",
       "      <td>-1.043687</td>\n",
       "      <td>-0.477915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128161</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.323493</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>-0.492980</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-4.368677</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.423462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0033</th>\n",
       "      <td>-0.308662</td>\n",
       "      <td>-2.842400</td>\n",
       "      <td>-1.013575</td>\n",
       "      <td>-1.503260</td>\n",
       "      <td>1.012608</td>\n",
       "      <td>1.045038</td>\n",
       "      <td>0.305299</td>\n",
       "      <td>1.377415</td>\n",
       "      <td>0.175105</td>\n",
       "      <td>1.355158</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.949676</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.113567</td>\n",
       "      <td>2.240185</td>\n",
       "      <td>0.180481</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.492978</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.463357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0026</th>\n",
       "      <td>-1.104348</td>\n",
       "      <td>-0.361754</td>\n",
       "      <td>-2.265461</td>\n",
       "      <td>-1.338545</td>\n",
       "      <td>-1.442219</td>\n",
       "      <td>1.086292</td>\n",
       "      <td>0.306438</td>\n",
       "      <td>-1.990019</td>\n",
       "      <td>-2.105757</td>\n",
       "      <td>-1.549385</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.444562</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-2.168804</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.285848</td>\n",
       "      <td>0.708244</td>\n",
       "      <td>-0.160791</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.689478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0020</th>\n",
       "      <td>0.402486</td>\n",
       "      <td>0.358057</td>\n",
       "      <td>0.360601</td>\n",
       "      <td>0.890447</td>\n",
       "      <td>1.228254</td>\n",
       "      <td>0.222134</td>\n",
       "      <td>-0.048097</td>\n",
       "      <td>1.077339</td>\n",
       "      <td>0.915871</td>\n",
       "      <td>0.779060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.272410</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.876687</td>\n",
       "      <td>1.026927</td>\n",
       "      <td>0.919544</td>\n",
       "      <td>0.541630</td>\n",
       "      <td>0.749975</td>\n",
       "      <td>-0.343924</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.017914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0657</th>\n",
       "      <td>-0.064258</td>\n",
       "      <td>0.172921</td>\n",
       "      <td>0.519725</td>\n",
       "      <td>-0.133270</td>\n",
       "      <td>-0.175916</td>\n",
       "      <td>1.377655</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.458264</td>\n",
       "      <td>-0.163786</td>\n",
       "      <td>-0.114812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179268</td>\n",
       "      <td>0.526197</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.282419</td>\n",
       "      <td>-0.833780</td>\n",
       "      <td>-0.073411</td>\n",
       "      <td>0.835596</td>\n",
       "      <td>0.287229</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.182819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 21861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "C_0083  0.388913  0.232071  1.041605  0.902932  0.923106 -1.479170 -0.725972   \n",
       "P_0031  0.599252  0.517350 -0.696765 -0.421019  0.050207  1.220664  1.151044   \n",
       "H_0006  1.007862  0.051293  0.647164 -0.520091  0.337481  1.187124  0.750467   \n",
       "C_0008 -0.063484  0.604704 -0.010074  0.157058  0.784126  0.523687  0.705062   \n",
       "C_0050  1.048922  0.577184  1.692505  1.645615  0.750238 -0.066897 -0.130413   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "H_0012 -1.521997  0.067175 -0.349465 -1.227161 -1.159223  0.147176  0.480327   \n",
       "P_0033 -0.308662 -2.842400 -1.013575 -1.503260  1.012608  1.045038  0.305299   \n",
       "P_0026 -1.104348 -0.361754 -2.265461 -1.338545 -1.442219  1.086292  0.306438   \n",
       "P_0020  0.402486  0.358057  0.360601  0.890447  1.228254  0.222134 -0.048097   \n",
       "H_0657 -0.064258  0.172921  0.519725 -0.133270 -0.175916  1.377655  0.786557   \n",
       "\n",
       "           7         8         9      ...     21853     21854     21855  \\\n",
       "C_0083  0.561737  1.005341  0.631400  ...  0.753887  0.656740 -1.029937   \n",
       "P_0031  0.018565 -1.110864 -0.437187  ... -0.183169 -1.270403  1.097530   \n",
       "H_0006 -0.115304 -0.631415 -0.789085  ... -0.340969  0.852506  1.126368   \n",
       "C_0008  0.107073  0.650657  0.591910  ...  0.626894  0.690349 -1.029937   \n",
       "C_0050  1.106432  1.015931  1.764417  ...  1.333553 -1.270403  1.216004   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "H_0012 -1.637841 -1.043687 -0.477915  ...  0.128161  0.782275 -1.029937   \n",
       "P_0033  1.377415  0.175105  1.355158  ... -1.949676 -1.270403 -1.029937   \n",
       "P_0026 -1.990019 -2.105757 -1.549385  ... -1.444562 -1.270403 -1.029937   \n",
       "P_0020  1.077339  0.915871  0.779060  ...  1.272410 -1.270403  0.876687   \n",
       "H_0657  0.458264 -0.163786 -0.114812  ...  0.179268  0.526197 -1.029937   \n",
       "\n",
       "           21856     21857     21858     21859     21860     21861     21862  \n",
       "C_0083  0.344238 -0.614887  0.347417 -1.220236  0.130942  3.000866  0.672039  \n",
       "P_0031  0.200089  0.739144  0.427200  0.690276  0.232364 -0.349492  0.365384  \n",
       "H_0006  0.267152  0.448367 -0.559285 -1.220236  0.912924 -0.349492  1.014469  \n",
       "C_0008 -0.004865  0.357423  0.598058  1.032206 -0.156499 -0.349492 -0.711918  \n",
       "C_0050  0.990117 -0.753045  0.618545  1.050514  0.563625  2.764119  1.325121  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "H_0012 -1.323493 -0.181305 -0.492980 -1.220236 -4.368677 -0.349492 -1.423462  \n",
       "P_0033 -0.113567  2.240185  0.180481 -1.220236  0.492978 -0.349492 -0.463357  \n",
       "P_0026 -2.168804  0.318966  0.285848  0.708244 -0.160791 -0.349492 -1.689478  \n",
       "P_0020  1.026927  0.919544  0.541630  0.749975 -0.343924 -0.349492  0.017914  \n",
       "H_0657  0.282419 -0.833780 -0.073411  0.835596  0.287229 -0.349492  0.182819  \n",
       "\n",
       "[102 rows x 21861 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_del2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "296993e0-eb59-4bfa-aff1-b1868f582b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 1, 2, 1, 0, 0, 0, 2, 1, 2, 0, 1,\n",
       "       0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1,\n",
       "       2, 0, 1, 1, 2, 0, 1, 1, 0, 2, 1, 1, 2, 2, 0, 1, 2, 2, 0, 0, 0, 2,\n",
       "       1, 0, 1, 2, 0, 2, 1, 0, 1, 2, 1, 1, 2, 1, 2, 2, 1, 0, 1, 2, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_patient_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c7bf0d7-a8f2-4069-9c0d-84aae796c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0083</th>\n",
       "      <td>0.388913</td>\n",
       "      <td>0.232071</td>\n",
       "      <td>1.041605</td>\n",
       "      <td>0.902932</td>\n",
       "      <td>0.923106</td>\n",
       "      <td>-1.479170</td>\n",
       "      <td>-0.725972</td>\n",
       "      <td>0.561737</td>\n",
       "      <td>1.005341</td>\n",
       "      <td>0.631400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656740</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.344238</td>\n",
       "      <td>-0.614887</td>\n",
       "      <td>0.347417</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.130942</td>\n",
       "      <td>3.000866</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0014</th>\n",
       "      <td>-0.491357</td>\n",
       "      <td>-0.208702</td>\n",
       "      <td>-0.949570</td>\n",
       "      <td>-0.080523</td>\n",
       "      <td>0.650120</td>\n",
       "      <td>-0.477062</td>\n",
       "      <td>0.117402</td>\n",
       "      <td>-0.177543</td>\n",
       "      <td>-0.005107</td>\n",
       "      <td>0.238695</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.623604</td>\n",
       "      <td>0.379853</td>\n",
       "      <td>0.394208</td>\n",
       "      <td>0.644572</td>\n",
       "      <td>0.454151</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.281494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0006</th>\n",
       "      <td>1.007862</td>\n",
       "      <td>0.051293</td>\n",
       "      <td>0.647164</td>\n",
       "      <td>-0.520091</td>\n",
       "      <td>0.337481</td>\n",
       "      <td>1.187124</td>\n",
       "      <td>0.750467</td>\n",
       "      <td>-0.115304</td>\n",
       "      <td>-0.631415</td>\n",
       "      <td>-0.789085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852506</td>\n",
       "      <td>1.126368</td>\n",
       "      <td>0.267152</td>\n",
       "      <td>0.448367</td>\n",
       "      <td>-0.559285</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.912924</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.014469</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0008</th>\n",
       "      <td>-0.063484</td>\n",
       "      <td>0.604704</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>0.157058</td>\n",
       "      <td>0.784126</td>\n",
       "      <td>0.523687</td>\n",
       "      <td>0.705062</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.650657</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690349</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.357423</td>\n",
       "      <td>0.598058</td>\n",
       "      <td>1.032206</td>\n",
       "      <td>-0.156499</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.711918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0132</th>\n",
       "      <td>-0.379078</td>\n",
       "      <td>-0.063351</td>\n",
       "      <td>-0.422360</td>\n",
       "      <td>-1.034857</td>\n",
       "      <td>-0.855160</td>\n",
       "      <td>0.566042</td>\n",
       "      <td>-0.034787</td>\n",
       "      <td>-0.017356</td>\n",
       "      <td>-0.152592</td>\n",
       "      <td>-1.035450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712918</td>\n",
       "      <td>1.102537</td>\n",
       "      <td>0.679585</td>\n",
       "      <td>0.828777</td>\n",
       "      <td>-0.162848</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.291017</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.054538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0012</th>\n",
       "      <td>-1.521997</td>\n",
       "      <td>0.067175</td>\n",
       "      <td>-0.349465</td>\n",
       "      <td>-1.227161</td>\n",
       "      <td>-1.159223</td>\n",
       "      <td>0.147176</td>\n",
       "      <td>0.480327</td>\n",
       "      <td>-1.637841</td>\n",
       "      <td>-1.043687</td>\n",
       "      <td>-0.477915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.323493</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>-0.492980</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-4.368677</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.423462</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0015</th>\n",
       "      <td>-1.501659</td>\n",
       "      <td>-0.015775</td>\n",
       "      <td>-2.043978</td>\n",
       "      <td>-1.415894</td>\n",
       "      <td>-0.616190</td>\n",
       "      <td>-1.331602</td>\n",
       "      <td>-1.422446</td>\n",
       "      <td>-1.490010</td>\n",
       "      <td>-1.171014</td>\n",
       "      <td>-0.957152</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.174205</td>\n",
       "      <td>0.032423</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.143522</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.608102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0087</th>\n",
       "      <td>0.262581</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>0.801761</td>\n",
       "      <td>0.796105</td>\n",
       "      <td>0.392620</td>\n",
       "      <td>-0.952609</td>\n",
       "      <td>0.115493</td>\n",
       "      <td>0.295912</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.749829</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.797906</td>\n",
       "      <td>0.189569</td>\n",
       "      <td>-1.457010</td>\n",
       "      <td>0.273234</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>0.341713</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.079904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0050</th>\n",
       "      <td>1.048922</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>1.692505</td>\n",
       "      <td>1.645615</td>\n",
       "      <td>0.750238</td>\n",
       "      <td>-0.066897</td>\n",
       "      <td>-0.130413</td>\n",
       "      <td>1.106432</td>\n",
       "      <td>1.015931</td>\n",
       "      <td>1.764417</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.216004</td>\n",
       "      <td>0.990117</td>\n",
       "      <td>-0.753045</td>\n",
       "      <td>0.618545</td>\n",
       "      <td>1.050514</td>\n",
       "      <td>0.563625</td>\n",
       "      <td>2.764119</td>\n",
       "      <td>1.325121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0657</th>\n",
       "      <td>-0.064258</td>\n",
       "      <td>0.172921</td>\n",
       "      <td>0.519725</td>\n",
       "      <td>-0.133270</td>\n",
       "      <td>-0.175916</td>\n",
       "      <td>1.377655</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.458264</td>\n",
       "      <td>-0.163786</td>\n",
       "      <td>-0.114812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526197</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.282419</td>\n",
       "      <td>-0.833780</td>\n",
       "      <td>-0.073411</td>\n",
       "      <td>0.835596</td>\n",
       "      <td>0.287229</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.182819</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 21862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "C_0083  0.388913  0.232071  1.041605  0.902932  0.923106 -1.479170 -0.725972   \n",
       "P_0014 -0.491357 -0.208702 -0.949570 -0.080523  0.650120 -0.477062  0.117402   \n",
       "H_0006  1.007862  0.051293  0.647164 -0.520091  0.337481  1.187124  0.750467   \n",
       "C_0008 -0.063484  0.604704 -0.010074  0.157058  0.784126  0.523687  0.705062   \n",
       "P_0132 -0.379078 -0.063351 -0.422360 -1.034857 -0.855160  0.566042 -0.034787   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "H_0012 -1.521997  0.067175 -0.349465 -1.227161 -1.159223  0.147176  0.480327   \n",
       "P_0015 -1.501659 -0.015775 -2.043978 -1.415894 -0.616190 -1.331602 -1.422446   \n",
       "C_0087  0.262581  0.557800  0.801761  0.796105  0.392620 -0.952609  0.115493   \n",
       "C_0050  1.048922  0.577184  1.692505  1.645615  0.750238 -0.066897 -0.130413   \n",
       "H_0657 -0.064258  0.172921  0.519725 -0.133270 -0.175916  1.377655  0.786557   \n",
       "\n",
       "               7         8         9  ...     21854     21855     21856  \\\n",
       "C_0083  0.561737  1.005341  0.631400  ...  0.656740 -1.029937  0.344238   \n",
       "P_0014 -0.177543 -0.005107  0.238695  ... -1.270403 -1.029937 -0.623604   \n",
       "H_0006 -0.115304 -0.631415 -0.789085  ...  0.852506  1.126368  0.267152   \n",
       "C_0008  0.107073  0.650657  0.591910  ...  0.690349 -1.029937 -0.004865   \n",
       "P_0132 -0.017356 -0.152592 -1.035450  ...  0.712918  1.102537  0.679585   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "H_0012 -1.637841 -1.043687 -0.477915  ...  0.782275 -1.029937 -1.323493   \n",
       "P_0015 -1.490010 -1.171014 -0.957152  ... -1.270403 -1.029937 -1.174205   \n",
       "C_0087  0.295912  0.798726  0.749829  ... -1.270403  0.797906  0.189569   \n",
       "C_0050  1.106432  1.015931  1.764417  ... -1.270403  1.216004  0.990117   \n",
       "H_0657  0.458264 -0.163786 -0.114812  ...  0.526197 -1.029937  0.282419   \n",
       "\n",
       "           21857     21858     21859     21860     21861     21862  cluster  \n",
       "C_0083 -0.614887  0.347417 -1.220236  0.130942  3.000866  0.672039        1  \n",
       "P_0014  0.379853  0.394208  0.644572  0.454151 -0.349492 -1.281494        0  \n",
       "H_0006  0.448367 -0.559285 -1.220236  0.912924 -0.349492  1.014469        2  \n",
       "C_0008  0.357423  0.598058  1.032206 -0.156499 -0.349492 -0.711918        1  \n",
       "P_0132  0.828777 -0.162848 -1.220236  0.291017 -0.349492 -1.054538        0  \n",
       "...          ...       ...       ...       ...       ...       ...      ...  \n",
       "H_0012 -0.181305 -0.492980 -1.220236 -4.368677 -0.349492 -1.423462        2  \n",
       "P_0015  0.032423  0.012057 -1.220236 -0.143522 -0.349492 -1.608102        0  \n",
       "C_0087 -1.457010  0.273234  0.680197  0.341713 -0.349492  1.079904        1  \n",
       "C_0050 -0.753045  0.618545  1.050514  0.563625  2.764119  1.325121        1  \n",
       "H_0657 -0.833780 -0.073411  0.835596  0.287229 -0.349492  0.182819        2  \n",
       "\n",
       "[102 rows x 21862 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "773aa701-e61f-43ec-9ba9-12e0c23ff7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_0063</th>\n",
       "      <td>-0.354154</td>\n",
       "      <td>-0.443490</td>\n",
       "      <td>-0.519781</td>\n",
       "      <td>-0.938225</td>\n",
       "      <td>-0.692398</td>\n",
       "      <td>-1.225452</td>\n",
       "      <td>-0.567080</td>\n",
       "      <td>-0.929789</td>\n",
       "      <td>-0.391042</td>\n",
       "      <td>-0.918295</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.770840</td>\n",
       "      <td>-0.650630</td>\n",
       "      <td>0.148355</td>\n",
       "      <td>-0.417226</td>\n",
       "      <td>0.656224</td>\n",
       "      <td>-1.557539</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.420660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0029</th>\n",
       "      <td>-0.495266</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>-1.553595</td>\n",
       "      <td>-1.080348</td>\n",
       "      <td>-0.552315</td>\n",
       "      <td>1.010324</td>\n",
       "      <td>-0.309374</td>\n",
       "      <td>-1.022790</td>\n",
       "      <td>-0.761766</td>\n",
       "      <td>-0.485853</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.033890</td>\n",
       "      <td>-0.783647</td>\n",
       "      <td>-0.293198</td>\n",
       "      <td>0.669075</td>\n",
       "      <td>-0.153178</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.354232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0010</th>\n",
       "      <td>0.947469</td>\n",
       "      <td>0.610187</td>\n",
       "      <td>1.167948</td>\n",
       "      <td>1.184255</td>\n",
       "      <td>0.972135</td>\n",
       "      <td>0.467329</td>\n",
       "      <td>1.196569</td>\n",
       "      <td>0.468982</td>\n",
       "      <td>0.605396</td>\n",
       "      <td>0.755573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936328</td>\n",
       "      <td>1.164238</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>-0.605207</td>\n",
       "      <td>0.286310</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.613593</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.488160</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0025</th>\n",
       "      <td>-0.525737</td>\n",
       "      <td>0.242389</td>\n",
       "      <td>0.106966</td>\n",
       "      <td>0.424007</td>\n",
       "      <td>0.286912</td>\n",
       "      <td>-0.878035</td>\n",
       "      <td>-1.127625</td>\n",
       "      <td>0.521370</td>\n",
       "      <td>0.787054</td>\n",
       "      <td>0.509760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740892</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.404844</td>\n",
       "      <td>-0.157597</td>\n",
       "      <td>0.652556</td>\n",
       "      <td>1.144599</td>\n",
       "      <td>0.312478</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.480518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0070</th>\n",
       "      <td>-1.309004</td>\n",
       "      <td>0.213414</td>\n",
       "      <td>-0.418802</td>\n",
       "      <td>-1.097679</td>\n",
       "      <td>-1.892068</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>-1.458774</td>\n",
       "      <td>-2.380129</td>\n",
       "      <td>-1.965949</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-2.301812</td>\n",
       "      <td>-1.832232</td>\n",
       "      <td>-0.425255</td>\n",
       "      <td>0.830336</td>\n",
       "      <td>-1.228546</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.297272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0039</th>\n",
       "      <td>0.076393</td>\n",
       "      <td>0.369525</td>\n",
       "      <td>0.262198</td>\n",
       "      <td>-0.434926</td>\n",
       "      <td>-0.641064</td>\n",
       "      <td>-0.367527</td>\n",
       "      <td>-0.258453</td>\n",
       "      <td>-0.416765</td>\n",
       "      <td>-0.246040</td>\n",
       "      <td>-0.748481</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.039146</td>\n",
       "      <td>0.081579</td>\n",
       "      <td>-1.086837</td>\n",
       "      <td>-0.351680</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.517124</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.052990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "P_0063 -0.354154 -0.443490 -0.519781 -0.938225 -0.692398 -1.225452 -0.567080   \n",
       "P_0029 -0.495266  0.082892 -1.553595 -1.080348 -0.552315  1.010324 -0.309374   \n",
       "H_0010  0.947469  0.610187  1.167948  1.184255  0.972135  0.467329  1.196569   \n",
       "C_0025 -0.525737  0.242389  0.106966  0.424007  0.286912 -0.878035 -1.127625   \n",
       "C_0070 -1.309004  0.213414 -0.418802 -1.097679 -1.892068  0.063291  0.524590   \n",
       "C_0039  0.076393  0.369525  0.262198 -0.434926 -0.641064 -0.367527 -0.258453   \n",
       "\n",
       "               7         8         9  ...     21854     21855     21856  \\\n",
       "P_0063 -0.929789 -0.391042 -0.918295  ... -1.270403  0.770840 -0.650630   \n",
       "P_0029 -1.022790 -0.761766 -0.485853  ... -1.270403 -1.029937 -1.033890   \n",
       "H_0010  0.468982  0.605396  0.755573  ...  0.936328  1.164238  0.185686   \n",
       "C_0025  0.521370  0.787054  0.509760  ...  0.740892 -1.029937  0.404844   \n",
       "C_0070 -1.458774 -2.380129 -1.965949  ... -1.270403 -1.029937 -2.301812   \n",
       "C_0039 -0.416765 -0.246040 -0.748481  ... -1.270403  1.039146  0.081579   \n",
       "\n",
       "           21857     21858     21859     21860     21861     21862  cluster  \n",
       "P_0063  0.148355 -0.417226  0.656224 -1.557539 -0.349492 -1.420660        0  \n",
       "P_0029 -0.783647 -0.293198  0.669075 -0.153178 -0.349492  0.354232        0  \n",
       "H_0010 -0.605207  0.286310 -1.220236  0.613593 -0.349492  1.488160        2  \n",
       "C_0025 -0.157597  0.652556  1.144599  0.312478 -0.349492  0.480518        1  \n",
       "C_0070 -1.832232 -0.425255  0.830336 -1.228546 -0.349492 -0.297272        1  \n",
       "C_0039 -1.086837 -0.351680 -1.220236  0.517124 -0.349492 -1.052990        1  \n",
       "\n",
       "[6 rows x 21862 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b24a278-4b08-4332-8815-006f4a26629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0083</th>\n",
       "      <td>0.388913</td>\n",
       "      <td>0.232071</td>\n",
       "      <td>1.041605</td>\n",
       "      <td>0.902932</td>\n",
       "      <td>0.923106</td>\n",
       "      <td>-1.479170</td>\n",
       "      <td>-0.725972</td>\n",
       "      <td>0.561737</td>\n",
       "      <td>1.005341</td>\n",
       "      <td>0.631400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753887</td>\n",
       "      <td>0.656740</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.344238</td>\n",
       "      <td>-0.614887</td>\n",
       "      <td>0.347417</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.130942</td>\n",
       "      <td>3.000866</td>\n",
       "      <td>0.672039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0031</th>\n",
       "      <td>0.599252</td>\n",
       "      <td>0.517350</td>\n",
       "      <td>-0.696765</td>\n",
       "      <td>-0.421019</td>\n",
       "      <td>0.050207</td>\n",
       "      <td>1.220664</td>\n",
       "      <td>1.151044</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>-1.110864</td>\n",
       "      <td>-0.437187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183169</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.097530</td>\n",
       "      <td>0.200089</td>\n",
       "      <td>0.739144</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.232364</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.365384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0006</th>\n",
       "      <td>1.007862</td>\n",
       "      <td>0.051293</td>\n",
       "      <td>0.647164</td>\n",
       "      <td>-0.520091</td>\n",
       "      <td>0.337481</td>\n",
       "      <td>1.187124</td>\n",
       "      <td>0.750467</td>\n",
       "      <td>-0.115304</td>\n",
       "      <td>-0.631415</td>\n",
       "      <td>-0.789085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340969</td>\n",
       "      <td>0.852506</td>\n",
       "      <td>1.126368</td>\n",
       "      <td>0.267152</td>\n",
       "      <td>0.448367</td>\n",
       "      <td>-0.559285</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.912924</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.014469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0008</th>\n",
       "      <td>-0.063484</td>\n",
       "      <td>0.604704</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>0.157058</td>\n",
       "      <td>0.784126</td>\n",
       "      <td>0.523687</td>\n",
       "      <td>0.705062</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.650657</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626894</td>\n",
       "      <td>0.690349</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.357423</td>\n",
       "      <td>0.598058</td>\n",
       "      <td>1.032206</td>\n",
       "      <td>-0.156499</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.711918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0050</th>\n",
       "      <td>1.048922</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>1.692505</td>\n",
       "      <td>1.645615</td>\n",
       "      <td>0.750238</td>\n",
       "      <td>-0.066897</td>\n",
       "      <td>-0.130413</td>\n",
       "      <td>1.106432</td>\n",
       "      <td>1.015931</td>\n",
       "      <td>1.764417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333553</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.216004</td>\n",
       "      <td>0.990117</td>\n",
       "      <td>-0.753045</td>\n",
       "      <td>0.618545</td>\n",
       "      <td>1.050514</td>\n",
       "      <td>0.563625</td>\n",
       "      <td>2.764119</td>\n",
       "      <td>1.325121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0032</th>\n",
       "      <td>1.363014</td>\n",
       "      <td>0.852724</td>\n",
       "      <td>1.620287</td>\n",
       "      <td>1.712404</td>\n",
       "      <td>1.276279</td>\n",
       "      <td>0.174185</td>\n",
       "      <td>0.437325</td>\n",
       "      <td>1.204032</td>\n",
       "      <td>1.578419</td>\n",
       "      <td>1.610603</td>\n",
       "      <td>...</td>\n",
       "      <td>1.564273</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.916243</td>\n",
       "      <td>1.594664</td>\n",
       "      <td>-1.017494</td>\n",
       "      <td>0.866281</td>\n",
       "      <td>1.040314</td>\n",
       "      <td>0.346796</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.727455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0010</th>\n",
       "      <td>0.947469</td>\n",
       "      <td>0.610187</td>\n",
       "      <td>1.167948</td>\n",
       "      <td>1.184255</td>\n",
       "      <td>0.972135</td>\n",
       "      <td>0.467329</td>\n",
       "      <td>1.196569</td>\n",
       "      <td>0.468982</td>\n",
       "      <td>0.605396</td>\n",
       "      <td>0.755573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017267</td>\n",
       "      <td>0.936328</td>\n",
       "      <td>1.164238</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>-0.605207</td>\n",
       "      <td>0.286310</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.613593</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.488160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0025</th>\n",
       "      <td>-0.525737</td>\n",
       "      <td>0.242389</td>\n",
       "      <td>0.106966</td>\n",
       "      <td>0.424007</td>\n",
       "      <td>0.286912</td>\n",
       "      <td>-0.878035</td>\n",
       "      <td>-1.127625</td>\n",
       "      <td>0.521370</td>\n",
       "      <td>0.787054</td>\n",
       "      <td>0.509760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186735</td>\n",
       "      <td>0.740892</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.404844</td>\n",
       "      <td>-0.157597</td>\n",
       "      <td>0.652556</td>\n",
       "      <td>1.144599</td>\n",
       "      <td>0.312478</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.480518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0022</th>\n",
       "      <td>-0.372896</td>\n",
       "      <td>-2.842400</td>\n",
       "      <td>-2.025715</td>\n",
       "      <td>-0.957543</td>\n",
       "      <td>-0.276603</td>\n",
       "      <td>1.231127</td>\n",
       "      <td>0.169027</td>\n",
       "      <td>-1.040032</td>\n",
       "      <td>-1.269776</td>\n",
       "      <td>-0.650172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301786</td>\n",
       "      <td>0.794579</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.312170</td>\n",
       "      <td>0.494377</td>\n",
       "      <td>0.513989</td>\n",
       "      <td>0.740662</td>\n",
       "      <td>0.299541</td>\n",
       "      <td>2.420545</td>\n",
       "      <td>-0.750476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0019</th>\n",
       "      <td>0.227191</td>\n",
       "      <td>0.644707</td>\n",
       "      <td>-0.409169</td>\n",
       "      <td>0.224370</td>\n",
       "      <td>-0.221557</td>\n",
       "      <td>1.787151</td>\n",
       "      <td>-1.057262</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.293454</td>\n",
       "      <td>0.427701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466960</td>\n",
       "      <td>0.924762</td>\n",
       "      <td>1.042216</td>\n",
       "      <td>-0.079025</td>\n",
       "      <td>0.774095</td>\n",
       "      <td>0.323501</td>\n",
       "      <td>0.735508</td>\n",
       "      <td>-0.219296</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.428749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 21861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "C_0083  0.388913  0.232071  1.041605  0.902932  0.923106 -1.479170 -0.725972   \n",
       "P_0031  0.599252  0.517350 -0.696765 -0.421019  0.050207  1.220664  1.151044   \n",
       "H_0006  1.007862  0.051293  0.647164 -0.520091  0.337481  1.187124  0.750467   \n",
       "C_0008 -0.063484  0.604704 -0.010074  0.157058  0.784126  0.523687  0.705062   \n",
       "C_0050  1.048922  0.577184  1.692505  1.645615  0.750238 -0.066897 -0.130413   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "C_0032  1.363014  0.852724  1.620287  1.712404  1.276279  0.174185  0.437325   \n",
       "H_0010  0.947469  0.610187  1.167948  1.184255  0.972135  0.467329  1.196569   \n",
       "C_0025 -0.525737  0.242389  0.106966  0.424007  0.286912 -0.878035 -1.127625   \n",
       "P_0022 -0.372896 -2.842400 -2.025715 -0.957543 -0.276603  1.231127  0.169027   \n",
       "P_0019  0.227191  0.644707 -0.409169  0.224370 -0.221557  1.787151 -1.057262   \n",
       "\n",
       "           7         8         9      ...     21853     21854     21855  \\\n",
       "C_0083  0.561737  1.005341  0.631400  ...  0.753887  0.656740 -1.029937   \n",
       "P_0031  0.018565 -1.110864 -0.437187  ... -0.183169 -1.270403  1.097530   \n",
       "H_0006 -0.115304 -0.631415 -0.789085  ... -0.340969  0.852506  1.126368   \n",
       "C_0008  0.107073  0.650657  0.591910  ...  0.626894  0.690349 -1.029937   \n",
       "C_0050  1.106432  1.015931  1.764417  ...  1.333553 -1.270403  1.216004   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "C_0032  1.204032  1.578419  1.610603  ...  1.564273 -1.270403  0.916243   \n",
       "H_0010  0.468982  0.605396  0.755573  ...  1.017267  0.936328  1.164238   \n",
       "C_0025  0.521370  0.787054  0.509760  ... -0.186735  0.740892 -1.029937   \n",
       "P_0022 -1.040032 -1.269776 -0.650172  ... -0.301786  0.794579 -1.029937   \n",
       "P_0019  0.802575  0.293454  0.427701  ...  0.466960  0.924762  1.042216   \n",
       "\n",
       "           21856     21857     21858     21859     21860     21861     21862  \n",
       "C_0083  0.344238 -0.614887  0.347417 -1.220236  0.130942  3.000866  0.672039  \n",
       "P_0031  0.200089  0.739144  0.427200  0.690276  0.232364 -0.349492  0.365384  \n",
       "H_0006  0.267152  0.448367 -0.559285 -1.220236  0.912924 -0.349492  1.014469  \n",
       "C_0008 -0.004865  0.357423  0.598058  1.032206 -0.156499 -0.349492 -0.711918  \n",
       "C_0050  0.990117 -0.753045  0.618545  1.050514  0.563625  2.764119  1.325121  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "C_0032  1.594664 -1.017494  0.866281  1.040314  0.346796 -0.349492  0.727455  \n",
       "H_0010  0.185686 -0.605207  0.286310 -1.220236  0.613593 -0.349492  1.488160  \n",
       "C_0025  0.404844 -0.157597  0.652556  1.144599  0.312478 -0.349492  0.480518  \n",
       "P_0022 -1.312170  0.494377  0.513989  0.740662  0.299541  2.420545 -0.750476  \n",
       "P_0019 -0.079025  0.774095  0.323501  0.735508 -0.219296 -0.349492  0.428749  \n",
       "\n",
       "[108 rows x 21861 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_AE_learning = pd.concat([X_train_del2, X_test_del2], axis=0, ignore_index=False)\n",
    "df_for_AE_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a6e0d23-f8e6-4305-9b62-a04fe2d2347e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 1, 2, 1, 0, 0, 0, 2, 1, 2, 0, 1,\n",
       "       0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1,\n",
       "       2, 0, 1, 1, 2, 0, 1, 1, 0, 2, 1, 1, 2, 2, 0, 1, 2, 2, 0, 0, 0, 2,\n",
       "       1, 0, 1, 2, 0, 2, 1, 0, 1, 2, 1, 1, 2, 1, 2, 2, 1, 0, 1, 2, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_num_all = np.concatenate((train_patient_num, test_patient_num), axis = 0)\n",
    "patient_num_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07edc821-50a2-44dd-b6e3-88697267f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corre_plot(X_train, X_train_pred, X_test, X_test_pred):\n",
    "    x=np.linspace(-2,10)\n",
    "    y=x\n",
    "    plt.figure(constrained_layout=True)\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title('train correlation')\n",
    "    plt.scatter(X_train,X_train_pred,alpha=0.02,s=1)\n",
    "    plt.plot(x,y,color='green')\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.title('test correlation')\n",
    "    plt.scatter(X_test,X_test_pred,alpha=0.02,s=1)\n",
    "    plt.plot(x,y,color='green')\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.title('train correlation narrow')\n",
    "    plt.scatter(X_train,X_train_pred,alpha=0.02,s=1,c='black')\n",
    "    plt.xlim(-3,3)\n",
    "    plt.ylim(-3,3)\n",
    "    plt.plot(x,y,color='green')\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.title('test correlation narrow')\n",
    "    plt.scatter(X_test,X_test_pred,alpha=0.02,s=1,c='black')\n",
    "    plt.xlim(-3,3)\n",
    "    plt.ylim(-3,3)\n",
    "    plt.plot(x,y,color='green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b70d549-a444-4d9f-9ed1-85bd28b446d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(history):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','eval'], loc='upper right')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.plot(history.history['val_categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','eval'],loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35941254-ed2d-45a6-b4ed-850a6fcdda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(df): \n",
    "    n_features = len(df)\n",
    "    df_plot = df.sort_values('importance')\n",
    "    f_importance_plot = df_plot['importance'].values\n",
    "    plt.barh(range(n_features), f_importance_plot, align='center')\n",
    "    cols_plot = df_plot['feature'].values             \n",
    "    plt.yticks(np.arange(n_features), cols_plot)      \n",
    "    plt.xlabel('Feature importance')                  \n",
    "    plt.ylabel('Feature') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2593e5dc-656e-4d4a-9e37-d9e3f74c8859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 18:12:15.698465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import BatchNormalization, Input, Lambda\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f853d8c6-d5ea-4738-8bc9-75a17aa82c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') memory growth: True\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU') memory growth: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 18:12:16.855108: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-06-03 18:12:16.856175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-06-03 18:12:16.907419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.908258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2025-06-03 18:12:16.908480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.909261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:05:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2025-06-03 18:12:16.909494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.909878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GT 710 computeCapability: 3.5\n",
      "coreClock: 0.954GHz coreCount: 1 deviceMemorySize: 978.25MiB deviceMemoryBandwidth: 11.92GiB/s\n",
      "2025-06-03 18:12:16.909933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-06-03 18:12:16.911837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-06-03 18:12:16.911965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-06-03 18:12:16.945834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-06-03 18:12:16.946444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-06-03 18:12:16.948197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-06-03 18:12:16.949142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-06-03 18:12:16.952940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-06-03 18:12:16.953214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.954211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.955087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.955585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.956564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.957529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:16.958108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1847] Ignoring visible gpu device (device: 2, name: NVIDIA GeForce GT 710, pci bus id: 0000:01:00.0, compute capability: 3.5) with core count: 1. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2025-06-03 18:12:16.958134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        tf.config.set_soft_device_placement(True)\n",
    "        growth = tf.config.experimental.get_memory_growth(device)\n",
    "        print('{} memory growth: {}'.format(device, growth))\n",
    "else:\n",
    "    print(\"Not enough GPU hardware devices available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "435f2df7-e0b3-438c-a381-3daf44205f4e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 18:12:16.972927: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-03 18:12:16.973923: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-06-03 18:12:17.097338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.098091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2025-06-03 18:12:17.098174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.099103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:05:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2025-06-03 18:12:17.099158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-06-03 18:12:17.099195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-06-03 18:12:17.099228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-06-03 18:12:17.099261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-06-03 18:12:17.099295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-06-03 18:12:17.099329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-06-03 18:12:17.099363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-06-03 18:12:17.099399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-06-03 18:12:17.099500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.100236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.100959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.101687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.102357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2025-06-03 18:12:17.102428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-06-03 18:12:17.782023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-06-03 18:12:17.782084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2025-06-03 18:12:17.782101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2025-06-03 18:12:17.782115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2025-06-03 18:12:17.782468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.783424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.784387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.785297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.786167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10623 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)\n",
      "2025-06-03 18:12:17.786691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.787615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-03 18:12:17.788453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10623 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_914 (Dense)            (None, 100)               2186200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_693 (Bat (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_915 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_694 (Bat (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_916 (Dense)            (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "batch_normalization_695 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_917 (Dense)            (None, 100)               2100      \n",
      "_________________________________________________________________\n",
      "batch_normalization_696 (Bat (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_918 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_697 (Bat (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_919 (Dense)            (None, 21861)             2207961   \n",
      "=================================================================\n",
      "Total params: 4,420,161\n",
      "Trainable params: 4,419,321\n",
      "Non-trainable params: 840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"model20_11_20dim.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d35e1573-5934-4d3a-8172-443635844b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = X_train.iloc[:, :-1]\n",
    "df_test = X_test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1f64a44-cc92-4c3c-9208-0e0a02aa1c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_0083</th>\n",
       "      <td>0.388913</td>\n",
       "      <td>0.232071</td>\n",
       "      <td>1.041605</td>\n",
       "      <td>0.902932</td>\n",
       "      <td>0.923106</td>\n",
       "      <td>-1.479170</td>\n",
       "      <td>-0.725972</td>\n",
       "      <td>0.561737</td>\n",
       "      <td>1.005341</td>\n",
       "      <td>0.631400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753887</td>\n",
       "      <td>0.656740</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.344238</td>\n",
       "      <td>-0.614887</td>\n",
       "      <td>0.347417</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.130942</td>\n",
       "      <td>3.000866</td>\n",
       "      <td>0.672039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0014</th>\n",
       "      <td>-0.491357</td>\n",
       "      <td>-0.208702</td>\n",
       "      <td>-0.949570</td>\n",
       "      <td>-0.080523</td>\n",
       "      <td>0.650120</td>\n",
       "      <td>-0.477062</td>\n",
       "      <td>0.117402</td>\n",
       "      <td>-0.177543</td>\n",
       "      <td>-0.005107</td>\n",
       "      <td>0.238695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227848</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.623604</td>\n",
       "      <td>0.379853</td>\n",
       "      <td>0.394208</td>\n",
       "      <td>0.644572</td>\n",
       "      <td>0.454151</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.281494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0006</th>\n",
       "      <td>1.007862</td>\n",
       "      <td>0.051293</td>\n",
       "      <td>0.647164</td>\n",
       "      <td>-0.520091</td>\n",
       "      <td>0.337481</td>\n",
       "      <td>1.187124</td>\n",
       "      <td>0.750467</td>\n",
       "      <td>-0.115304</td>\n",
       "      <td>-0.631415</td>\n",
       "      <td>-0.789085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340969</td>\n",
       "      <td>0.852506</td>\n",
       "      <td>1.126368</td>\n",
       "      <td>0.267152</td>\n",
       "      <td>0.448367</td>\n",
       "      <td>-0.559285</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.912924</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.014469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0008</th>\n",
       "      <td>-0.063484</td>\n",
       "      <td>0.604704</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>0.157058</td>\n",
       "      <td>0.784126</td>\n",
       "      <td>0.523687</td>\n",
       "      <td>0.705062</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.650657</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626894</td>\n",
       "      <td>0.690349</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.357423</td>\n",
       "      <td>0.598058</td>\n",
       "      <td>1.032206</td>\n",
       "      <td>-0.156499</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.711918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0132</th>\n",
       "      <td>-0.379078</td>\n",
       "      <td>-0.063351</td>\n",
       "      <td>-0.422360</td>\n",
       "      <td>-1.034857</td>\n",
       "      <td>-0.855160</td>\n",
       "      <td>0.566042</td>\n",
       "      <td>-0.034787</td>\n",
       "      <td>-0.017356</td>\n",
       "      <td>-0.152592</td>\n",
       "      <td>-1.035450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.987399</td>\n",
       "      <td>0.712918</td>\n",
       "      <td>1.102537</td>\n",
       "      <td>0.679585</td>\n",
       "      <td>0.828777</td>\n",
       "      <td>-0.162848</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.291017</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.054538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0012</th>\n",
       "      <td>-1.521997</td>\n",
       "      <td>0.067175</td>\n",
       "      <td>-0.349465</td>\n",
       "      <td>-1.227161</td>\n",
       "      <td>-1.159223</td>\n",
       "      <td>0.147176</td>\n",
       "      <td>0.480327</td>\n",
       "      <td>-1.637841</td>\n",
       "      <td>-1.043687</td>\n",
       "      <td>-0.477915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128161</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.323493</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>-0.492980</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-4.368677</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.423462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0015</th>\n",
       "      <td>-1.501659</td>\n",
       "      <td>-0.015775</td>\n",
       "      <td>-2.043978</td>\n",
       "      <td>-1.415894</td>\n",
       "      <td>-0.616190</td>\n",
       "      <td>-1.331602</td>\n",
       "      <td>-1.422446</td>\n",
       "      <td>-1.490010</td>\n",
       "      <td>-1.171014</td>\n",
       "      <td>-0.957152</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.225591</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.174205</td>\n",
       "      <td>0.032423</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>-0.143522</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.608102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0087</th>\n",
       "      <td>0.262581</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>0.801761</td>\n",
       "      <td>0.796105</td>\n",
       "      <td>0.392620</td>\n",
       "      <td>-0.952609</td>\n",
       "      <td>0.115493</td>\n",
       "      <td>0.295912</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.749829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412925</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.797906</td>\n",
       "      <td>0.189569</td>\n",
       "      <td>-1.457010</td>\n",
       "      <td>0.273234</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>0.341713</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.079904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0050</th>\n",
       "      <td>1.048922</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>1.692505</td>\n",
       "      <td>1.645615</td>\n",
       "      <td>0.750238</td>\n",
       "      <td>-0.066897</td>\n",
       "      <td>-0.130413</td>\n",
       "      <td>1.106432</td>\n",
       "      <td>1.015931</td>\n",
       "      <td>1.764417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333553</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.216004</td>\n",
       "      <td>0.990117</td>\n",
       "      <td>-0.753045</td>\n",
       "      <td>0.618545</td>\n",
       "      <td>1.050514</td>\n",
       "      <td>0.563625</td>\n",
       "      <td>2.764119</td>\n",
       "      <td>1.325121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0657</th>\n",
       "      <td>-0.064258</td>\n",
       "      <td>0.172921</td>\n",
       "      <td>0.519725</td>\n",
       "      <td>-0.133270</td>\n",
       "      <td>-0.175916</td>\n",
       "      <td>1.377655</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.458264</td>\n",
       "      <td>-0.163786</td>\n",
       "      <td>-0.114812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179268</td>\n",
       "      <td>0.526197</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.282419</td>\n",
       "      <td>-0.833780</td>\n",
       "      <td>-0.073411</td>\n",
       "      <td>0.835596</td>\n",
       "      <td>0.287229</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.182819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 21861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "C_0083  0.388913  0.232071  1.041605  0.902932  0.923106 -1.479170 -0.725972   \n",
       "P_0014 -0.491357 -0.208702 -0.949570 -0.080523  0.650120 -0.477062  0.117402   \n",
       "H_0006  1.007862  0.051293  0.647164 -0.520091  0.337481  1.187124  0.750467   \n",
       "C_0008 -0.063484  0.604704 -0.010074  0.157058  0.784126  0.523687  0.705062   \n",
       "P_0132 -0.379078 -0.063351 -0.422360 -1.034857 -0.855160  0.566042 -0.034787   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "H_0012 -1.521997  0.067175 -0.349465 -1.227161 -1.159223  0.147176  0.480327   \n",
       "P_0015 -1.501659 -0.015775 -2.043978 -1.415894 -0.616190 -1.331602 -1.422446   \n",
       "C_0087  0.262581  0.557800  0.801761  0.796105  0.392620 -0.952609  0.115493   \n",
       "C_0050  1.048922  0.577184  1.692505  1.645615  0.750238 -0.066897 -0.130413   \n",
       "H_0657 -0.064258  0.172921  0.519725 -0.133270 -0.175916  1.377655  0.786557   \n",
       "\n",
       "           7         8         9      ...     21853     21854     21855  \\\n",
       "C_0083  0.561737  1.005341  0.631400  ...  0.753887  0.656740 -1.029937   \n",
       "P_0014 -0.177543 -0.005107  0.238695  ... -0.227848 -1.270403 -1.029937   \n",
       "H_0006 -0.115304 -0.631415 -0.789085  ... -0.340969  0.852506  1.126368   \n",
       "C_0008  0.107073  0.650657  0.591910  ...  0.626894  0.690349 -1.029937   \n",
       "P_0132 -0.017356 -0.152592 -1.035450  ... -1.987399  0.712918  1.102537   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "H_0012 -1.637841 -1.043687 -0.477915  ...  0.128161  0.782275 -1.029937   \n",
       "P_0015 -1.490010 -1.171014 -0.957152  ... -1.225591 -1.270403 -1.029937   \n",
       "C_0087  0.295912  0.798726  0.749829  ...  0.412925 -1.270403  0.797906   \n",
       "C_0050  1.106432  1.015931  1.764417  ...  1.333553 -1.270403  1.216004   \n",
       "H_0657  0.458264 -0.163786 -0.114812  ...  0.179268  0.526197 -1.029937   \n",
       "\n",
       "           21856     21857     21858     21859     21860     21861     21862  \n",
       "C_0083  0.344238 -0.614887  0.347417 -1.220236  0.130942  3.000866  0.672039  \n",
       "P_0014 -0.623604  0.379853  0.394208  0.644572  0.454151 -0.349492 -1.281494  \n",
       "H_0006  0.267152  0.448367 -0.559285 -1.220236  0.912924 -0.349492  1.014469  \n",
       "C_0008 -0.004865  0.357423  0.598058  1.032206 -0.156499 -0.349492 -0.711918  \n",
       "P_0132  0.679585  0.828777 -0.162848 -1.220236  0.291017 -0.349492 -1.054538  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "H_0012 -1.323493 -0.181305 -0.492980 -1.220236 -4.368677 -0.349492 -1.423462  \n",
       "P_0015 -1.174205  0.032423  0.012057 -1.220236 -0.143522 -0.349492 -1.608102  \n",
       "C_0087  0.189569 -1.457010  0.273234  0.680197  0.341713 -0.349492  1.079904  \n",
       "C_0050  0.990117 -0.753045  0.618545  1.050514  0.563625  2.764119  1.325121  \n",
       "H_0657  0.282419 -0.833780 -0.073411  0.835596  0.287229 -0.349492  0.182819  \n",
       "\n",
       "[102 rows x 21861 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f2d4c20-9701-4384-8e78-8883e8e02b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21853</th>\n",
       "      <th>21854</th>\n",
       "      <th>21855</th>\n",
       "      <th>21856</th>\n",
       "      <th>21857</th>\n",
       "      <th>21858</th>\n",
       "      <th>21859</th>\n",
       "      <th>21860</th>\n",
       "      <th>21861</th>\n",
       "      <th>21862</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P_0063</th>\n",
       "      <td>-0.354154</td>\n",
       "      <td>-0.443490</td>\n",
       "      <td>-0.519781</td>\n",
       "      <td>-0.938225</td>\n",
       "      <td>-0.692398</td>\n",
       "      <td>-1.225452</td>\n",
       "      <td>-0.567080</td>\n",
       "      <td>-0.929789</td>\n",
       "      <td>-0.391042</td>\n",
       "      <td>-0.918295</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.361050</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>0.770840</td>\n",
       "      <td>-0.650630</td>\n",
       "      <td>0.148355</td>\n",
       "      <td>-0.417226</td>\n",
       "      <td>0.656224</td>\n",
       "      <td>-1.557539</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.420660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_0029</th>\n",
       "      <td>-0.495266</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>-1.553595</td>\n",
       "      <td>-1.080348</td>\n",
       "      <td>-0.552315</td>\n",
       "      <td>1.010324</td>\n",
       "      <td>-0.309374</td>\n",
       "      <td>-1.022790</td>\n",
       "      <td>-0.761766</td>\n",
       "      <td>-0.485853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.872063</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-1.033890</td>\n",
       "      <td>-0.783647</td>\n",
       "      <td>-0.293198</td>\n",
       "      <td>0.669075</td>\n",
       "      <td>-0.153178</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.354232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_0010</th>\n",
       "      <td>0.947469</td>\n",
       "      <td>0.610187</td>\n",
       "      <td>1.167948</td>\n",
       "      <td>1.184255</td>\n",
       "      <td>0.972135</td>\n",
       "      <td>0.467329</td>\n",
       "      <td>1.196569</td>\n",
       "      <td>0.468982</td>\n",
       "      <td>0.605396</td>\n",
       "      <td>0.755573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017267</td>\n",
       "      <td>0.936328</td>\n",
       "      <td>1.164238</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>-0.605207</td>\n",
       "      <td>0.286310</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.613593</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>1.488160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0025</th>\n",
       "      <td>-0.525737</td>\n",
       "      <td>0.242389</td>\n",
       "      <td>0.106966</td>\n",
       "      <td>0.424007</td>\n",
       "      <td>0.286912</td>\n",
       "      <td>-0.878035</td>\n",
       "      <td>-1.127625</td>\n",
       "      <td>0.521370</td>\n",
       "      <td>0.787054</td>\n",
       "      <td>0.509760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186735</td>\n",
       "      <td>0.740892</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>0.404844</td>\n",
       "      <td>-0.157597</td>\n",
       "      <td>0.652556</td>\n",
       "      <td>1.144599</td>\n",
       "      <td>0.312478</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>0.480518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0070</th>\n",
       "      <td>-1.309004</td>\n",
       "      <td>0.213414</td>\n",
       "      <td>-0.418802</td>\n",
       "      <td>-1.097679</td>\n",
       "      <td>-1.892068</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>-1.458774</td>\n",
       "      <td>-2.380129</td>\n",
       "      <td>-1.965949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788725</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>-1.029937</td>\n",
       "      <td>-2.301812</td>\n",
       "      <td>-1.832232</td>\n",
       "      <td>-0.425255</td>\n",
       "      <td>0.830336</td>\n",
       "      <td>-1.228546</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-0.297272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_0039</th>\n",
       "      <td>0.076393</td>\n",
       "      <td>0.369525</td>\n",
       "      <td>0.262198</td>\n",
       "      <td>-0.434926</td>\n",
       "      <td>-0.641064</td>\n",
       "      <td>-0.367527</td>\n",
       "      <td>-0.258453</td>\n",
       "      <td>-0.416765</td>\n",
       "      <td>-0.246040</td>\n",
       "      <td>-0.748481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543181</td>\n",
       "      <td>-1.270403</td>\n",
       "      <td>1.039146</td>\n",
       "      <td>0.081579</td>\n",
       "      <td>-1.086837</td>\n",
       "      <td>-0.351680</td>\n",
       "      <td>-1.220236</td>\n",
       "      <td>0.517124</td>\n",
       "      <td>-0.349492</td>\n",
       "      <td>-1.052990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6      \\\n",
       "P_0063 -0.354154 -0.443490 -0.519781 -0.938225 -0.692398 -1.225452 -0.567080   \n",
       "P_0029 -0.495266  0.082892 -1.553595 -1.080348 -0.552315  1.010324 -0.309374   \n",
       "H_0010  0.947469  0.610187  1.167948  1.184255  0.972135  0.467329  1.196569   \n",
       "C_0025 -0.525737  0.242389  0.106966  0.424007  0.286912 -0.878035 -1.127625   \n",
       "C_0070 -1.309004  0.213414 -0.418802 -1.097679 -1.892068  0.063291  0.524590   \n",
       "C_0039  0.076393  0.369525  0.262198 -0.434926 -0.641064 -0.367527 -0.258453   \n",
       "\n",
       "           7         8         9      ...     21853     21854     21855  \\\n",
       "P_0063 -0.929789 -0.391042 -0.918295  ... -1.361050 -1.270403  0.770840   \n",
       "P_0029 -1.022790 -0.761766 -0.485853  ... -0.872063 -1.270403 -1.029937   \n",
       "H_0010  0.468982  0.605396  0.755573  ...  1.017267  0.936328  1.164238   \n",
       "C_0025  0.521370  0.787054  0.509760  ... -0.186735  0.740892 -1.029937   \n",
       "C_0070 -1.458774 -2.380129 -1.965949  ... -0.788725 -1.270403 -1.029937   \n",
       "C_0039 -0.416765 -0.246040 -0.748481  ...  0.543181 -1.270403  1.039146   \n",
       "\n",
       "           21856     21857     21858     21859     21860     21861     21862  \n",
       "P_0063 -0.650630  0.148355 -0.417226  0.656224 -1.557539 -0.349492 -1.420660  \n",
       "P_0029 -1.033890 -0.783647 -0.293198  0.669075 -0.153178 -0.349492  0.354232  \n",
       "H_0010  0.185686 -0.605207  0.286310 -1.220236  0.613593 -0.349492  1.488160  \n",
       "C_0025  0.404844 -0.157597  0.652556  1.144599  0.312478 -0.349492  0.480518  \n",
       "C_0070 -2.301812 -1.832232 -0.425255  0.830336 -1.228546 -0.349492 -0.297272  \n",
       "C_0039  0.081579 -1.086837 -0.351680 -1.220236  0.517124 -0.349492 -1.052990  \n",
       "\n",
       "[6 rows x 21861 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76ffa81a-77f9-42b2-a6f0-d5655ccea83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 18:12:18.257800: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-06-03 18:12:18.258415: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3491720000 Hz\n",
      "2025-06-03 18:12:18.413727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "pearson's correlation cefficient: 0.9918914483252083\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_all_pred=model.predict(dataX_log_del2,verbose=1)\n",
    "\n",
    "plt.figure(figsize=(2.5,2.5))\n",
    "plt.scatter(dataX_log_del2.to_numpy().reshape(-1),X_all_pred.reshape(-1), s=0.01)\n",
    "plt.plot([-10,10],[-10,10], 'g--',linewidth=1.)\n",
    "plt.title('Autoencoder (10 dimensions)')\n",
    "plt.xlabel('input data')\n",
    "plt.ylabel('output data')\n",
    "print(f\"pearson's correlation cefficient: {np.corrcoef(dataX_log_del2.to_numpy().reshape(-1),X_all_pred.reshape(-1))[0,1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e39a6fbd-f7bf-4675-a0cd-f000c84c9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_coefficient(x, y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    numerator = np.sum((x - x_mean) * (y - y_mean))\n",
    "    denominator = np.sqrt(np.sum((x - x_mean) ** 2) * np.sum((y - y_mean) ** 2))\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa09113f-f22c-499e-839f-fe50af4ca5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9877917766094358\n"
     ]
    }
   ],
   "source": [
    "corr_coef_test = correlation_coefficient(df_test.values, X_test_pred)\n",
    "print(corr_coef_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e942459c-c037-47ce-82c2-ca9d565557ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9920659137328623\n"
     ]
    }
   ],
   "source": [
    "corr_coef_tr = correlation_coefficient(df_train.values, X_train_pred)\n",
    "print(corr_coef_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23a57bbe-b417-45b4-bc2d-ae90845b5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name='dense_916'\n",
    "latent_layer=Model(inputs=model.input, outputs=model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6118bdf9-cf50-40d3-8398-ead4a5033097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "latent_layer_pred_train = latent_layer.predict(df_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6cae01d-55a0-4777-bbb5-f8b239be5e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 20)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_layer_pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc149c53-8a0b-4121-98b1-7eb65d09d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "latent_layer_pred_test=latent_layer.predict(df_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5707eed-0731-4d2a-8221-5c52ee8d086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_layer_pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e39febd-2403-4f86-a562-392b01dbf8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.894204</td>\n",
       "      <td>4.146495</td>\n",
       "      <td>-10.627995</td>\n",
       "      <td>4.333094</td>\n",
       "      <td>-0.211089</td>\n",
       "      <td>-6.648520</td>\n",
       "      <td>-4.280519</td>\n",
       "      <td>-3.815852</td>\n",
       "      <td>-3.777365</td>\n",
       "      <td>-1.499009</td>\n",
       "      <td>-0.625212</td>\n",
       "      <td>-7.137741</td>\n",
       "      <td>-5.564987</td>\n",
       "      <td>1.921789</td>\n",
       "      <td>-6.913729</td>\n",
       "      <td>7.227826</td>\n",
       "      <td>-7.480397</td>\n",
       "      <td>-3.841025</td>\n",
       "      <td>-2.643135</td>\n",
       "      <td>-4.290059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.944945</td>\n",
       "      <td>-4.172675</td>\n",
       "      <td>2.317636</td>\n",
       "      <td>3.224382</td>\n",
       "      <td>2.160191</td>\n",
       "      <td>3.711342</td>\n",
       "      <td>5.053267</td>\n",
       "      <td>-7.703063</td>\n",
       "      <td>8.844687</td>\n",
       "      <td>-1.244160</td>\n",
       "      <td>0.254470</td>\n",
       "      <td>5.201087</td>\n",
       "      <td>-5.925610</td>\n",
       "      <td>4.695848</td>\n",
       "      <td>3.283216</td>\n",
       "      <td>-3.963865</td>\n",
       "      <td>5.261399</td>\n",
       "      <td>-4.708281</td>\n",
       "      <td>2.653075</td>\n",
       "      <td>-5.063646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.588860</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>2.670450</td>\n",
       "      <td>-8.996168</td>\n",
       "      <td>-3.310686</td>\n",
       "      <td>-7.067754</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>10.910929</td>\n",
       "      <td>2.443390</td>\n",
       "      <td>-4.109570</td>\n",
       "      <td>7.296700</td>\n",
       "      <td>6.122800</td>\n",
       "      <td>6.156366</td>\n",
       "      <td>-1.021480</td>\n",
       "      <td>3.269602</td>\n",
       "      <td>2.010873</td>\n",
       "      <td>1.207476</td>\n",
       "      <td>5.214314</td>\n",
       "      <td>6.464255</td>\n",
       "      <td>-2.690952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.072881</td>\n",
       "      <td>-4.657294</td>\n",
       "      <td>-6.835857</td>\n",
       "      <td>9.598818</td>\n",
       "      <td>1.465891</td>\n",
       "      <td>-5.823493</td>\n",
       "      <td>-5.777774</td>\n",
       "      <td>-7.312018</td>\n",
       "      <td>-0.630546</td>\n",
       "      <td>-6.401748</td>\n",
       "      <td>-6.745100</td>\n",
       "      <td>3.504016</td>\n",
       "      <td>4.543265</td>\n",
       "      <td>6.947121</td>\n",
       "      <td>8.620768</td>\n",
       "      <td>0.387783</td>\n",
       "      <td>-1.047444</td>\n",
       "      <td>3.723100</td>\n",
       "      <td>5.218976</td>\n",
       "      <td>4.335200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.568182</td>\n",
       "      <td>9.380668</td>\n",
       "      <td>7.979990</td>\n",
       "      <td>1.130456</td>\n",
       "      <td>5.788285</td>\n",
       "      <td>-3.061255</td>\n",
       "      <td>-3.599283</td>\n",
       "      <td>6.892598</td>\n",
       "      <td>2.539938</td>\n",
       "      <td>2.496101</td>\n",
       "      <td>-4.084094</td>\n",
       "      <td>8.950968</td>\n",
       "      <td>-4.972475</td>\n",
       "      <td>-5.133507</td>\n",
       "      <td>-7.145875</td>\n",
       "      <td>-4.389797</td>\n",
       "      <td>6.115207</td>\n",
       "      <td>-6.742897</td>\n",
       "      <td>5.260499</td>\n",
       "      <td>-5.494330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.891827</td>\n",
       "      <td>2.561099</td>\n",
       "      <td>6.970787</td>\n",
       "      <td>-7.018413</td>\n",
       "      <td>-5.253020</td>\n",
       "      <td>3.758243</td>\n",
       "      <td>3.671204</td>\n",
       "      <td>-10.044440</td>\n",
       "      <td>-7.940752</td>\n",
       "      <td>-0.323961</td>\n",
       "      <td>6.115371</td>\n",
       "      <td>-5.004793</td>\n",
       "      <td>1.852236</td>\n",
       "      <td>5.476236</td>\n",
       "      <td>-3.787934</td>\n",
       "      <td>-4.054970</td>\n",
       "      <td>2.748752</td>\n",
       "      <td>6.475208</td>\n",
       "      <td>0.135383</td>\n",
       "      <td>-7.873878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-7.752234</td>\n",
       "      <td>-4.231459</td>\n",
       "      <td>8.498736</td>\n",
       "      <td>-5.204750</td>\n",
       "      <td>-0.988339</td>\n",
       "      <td>2.461777</td>\n",
       "      <td>-1.641066</td>\n",
       "      <td>-7.762600</td>\n",
       "      <td>-0.770963</td>\n",
       "      <td>6.920038</td>\n",
       "      <td>-2.429935</td>\n",
       "      <td>-3.921720</td>\n",
       "      <td>-4.659022</td>\n",
       "      <td>-4.321660</td>\n",
       "      <td>2.040658</td>\n",
       "      <td>-4.948812</td>\n",
       "      <td>7.810775</td>\n",
       "      <td>-6.515944</td>\n",
       "      <td>4.377778</td>\n",
       "      <td>4.249447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.738795</td>\n",
       "      <td>3.508221</td>\n",
       "      <td>-3.084219</td>\n",
       "      <td>-2.055181</td>\n",
       "      <td>-6.202135</td>\n",
       "      <td>-2.324691</td>\n",
       "      <td>-3.598113</td>\n",
       "      <td>-4.881999</td>\n",
       "      <td>4.343721</td>\n",
       "      <td>3.288866</td>\n",
       "      <td>-8.758722</td>\n",
       "      <td>-8.157871</td>\n",
       "      <td>-1.671575</td>\n",
       "      <td>-0.765159</td>\n",
       "      <td>-4.126219</td>\n",
       "      <td>5.952621</td>\n",
       "      <td>-7.953374</td>\n",
       "      <td>-6.093229</td>\n",
       "      <td>4.663666</td>\n",
       "      <td>4.219165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1.368667</td>\n",
       "      <td>-3.972085</td>\n",
       "      <td>5.433074</td>\n",
       "      <td>6.601264</td>\n",
       "      <td>-6.426833</td>\n",
       "      <td>1.042758</td>\n",
       "      <td>4.944042</td>\n",
       "      <td>7.671537</td>\n",
       "      <td>-5.333508</td>\n",
       "      <td>-7.128211</td>\n",
       "      <td>-5.145265</td>\n",
       "      <td>1.020387</td>\n",
       "      <td>-3.897650</td>\n",
       "      <td>-7.551147</td>\n",
       "      <td>-4.268405</td>\n",
       "      <td>8.827366</td>\n",
       "      <td>-7.952704</td>\n",
       "      <td>4.574883</td>\n",
       "      <td>-4.473346</td>\n",
       "      <td>8.431083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-6.736793</td>\n",
       "      <td>4.325078</td>\n",
       "      <td>7.136744</td>\n",
       "      <td>-9.854633</td>\n",
       "      <td>-3.301502</td>\n",
       "      <td>7.679328</td>\n",
       "      <td>0.639486</td>\n",
       "      <td>-3.328637</td>\n",
       "      <td>2.995985</td>\n",
       "      <td>-4.804451</td>\n",
       "      <td>-3.153152</td>\n",
       "      <td>-5.169599</td>\n",
       "      <td>2.650948</td>\n",
       "      <td>8.221815</td>\n",
       "      <td>10.039940</td>\n",
       "      <td>5.607178</td>\n",
       "      <td>-3.370453</td>\n",
       "      <td>8.624197</td>\n",
       "      <td>1.544150</td>\n",
       "      <td>-6.974489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1          2         3         4         5         6   \\\n",
       "0   -4.894204  4.146495 -10.627995  4.333094 -0.211089 -6.648520 -4.280519   \n",
       "1   -2.944945 -4.172675   2.317636  3.224382  2.160191  3.711342  5.053267   \n",
       "2    5.588860 -0.694617   2.670450 -8.996168 -3.310686 -7.067754  3.733333   \n",
       "3   -7.072881 -4.657294  -6.835857  9.598818  1.465891 -5.823493 -5.777774   \n",
       "4   -5.568182  9.380668   7.979990  1.130456  5.788285 -3.061255 -3.599283   \n",
       "..        ...       ...        ...       ...       ...       ...       ...   \n",
       "97   3.891827  2.561099   6.970787 -7.018413 -5.253020  3.758243  3.671204   \n",
       "98  -7.752234 -4.231459   8.498736 -5.204750 -0.988339  2.461777 -1.641066   \n",
       "99   5.738795  3.508221  -3.084219 -2.055181 -6.202135 -2.324691 -3.598113   \n",
       "100 -1.368667 -3.972085   5.433074  6.601264 -6.426833  1.042758  4.944042   \n",
       "101 -6.736793  4.325078   7.136744 -9.854633 -3.301502  7.679328  0.639486   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -3.815852 -3.777365 -1.499009 -0.625212 -7.137741 -5.564987  1.921789   \n",
       "1    -7.703063  8.844687 -1.244160  0.254470  5.201087 -5.925610  4.695848   \n",
       "2    10.910929  2.443390 -4.109570  7.296700  6.122800  6.156366 -1.021480   \n",
       "3    -7.312018 -0.630546 -6.401748 -6.745100  3.504016  4.543265  6.947121   \n",
       "4     6.892598  2.539938  2.496101 -4.084094  8.950968 -4.972475 -5.133507   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "97  -10.044440 -7.940752 -0.323961  6.115371 -5.004793  1.852236  5.476236   \n",
       "98   -7.762600 -0.770963  6.920038 -2.429935 -3.921720 -4.659022 -4.321660   \n",
       "99   -4.881999  4.343721  3.288866 -8.758722 -8.157871 -1.671575 -0.765159   \n",
       "100   7.671537 -5.333508 -7.128211 -5.145265  1.020387 -3.897650 -7.551147   \n",
       "101  -3.328637  2.995985 -4.804451 -3.153152 -5.169599  2.650948  8.221815   \n",
       "\n",
       "            14        15        16        17        18        19  \n",
       "0    -6.913729  7.227826 -7.480397 -3.841025 -2.643135 -4.290059  \n",
       "1     3.283216 -3.963865  5.261399 -4.708281  2.653075 -5.063646  \n",
       "2     3.269602  2.010873  1.207476  5.214314  6.464255 -2.690952  \n",
       "3     8.620768  0.387783 -1.047444  3.723100  5.218976  4.335200  \n",
       "4    -7.145875 -4.389797  6.115207 -6.742897  5.260499 -5.494330  \n",
       "..         ...       ...       ...       ...       ...       ...  \n",
       "97   -3.787934 -4.054970  2.748752  6.475208  0.135383 -7.873878  \n",
       "98    2.040658 -4.948812  7.810775 -6.515944  4.377778  4.249447  \n",
       "99   -4.126219  5.952621 -7.953374 -6.093229  4.663666  4.219165  \n",
       "100  -4.268405  8.827366 -7.952704  4.574883 -4.473346  8.431083  \n",
       "101  10.039940  5.607178 -3.370453  8.624197  1.544150 -6.974489  \n",
       "\n",
       "[102 rows x 20 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_20dims=pd.DataFrame(latent_layer_pred_train)\n",
    "X_train_20dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45b331bb-6a36-425a-80c1-b1ea167f00da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.376636</td>\n",
       "      <td>6.685627</td>\n",
       "      <td>8.486855</td>\n",
       "      <td>-5.005437</td>\n",
       "      <td>0.986963</td>\n",
       "      <td>-2.510396</td>\n",
       "      <td>0.891873</td>\n",
       "      <td>-5.870406</td>\n",
       "      <td>-4.658065</td>\n",
       "      <td>5.980363</td>\n",
       "      <td>6.565961</td>\n",
       "      <td>-5.318729</td>\n",
       "      <td>-6.247756</td>\n",
       "      <td>-2.401874</td>\n",
       "      <td>-9.539203</td>\n",
       "      <td>4.514901</td>\n",
       "      <td>-6.644996</td>\n",
       "      <td>-1.029745</td>\n",
       "      <td>5.043787</td>\n",
       "      <td>-7.681988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.641945</td>\n",
       "      <td>-7.661404</td>\n",
       "      <td>7.613710</td>\n",
       "      <td>-1.599616</td>\n",
       "      <td>7.090220</td>\n",
       "      <td>6.726690</td>\n",
       "      <td>-2.069273</td>\n",
       "      <td>-2.745076</td>\n",
       "      <td>2.530561</td>\n",
       "      <td>2.660381</td>\n",
       "      <td>7.137661</td>\n",
       "      <td>8.682987</td>\n",
       "      <td>6.308665</td>\n",
       "      <td>5.456786</td>\n",
       "      <td>8.533322</td>\n",
       "      <td>-3.954587</td>\n",
       "      <td>6.808384</td>\n",
       "      <td>-5.964357</td>\n",
       "      <td>-6.926980</td>\n",
       "      <td>-4.553753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.359315</td>\n",
       "      <td>-4.861623</td>\n",
       "      <td>-5.498817</td>\n",
       "      <td>6.374908</td>\n",
       "      <td>1.541136</td>\n",
       "      <td>-6.441969</td>\n",
       "      <td>6.099424</td>\n",
       "      <td>5.147042</td>\n",
       "      <td>-2.580868</td>\n",
       "      <td>-4.977870</td>\n",
       "      <td>6.729605</td>\n",
       "      <td>-3.195096</td>\n",
       "      <td>5.148294</td>\n",
       "      <td>-4.076187</td>\n",
       "      <td>-7.195958</td>\n",
       "      <td>6.914922</td>\n",
       "      <td>-6.155535</td>\n",
       "      <td>4.881458</td>\n",
       "      <td>-7.642689</td>\n",
       "      <td>-8.291637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.756402</td>\n",
       "      <td>0.441134</td>\n",
       "      <td>-6.646461</td>\n",
       "      <td>1.472855</td>\n",
       "      <td>-6.947612</td>\n",
       "      <td>7.541595</td>\n",
       "      <td>4.625729</td>\n",
       "      <td>-6.928267</td>\n",
       "      <td>4.398932</td>\n",
       "      <td>1.071311</td>\n",
       "      <td>-1.451650</td>\n",
       "      <td>-5.603864</td>\n",
       "      <td>4.042096</td>\n",
       "      <td>-0.611265</td>\n",
       "      <td>-1.356958</td>\n",
       "      <td>-5.764071</td>\n",
       "      <td>-6.192120</td>\n",
       "      <td>-8.153080</td>\n",
       "      <td>-6.249497</td>\n",
       "      <td>5.730522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.938262</td>\n",
       "      <td>-3.290774</td>\n",
       "      <td>6.039089</td>\n",
       "      <td>-9.971478</td>\n",
       "      <td>4.504210</td>\n",
       "      <td>-7.470418</td>\n",
       "      <td>-7.287096</td>\n",
       "      <td>-3.256257</td>\n",
       "      <td>-2.944622</td>\n",
       "      <td>1.461293</td>\n",
       "      <td>7.112204</td>\n",
       "      <td>5.424419</td>\n",
       "      <td>-4.540638</td>\n",
       "      <td>-0.372598</td>\n",
       "      <td>-7.300920</td>\n",
       "      <td>-0.119995</td>\n",
       "      <td>-5.317137</td>\n",
       "      <td>-6.542215</td>\n",
       "      <td>-6.035981</td>\n",
       "      <td>4.083077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.365646</td>\n",
       "      <td>8.686355</td>\n",
       "      <td>-3.822531</td>\n",
       "      <td>-7.310308</td>\n",
       "      <td>-3.612169</td>\n",
       "      <td>-2.193326</td>\n",
       "      <td>-4.453616</td>\n",
       "      <td>-3.896858</td>\n",
       "      <td>2.272247</td>\n",
       "      <td>3.491675</td>\n",
       "      <td>8.014971</td>\n",
       "      <td>-7.702356</td>\n",
       "      <td>1.721457</td>\n",
       "      <td>-6.695879</td>\n",
       "      <td>-4.547217</td>\n",
       "      <td>-7.225779</td>\n",
       "      <td>2.713670</td>\n",
       "      <td>4.677006</td>\n",
       "      <td>1.589107</td>\n",
       "      <td>-5.289326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -6.376636  6.685627  8.486855 -5.005437  0.986963 -2.510396  0.891873   \n",
       "1  3.641945 -7.661404  7.613710 -1.599616  7.090220  6.726690 -2.069273   \n",
       "2  3.359315 -4.861623 -5.498817  6.374908  1.541136 -6.441969  6.099424   \n",
       "3 -0.756402  0.441134 -6.646461  1.472855 -6.947612  7.541595  4.625729   \n",
       "4  0.938262 -3.290774  6.039089 -9.971478  4.504210 -7.470418 -7.287096   \n",
       "5 -6.365646  8.686355 -3.822531 -7.310308 -3.612169 -2.193326 -4.453616   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -5.870406 -4.658065  5.980363  6.565961 -5.318729 -6.247756 -2.401874   \n",
       "1 -2.745076  2.530561  2.660381  7.137661  8.682987  6.308665  5.456786   \n",
       "2  5.147042 -2.580868 -4.977870  6.729605 -3.195096  5.148294 -4.076187   \n",
       "3 -6.928267  4.398932  1.071311 -1.451650 -5.603864  4.042096 -0.611265   \n",
       "4 -3.256257 -2.944622  1.461293  7.112204  5.424419 -4.540638 -0.372598   \n",
       "5 -3.896858  2.272247  3.491675  8.014971 -7.702356  1.721457 -6.695879   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0 -9.539203  4.514901 -6.644996 -1.029745  5.043787 -7.681988  \n",
       "1  8.533322 -3.954587  6.808384 -5.964357 -6.926980 -4.553753  \n",
       "2 -7.195958  6.914922 -6.155535  4.881458 -7.642689 -8.291637  \n",
       "3 -1.356958 -5.764071 -6.192120 -8.153080 -6.249497  5.730522  \n",
       "4 -7.300920 -0.119995 -5.317137 -6.542215 -6.035981  4.083077  \n",
       "5 -4.547217 -7.225779  2.713670  4.677006  1.589107 -5.289326  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_20dims=pd.DataFrame(latent_layer_pred_test)\n",
    "X_test_20dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "956c8ed1-a77e-4dd0-a10d-4b70564a631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_20dims['patient number'] = X_train.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0af79701-1457-4f6c-8a17-0b2e051d7974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>patient number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.894204</td>\n",
       "      <td>4.146495</td>\n",
       "      <td>-10.627995</td>\n",
       "      <td>4.333094</td>\n",
       "      <td>-0.211089</td>\n",
       "      <td>-6.648520</td>\n",
       "      <td>-4.280519</td>\n",
       "      <td>-3.815852</td>\n",
       "      <td>-3.777365</td>\n",
       "      <td>-1.499009</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.137741</td>\n",
       "      <td>-5.564987</td>\n",
       "      <td>1.921789</td>\n",
       "      <td>-6.913729</td>\n",
       "      <td>7.227826</td>\n",
       "      <td>-7.480397</td>\n",
       "      <td>-3.841025</td>\n",
       "      <td>-2.643135</td>\n",
       "      <td>-4.290059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.944945</td>\n",
       "      <td>-4.172675</td>\n",
       "      <td>2.317636</td>\n",
       "      <td>3.224382</td>\n",
       "      <td>2.160191</td>\n",
       "      <td>3.711342</td>\n",
       "      <td>5.053267</td>\n",
       "      <td>-7.703063</td>\n",
       "      <td>8.844687</td>\n",
       "      <td>-1.244160</td>\n",
       "      <td>...</td>\n",
       "      <td>5.201087</td>\n",
       "      <td>-5.925610</td>\n",
       "      <td>4.695848</td>\n",
       "      <td>3.283216</td>\n",
       "      <td>-3.963865</td>\n",
       "      <td>5.261399</td>\n",
       "      <td>-4.708281</td>\n",
       "      <td>2.653075</td>\n",
       "      <td>-5.063646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.588860</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>2.670450</td>\n",
       "      <td>-8.996168</td>\n",
       "      <td>-3.310686</td>\n",
       "      <td>-7.067754</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>10.910929</td>\n",
       "      <td>2.443390</td>\n",
       "      <td>-4.109570</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122800</td>\n",
       "      <td>6.156366</td>\n",
       "      <td>-1.021480</td>\n",
       "      <td>3.269602</td>\n",
       "      <td>2.010873</td>\n",
       "      <td>1.207476</td>\n",
       "      <td>5.214314</td>\n",
       "      <td>6.464255</td>\n",
       "      <td>-2.690952</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.072881</td>\n",
       "      <td>-4.657294</td>\n",
       "      <td>-6.835857</td>\n",
       "      <td>9.598818</td>\n",
       "      <td>1.465891</td>\n",
       "      <td>-5.823493</td>\n",
       "      <td>-5.777774</td>\n",
       "      <td>-7.312018</td>\n",
       "      <td>-0.630546</td>\n",
       "      <td>-6.401748</td>\n",
       "      <td>...</td>\n",
       "      <td>3.504016</td>\n",
       "      <td>4.543265</td>\n",
       "      <td>6.947121</td>\n",
       "      <td>8.620768</td>\n",
       "      <td>0.387783</td>\n",
       "      <td>-1.047444</td>\n",
       "      <td>3.723100</td>\n",
       "      <td>5.218976</td>\n",
       "      <td>4.335200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.568182</td>\n",
       "      <td>9.380668</td>\n",
       "      <td>7.979990</td>\n",
       "      <td>1.130456</td>\n",
       "      <td>5.788285</td>\n",
       "      <td>-3.061255</td>\n",
       "      <td>-3.599283</td>\n",
       "      <td>6.892598</td>\n",
       "      <td>2.539938</td>\n",
       "      <td>2.496101</td>\n",
       "      <td>...</td>\n",
       "      <td>8.950968</td>\n",
       "      <td>-4.972475</td>\n",
       "      <td>-5.133507</td>\n",
       "      <td>-7.145875</td>\n",
       "      <td>-4.389797</td>\n",
       "      <td>6.115207</td>\n",
       "      <td>-6.742897</td>\n",
       "      <td>5.260499</td>\n",
       "      <td>-5.494330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.891827</td>\n",
       "      <td>2.561099</td>\n",
       "      <td>6.970787</td>\n",
       "      <td>-7.018413</td>\n",
       "      <td>-5.253020</td>\n",
       "      <td>3.758243</td>\n",
       "      <td>3.671204</td>\n",
       "      <td>-10.044440</td>\n",
       "      <td>-7.940752</td>\n",
       "      <td>-0.323961</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.004793</td>\n",
       "      <td>1.852236</td>\n",
       "      <td>5.476236</td>\n",
       "      <td>-3.787934</td>\n",
       "      <td>-4.054970</td>\n",
       "      <td>2.748752</td>\n",
       "      <td>6.475208</td>\n",
       "      <td>0.135383</td>\n",
       "      <td>-7.873878</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-7.752234</td>\n",
       "      <td>-4.231459</td>\n",
       "      <td>8.498736</td>\n",
       "      <td>-5.204750</td>\n",
       "      <td>-0.988339</td>\n",
       "      <td>2.461777</td>\n",
       "      <td>-1.641066</td>\n",
       "      <td>-7.762600</td>\n",
       "      <td>-0.770963</td>\n",
       "      <td>6.920038</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921720</td>\n",
       "      <td>-4.659022</td>\n",
       "      <td>-4.321660</td>\n",
       "      <td>2.040658</td>\n",
       "      <td>-4.948812</td>\n",
       "      <td>7.810775</td>\n",
       "      <td>-6.515944</td>\n",
       "      <td>4.377778</td>\n",
       "      <td>4.249447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.738795</td>\n",
       "      <td>3.508221</td>\n",
       "      <td>-3.084219</td>\n",
       "      <td>-2.055181</td>\n",
       "      <td>-6.202135</td>\n",
       "      <td>-2.324691</td>\n",
       "      <td>-3.598113</td>\n",
       "      <td>-4.881999</td>\n",
       "      <td>4.343721</td>\n",
       "      <td>3.288866</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.157871</td>\n",
       "      <td>-1.671575</td>\n",
       "      <td>-0.765159</td>\n",
       "      <td>-4.126219</td>\n",
       "      <td>5.952621</td>\n",
       "      <td>-7.953374</td>\n",
       "      <td>-6.093229</td>\n",
       "      <td>4.663666</td>\n",
       "      <td>4.219165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1.368667</td>\n",
       "      <td>-3.972085</td>\n",
       "      <td>5.433074</td>\n",
       "      <td>6.601264</td>\n",
       "      <td>-6.426833</td>\n",
       "      <td>1.042758</td>\n",
       "      <td>4.944042</td>\n",
       "      <td>7.671537</td>\n",
       "      <td>-5.333508</td>\n",
       "      <td>-7.128211</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020387</td>\n",
       "      <td>-3.897650</td>\n",
       "      <td>-7.551147</td>\n",
       "      <td>-4.268405</td>\n",
       "      <td>8.827366</td>\n",
       "      <td>-7.952704</td>\n",
       "      <td>4.574883</td>\n",
       "      <td>-4.473346</td>\n",
       "      <td>8.431083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-6.736793</td>\n",
       "      <td>4.325078</td>\n",
       "      <td>7.136744</td>\n",
       "      <td>-9.854633</td>\n",
       "      <td>-3.301502</td>\n",
       "      <td>7.679328</td>\n",
       "      <td>0.639486</td>\n",
       "      <td>-3.328637</td>\n",
       "      <td>2.995985</td>\n",
       "      <td>-4.804451</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.169599</td>\n",
       "      <td>2.650948</td>\n",
       "      <td>8.221815</td>\n",
       "      <td>10.039940</td>\n",
       "      <td>5.607178</td>\n",
       "      <td>-3.370453</td>\n",
       "      <td>8.624197</td>\n",
       "      <td>1.544150</td>\n",
       "      <td>-6.974489</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1          2         3         4         5         6  \\\n",
       "0   -4.894204  4.146495 -10.627995  4.333094 -0.211089 -6.648520 -4.280519   \n",
       "1   -2.944945 -4.172675   2.317636  3.224382  2.160191  3.711342  5.053267   \n",
       "2    5.588860 -0.694617   2.670450 -8.996168 -3.310686 -7.067754  3.733333   \n",
       "3   -7.072881 -4.657294  -6.835857  9.598818  1.465891 -5.823493 -5.777774   \n",
       "4   -5.568182  9.380668   7.979990  1.130456  5.788285 -3.061255 -3.599283   \n",
       "..        ...       ...        ...       ...       ...       ...       ...   \n",
       "97   3.891827  2.561099   6.970787 -7.018413 -5.253020  3.758243  3.671204   \n",
       "98  -7.752234 -4.231459   8.498736 -5.204750 -0.988339  2.461777 -1.641066   \n",
       "99   5.738795  3.508221  -3.084219 -2.055181 -6.202135 -2.324691 -3.598113   \n",
       "100 -1.368667 -3.972085   5.433074  6.601264 -6.426833  1.042758  4.944042   \n",
       "101 -6.736793  4.325078   7.136744 -9.854633 -3.301502  7.679328  0.639486   \n",
       "\n",
       "             7         8         9  ...        11        12        13  \\\n",
       "0    -3.815852 -3.777365 -1.499009  ... -7.137741 -5.564987  1.921789   \n",
       "1    -7.703063  8.844687 -1.244160  ...  5.201087 -5.925610  4.695848   \n",
       "2    10.910929  2.443390 -4.109570  ...  6.122800  6.156366 -1.021480   \n",
       "3    -7.312018 -0.630546 -6.401748  ...  3.504016  4.543265  6.947121   \n",
       "4     6.892598  2.539938  2.496101  ...  8.950968 -4.972475 -5.133507   \n",
       "..         ...       ...       ...  ...       ...       ...       ...   \n",
       "97  -10.044440 -7.940752 -0.323961  ... -5.004793  1.852236  5.476236   \n",
       "98   -7.762600 -0.770963  6.920038  ... -3.921720 -4.659022 -4.321660   \n",
       "99   -4.881999  4.343721  3.288866  ... -8.157871 -1.671575 -0.765159   \n",
       "100   7.671537 -5.333508 -7.128211  ...  1.020387 -3.897650 -7.551147   \n",
       "101  -3.328637  2.995985 -4.804451  ... -5.169599  2.650948  8.221815   \n",
       "\n",
       "            14        15        16        17        18        19  \\\n",
       "0    -6.913729  7.227826 -7.480397 -3.841025 -2.643135 -4.290059   \n",
       "1     3.283216 -3.963865  5.261399 -4.708281  2.653075 -5.063646   \n",
       "2     3.269602  2.010873  1.207476  5.214314  6.464255 -2.690952   \n",
       "3     8.620768  0.387783 -1.047444  3.723100  5.218976  4.335200   \n",
       "4    -7.145875 -4.389797  6.115207 -6.742897  5.260499 -5.494330   \n",
       "..         ...       ...       ...       ...       ...       ...   \n",
       "97   -3.787934 -4.054970  2.748752  6.475208  0.135383 -7.873878   \n",
       "98    2.040658 -4.948812  7.810775 -6.515944  4.377778  4.249447   \n",
       "99   -4.126219  5.952621 -7.953374 -6.093229  4.663666  4.219165   \n",
       "100  -4.268405  8.827366 -7.952704  4.574883 -4.473346  8.431083   \n",
       "101  10.039940  5.607178 -3.370453  8.624197  1.544150 -6.974489   \n",
       "\n",
       "     patient number  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 0  \n",
       "..              ...  \n",
       "97                2  \n",
       "98                0  \n",
       "99                1  \n",
       "100               1  \n",
       "101               2  \n",
       "\n",
       "[102 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_20dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "268eeea7-7bdc-4c2d-8db2-63bf70fabe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_20dims['patient number'] = X_test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4455853-dfd3-47e3-8cc6-69926e6d72ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>patient number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.376636</td>\n",
       "      <td>6.685627</td>\n",
       "      <td>8.486855</td>\n",
       "      <td>-5.005437</td>\n",
       "      <td>0.986963</td>\n",
       "      <td>-2.510396</td>\n",
       "      <td>0.891873</td>\n",
       "      <td>-5.870406</td>\n",
       "      <td>-4.658065</td>\n",
       "      <td>5.980363</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.318729</td>\n",
       "      <td>-6.247756</td>\n",
       "      <td>-2.401874</td>\n",
       "      <td>-9.539203</td>\n",
       "      <td>4.514901</td>\n",
       "      <td>-6.644996</td>\n",
       "      <td>-1.029745</td>\n",
       "      <td>5.043787</td>\n",
       "      <td>-7.681988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.641945</td>\n",
       "      <td>-7.661404</td>\n",
       "      <td>7.613710</td>\n",
       "      <td>-1.599616</td>\n",
       "      <td>7.090220</td>\n",
       "      <td>6.726690</td>\n",
       "      <td>-2.069273</td>\n",
       "      <td>-2.745076</td>\n",
       "      <td>2.530561</td>\n",
       "      <td>2.660381</td>\n",
       "      <td>...</td>\n",
       "      <td>8.682987</td>\n",
       "      <td>6.308665</td>\n",
       "      <td>5.456786</td>\n",
       "      <td>8.533322</td>\n",
       "      <td>-3.954587</td>\n",
       "      <td>6.808384</td>\n",
       "      <td>-5.964357</td>\n",
       "      <td>-6.926980</td>\n",
       "      <td>-4.553753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.359315</td>\n",
       "      <td>-4.861623</td>\n",
       "      <td>-5.498817</td>\n",
       "      <td>6.374908</td>\n",
       "      <td>1.541136</td>\n",
       "      <td>-6.441969</td>\n",
       "      <td>6.099424</td>\n",
       "      <td>5.147042</td>\n",
       "      <td>-2.580868</td>\n",
       "      <td>-4.977870</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.195096</td>\n",
       "      <td>5.148294</td>\n",
       "      <td>-4.076187</td>\n",
       "      <td>-7.195958</td>\n",
       "      <td>6.914922</td>\n",
       "      <td>-6.155535</td>\n",
       "      <td>4.881458</td>\n",
       "      <td>-7.642689</td>\n",
       "      <td>-8.291637</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.756402</td>\n",
       "      <td>0.441134</td>\n",
       "      <td>-6.646461</td>\n",
       "      <td>1.472855</td>\n",
       "      <td>-6.947612</td>\n",
       "      <td>7.541595</td>\n",
       "      <td>4.625729</td>\n",
       "      <td>-6.928267</td>\n",
       "      <td>4.398932</td>\n",
       "      <td>1.071311</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.603864</td>\n",
       "      <td>4.042096</td>\n",
       "      <td>-0.611265</td>\n",
       "      <td>-1.356958</td>\n",
       "      <td>-5.764071</td>\n",
       "      <td>-6.192120</td>\n",
       "      <td>-8.153080</td>\n",
       "      <td>-6.249497</td>\n",
       "      <td>5.730522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.938262</td>\n",
       "      <td>-3.290774</td>\n",
       "      <td>6.039089</td>\n",
       "      <td>-9.971478</td>\n",
       "      <td>4.504210</td>\n",
       "      <td>-7.470418</td>\n",
       "      <td>-7.287096</td>\n",
       "      <td>-3.256257</td>\n",
       "      <td>-2.944622</td>\n",
       "      <td>1.461293</td>\n",
       "      <td>...</td>\n",
       "      <td>5.424419</td>\n",
       "      <td>-4.540638</td>\n",
       "      <td>-0.372598</td>\n",
       "      <td>-7.300920</td>\n",
       "      <td>-0.119995</td>\n",
       "      <td>-5.317137</td>\n",
       "      <td>-6.542215</td>\n",
       "      <td>-6.035981</td>\n",
       "      <td>4.083077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.365646</td>\n",
       "      <td>8.686355</td>\n",
       "      <td>-3.822531</td>\n",
       "      <td>-7.310308</td>\n",
       "      <td>-3.612169</td>\n",
       "      <td>-2.193326</td>\n",
       "      <td>-4.453616</td>\n",
       "      <td>-3.896858</td>\n",
       "      <td>2.272247</td>\n",
       "      <td>3.491675</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.702356</td>\n",
       "      <td>1.721457</td>\n",
       "      <td>-6.695879</td>\n",
       "      <td>-4.547217</td>\n",
       "      <td>-7.225779</td>\n",
       "      <td>2.713670</td>\n",
       "      <td>4.677006</td>\n",
       "      <td>1.589107</td>\n",
       "      <td>-5.289326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -6.376636  6.685627  8.486855 -5.005437  0.986963 -2.510396  0.891873   \n",
       "1  3.641945 -7.661404  7.613710 -1.599616  7.090220  6.726690 -2.069273   \n",
       "2  3.359315 -4.861623 -5.498817  6.374908  1.541136 -6.441969  6.099424   \n",
       "3 -0.756402  0.441134 -6.646461  1.472855 -6.947612  7.541595  4.625729   \n",
       "4  0.938262 -3.290774  6.039089 -9.971478  4.504210 -7.470418 -7.287096   \n",
       "5 -6.365646  8.686355 -3.822531 -7.310308 -3.612169 -2.193326 -4.453616   \n",
       "\n",
       "          7         8         9  ...        11        12        13        14  \\\n",
       "0 -5.870406 -4.658065  5.980363  ... -5.318729 -6.247756 -2.401874 -9.539203   \n",
       "1 -2.745076  2.530561  2.660381  ...  8.682987  6.308665  5.456786  8.533322   \n",
       "2  5.147042 -2.580868 -4.977870  ... -3.195096  5.148294 -4.076187 -7.195958   \n",
       "3 -6.928267  4.398932  1.071311  ... -5.603864  4.042096 -0.611265 -1.356958   \n",
       "4 -3.256257 -2.944622  1.461293  ...  5.424419 -4.540638 -0.372598 -7.300920   \n",
       "5 -3.896858  2.272247  3.491675  ... -7.702356  1.721457 -6.695879 -4.547217   \n",
       "\n",
       "         15        16        17        18        19  patient number  \n",
       "0  4.514901 -6.644996 -1.029745  5.043787 -7.681988               0  \n",
       "1 -3.954587  6.808384 -5.964357 -6.926980 -4.553753               0  \n",
       "2  6.914922 -6.155535  4.881458 -7.642689 -8.291637               2  \n",
       "3 -5.764071 -6.192120 -8.153080 -6.249497  5.730522               1  \n",
       "4 -0.119995 -5.317137 -6.542215 -6.035981  4.083077               1  \n",
       "5 -7.225779  2.713670  4.677006  1.589107 -5.289326               1  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_20dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9b0a07f-b165-4630-afa9-3235234f7ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>patient number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.894204</td>\n",
       "      <td>4.146495</td>\n",
       "      <td>-10.627995</td>\n",
       "      <td>4.333094</td>\n",
       "      <td>-0.211089</td>\n",
       "      <td>-6.648520</td>\n",
       "      <td>-4.280519</td>\n",
       "      <td>-3.815852</td>\n",
       "      <td>-3.777365</td>\n",
       "      <td>-1.499009</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.137741</td>\n",
       "      <td>-5.564987</td>\n",
       "      <td>1.921789</td>\n",
       "      <td>-6.913729</td>\n",
       "      <td>7.227826</td>\n",
       "      <td>-7.480397</td>\n",
       "      <td>-3.841025</td>\n",
       "      <td>-2.643135</td>\n",
       "      <td>-4.290059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.944945</td>\n",
       "      <td>-4.172675</td>\n",
       "      <td>2.317636</td>\n",
       "      <td>3.224382</td>\n",
       "      <td>2.160191</td>\n",
       "      <td>3.711342</td>\n",
       "      <td>5.053267</td>\n",
       "      <td>-7.703063</td>\n",
       "      <td>8.844687</td>\n",
       "      <td>-1.244160</td>\n",
       "      <td>...</td>\n",
       "      <td>5.201087</td>\n",
       "      <td>-5.925610</td>\n",
       "      <td>4.695848</td>\n",
       "      <td>3.283216</td>\n",
       "      <td>-3.963865</td>\n",
       "      <td>5.261399</td>\n",
       "      <td>-4.708281</td>\n",
       "      <td>2.653075</td>\n",
       "      <td>-5.063646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.588860</td>\n",
       "      <td>-0.694617</td>\n",
       "      <td>2.670450</td>\n",
       "      <td>-8.996168</td>\n",
       "      <td>-3.310686</td>\n",
       "      <td>-7.067754</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>10.910929</td>\n",
       "      <td>2.443390</td>\n",
       "      <td>-4.109570</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122800</td>\n",
       "      <td>6.156366</td>\n",
       "      <td>-1.021480</td>\n",
       "      <td>3.269602</td>\n",
       "      <td>2.010873</td>\n",
       "      <td>1.207476</td>\n",
       "      <td>5.214314</td>\n",
       "      <td>6.464255</td>\n",
       "      <td>-2.690952</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.072881</td>\n",
       "      <td>-4.657294</td>\n",
       "      <td>-6.835857</td>\n",
       "      <td>9.598818</td>\n",
       "      <td>1.465891</td>\n",
       "      <td>-5.823493</td>\n",
       "      <td>-5.777774</td>\n",
       "      <td>-7.312018</td>\n",
       "      <td>-0.630546</td>\n",
       "      <td>-6.401748</td>\n",
       "      <td>...</td>\n",
       "      <td>3.504016</td>\n",
       "      <td>4.543265</td>\n",
       "      <td>6.947121</td>\n",
       "      <td>8.620768</td>\n",
       "      <td>0.387783</td>\n",
       "      <td>-1.047444</td>\n",
       "      <td>3.723100</td>\n",
       "      <td>5.218976</td>\n",
       "      <td>4.335200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.568182</td>\n",
       "      <td>9.380668</td>\n",
       "      <td>7.979990</td>\n",
       "      <td>1.130456</td>\n",
       "      <td>5.788285</td>\n",
       "      <td>-3.061255</td>\n",
       "      <td>-3.599283</td>\n",
       "      <td>6.892598</td>\n",
       "      <td>2.539938</td>\n",
       "      <td>2.496101</td>\n",
       "      <td>...</td>\n",
       "      <td>8.950968</td>\n",
       "      <td>-4.972475</td>\n",
       "      <td>-5.133507</td>\n",
       "      <td>-7.145875</td>\n",
       "      <td>-4.389797</td>\n",
       "      <td>6.115207</td>\n",
       "      <td>-6.742897</td>\n",
       "      <td>5.260499</td>\n",
       "      <td>-5.494330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3.641945</td>\n",
       "      <td>-7.661404</td>\n",
       "      <td>7.613710</td>\n",
       "      <td>-1.599616</td>\n",
       "      <td>7.090220</td>\n",
       "      <td>6.726690</td>\n",
       "      <td>-2.069273</td>\n",
       "      <td>-2.745076</td>\n",
       "      <td>2.530561</td>\n",
       "      <td>2.660381</td>\n",
       "      <td>...</td>\n",
       "      <td>8.682987</td>\n",
       "      <td>6.308665</td>\n",
       "      <td>5.456786</td>\n",
       "      <td>8.533322</td>\n",
       "      <td>-3.954587</td>\n",
       "      <td>6.808384</td>\n",
       "      <td>-5.964357</td>\n",
       "      <td>-6.926980</td>\n",
       "      <td>-4.553753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3.359315</td>\n",
       "      <td>-4.861623</td>\n",
       "      <td>-5.498817</td>\n",
       "      <td>6.374908</td>\n",
       "      <td>1.541136</td>\n",
       "      <td>-6.441969</td>\n",
       "      <td>6.099424</td>\n",
       "      <td>5.147042</td>\n",
       "      <td>-2.580868</td>\n",
       "      <td>-4.977870</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.195096</td>\n",
       "      <td>5.148294</td>\n",
       "      <td>-4.076187</td>\n",
       "      <td>-7.195958</td>\n",
       "      <td>6.914922</td>\n",
       "      <td>-6.155535</td>\n",
       "      <td>4.881458</td>\n",
       "      <td>-7.642689</td>\n",
       "      <td>-8.291637</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.756402</td>\n",
       "      <td>0.441134</td>\n",
       "      <td>-6.646461</td>\n",
       "      <td>1.472855</td>\n",
       "      <td>-6.947612</td>\n",
       "      <td>7.541595</td>\n",
       "      <td>4.625729</td>\n",
       "      <td>-6.928267</td>\n",
       "      <td>4.398932</td>\n",
       "      <td>1.071311</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.603864</td>\n",
       "      <td>4.042096</td>\n",
       "      <td>-0.611265</td>\n",
       "      <td>-1.356958</td>\n",
       "      <td>-5.764071</td>\n",
       "      <td>-6.192120</td>\n",
       "      <td>-8.153080</td>\n",
       "      <td>-6.249497</td>\n",
       "      <td>5.730522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.938262</td>\n",
       "      <td>-3.290774</td>\n",
       "      <td>6.039089</td>\n",
       "      <td>-9.971478</td>\n",
       "      <td>4.504210</td>\n",
       "      <td>-7.470418</td>\n",
       "      <td>-7.287096</td>\n",
       "      <td>-3.256257</td>\n",
       "      <td>-2.944622</td>\n",
       "      <td>1.461293</td>\n",
       "      <td>...</td>\n",
       "      <td>5.424419</td>\n",
       "      <td>-4.540638</td>\n",
       "      <td>-0.372598</td>\n",
       "      <td>-7.300920</td>\n",
       "      <td>-0.119995</td>\n",
       "      <td>-5.317137</td>\n",
       "      <td>-6.542215</td>\n",
       "      <td>-6.035981</td>\n",
       "      <td>4.083077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-6.365646</td>\n",
       "      <td>8.686355</td>\n",
       "      <td>-3.822531</td>\n",
       "      <td>-7.310308</td>\n",
       "      <td>-3.612169</td>\n",
       "      <td>-2.193326</td>\n",
       "      <td>-4.453616</td>\n",
       "      <td>-3.896858</td>\n",
       "      <td>2.272247</td>\n",
       "      <td>3.491675</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.702356</td>\n",
       "      <td>1.721457</td>\n",
       "      <td>-6.695879</td>\n",
       "      <td>-4.547217</td>\n",
       "      <td>-7.225779</td>\n",
       "      <td>2.713670</td>\n",
       "      <td>4.677006</td>\n",
       "      <td>1.589107</td>\n",
       "      <td>-5.289326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1          2         3         4         5         6  \\\n",
       "0   -4.894204  4.146495 -10.627995  4.333094 -0.211089 -6.648520 -4.280519   \n",
       "1   -2.944945 -4.172675   2.317636  3.224382  2.160191  3.711342  5.053267   \n",
       "2    5.588860 -0.694617   2.670450 -8.996168 -3.310686 -7.067754  3.733333   \n",
       "3   -7.072881 -4.657294  -6.835857  9.598818  1.465891 -5.823493 -5.777774   \n",
       "4   -5.568182  9.380668   7.979990  1.130456  5.788285 -3.061255 -3.599283   \n",
       "..        ...       ...        ...       ...       ...       ...       ...   \n",
       "103  3.641945 -7.661404   7.613710 -1.599616  7.090220  6.726690 -2.069273   \n",
       "104  3.359315 -4.861623  -5.498817  6.374908  1.541136 -6.441969  6.099424   \n",
       "105 -0.756402  0.441134  -6.646461  1.472855 -6.947612  7.541595  4.625729   \n",
       "106  0.938262 -3.290774   6.039089 -9.971478  4.504210 -7.470418 -7.287096   \n",
       "107 -6.365646  8.686355  -3.822531 -7.310308 -3.612169 -2.193326 -4.453616   \n",
       "\n",
       "             7         8         9  ...        11        12        13  \\\n",
       "0    -3.815852 -3.777365 -1.499009  ... -7.137741 -5.564987  1.921789   \n",
       "1    -7.703063  8.844687 -1.244160  ...  5.201087 -5.925610  4.695848   \n",
       "2    10.910929  2.443390 -4.109570  ...  6.122800  6.156366 -1.021480   \n",
       "3    -7.312018 -0.630546 -6.401748  ...  3.504016  4.543265  6.947121   \n",
       "4     6.892598  2.539938  2.496101  ...  8.950968 -4.972475 -5.133507   \n",
       "..         ...       ...       ...  ...       ...       ...       ...   \n",
       "103  -2.745076  2.530561  2.660381  ...  8.682987  6.308665  5.456786   \n",
       "104   5.147042 -2.580868 -4.977870  ... -3.195096  5.148294 -4.076187   \n",
       "105  -6.928267  4.398932  1.071311  ... -5.603864  4.042096 -0.611265   \n",
       "106  -3.256257 -2.944622  1.461293  ...  5.424419 -4.540638 -0.372598   \n",
       "107  -3.896858  2.272247  3.491675  ... -7.702356  1.721457 -6.695879   \n",
       "\n",
       "           14        15        16        17        18        19  \\\n",
       "0   -6.913729  7.227826 -7.480397 -3.841025 -2.643135 -4.290059   \n",
       "1    3.283216 -3.963865  5.261399 -4.708281  2.653075 -5.063646   \n",
       "2    3.269602  2.010873  1.207476  5.214314  6.464255 -2.690952   \n",
       "3    8.620768  0.387783 -1.047444  3.723100  5.218976  4.335200   \n",
       "4   -7.145875 -4.389797  6.115207 -6.742897  5.260499 -5.494330   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "103  8.533322 -3.954587  6.808384 -5.964357 -6.926980 -4.553753   \n",
       "104 -7.195958  6.914922 -6.155535  4.881458 -7.642689 -8.291637   \n",
       "105 -1.356958 -5.764071 -6.192120 -8.153080 -6.249497  5.730522   \n",
       "106 -7.300920 -0.119995 -5.317137 -6.542215 -6.035981  4.083077   \n",
       "107 -4.547217 -7.225779  2.713670  4.677006  1.589107 -5.289326   \n",
       "\n",
       "     patient number  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 0  \n",
       "..              ...  \n",
       "103               0  \n",
       "104               2  \n",
       "105               1  \n",
       "106               1  \n",
       "107               1  \n",
       "\n",
       "[108 rows x 21 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20dims=pd.concat([X_train_20dims, X_test_20dims], axis=0, ignore_index=True)\n",
    "df_20dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4656c50-07cd-4a0c-b41b-1e1775c44e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name columns\n",
    "df_20dims.columns=['column 1','column 2','column 3','column 4','column 5','column 6','column 7','column 8','column 9','column 10','column 11','column 12','column 13','column 14','column 15','column 16','column 17','column 18','column 19', 'column 20', 'patient number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d5f07e5-f34b-4485-b3ab-92a255254cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_20dims.to_csv('revise_latent_df_train_20dims_PD_HD_xbg_final.csv', index = False)\n",
    "X_test_20dims.to_csv('revise_latent_df_test_20dims_PD_HD_xbg_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d296ca29-d25c-4c6e-a7a3-ba82da0b1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20dims.to_csv('revise_latent_df_20dims_PD_HD_xbg_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5d59dbe-9628-4dea-9eda-a74b332b4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xgb=df_20dims.drop('patient number', axis=1).values\n",
    "y_xgb=df_20dims['patient number'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00c3ddf9-a1e9-41e2-b21a-cf9b7aab77f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfujiwara/anaconda3/envs/Keras/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from scipy.special import softmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold,RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f746b8f3-389d-451a-a686-6885dec891b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardalization\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_xgb)\n",
    "X_xgb = sc.transform(X_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "159fd873-4fbd-4d28-acb5-beeca6630ecc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:12:22,498] A new study created in memory with name: no-name-c76df7a6-ee51-4942-8664-03ff89590f29\n",
      "[I 2025-06-03 18:12:23,351] Trial 0 finished with value: 0.333333 and parameters: {'max_depth': 17, 'learning_rate': 0.10033543422825011, 'subsample': 0.8074899163465622, 'colsample_bytree': 0.7213713132091699}. Best is trial 0 with value: 0.333333.\n",
      "[I 2025-06-03 18:12:23,486] Trial 1 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.2440960599328786, 'subsample': 0.9985831849755107, 'colsample_bytree': 0.6462111208311844}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:23,620] Trial 2 finished with value: 0.5 and parameters: {'max_depth': 15, 'learning_rate': 0.27975533876363673, 'subsample': 0.9980048816700418, 'colsample_bytree': 0.9796307745227065}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:23,746] Trial 3 finished with value: 0.166667 and parameters: {'max_depth': 18, 'learning_rate': 0.22551813591716283, 'subsample': 0.9807198389363965, 'colsample_bytree': 0.7052592863727275}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:23,934] Trial 4 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.16237286348627503, 'subsample': 0.6622599315189236, 'colsample_bytree': 0.6767952131990335}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:24,128] Trial 5 finished with value: 0.166667 and parameters: {'max_depth': 14, 'learning_rate': 0.2587680571811298, 'subsample': 0.7302809741204458, 'colsample_bytree': 0.8683025648526563}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:24,254] Trial 6 finished with value: 0.166667 and parameters: {'max_depth': 20, 'learning_rate': 0.2392545389676169, 'subsample': 0.9811243752074444, 'colsample_bytree': 0.7620640542813103}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:24,401] Trial 7 finished with value: 0.166667 and parameters: {'max_depth': 11, 'learning_rate': 0.24638231111775658, 'subsample': 0.9161488093605304, 'colsample_bytree': 0.781054949012299}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:24,528] Trial 8 finished with value: 0.166667 and parameters: {'max_depth': 17, 'learning_rate': 0.27638489567955193, 'subsample': 0.9316239430351924, 'colsample_bytree': 0.8242930157011432}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:24,643] Trial 9 finished with value: 0.5 and parameters: {'max_depth': 5, 'learning_rate': 0.2768701091686114, 'subsample': 0.8895055700737338, 'colsample_bytree': 0.6841534716795962}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:24,855] Trial 10 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.003551614914704432, 'subsample': 0.8201627953959536, 'colsample_bytree': 0.6023977618088897}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:24,991] Trial 11 finished with value: 0.166667 and parameters: {'max_depth': 14, 'learning_rate': 0.17807401963997038, 'subsample': 0.8764012664924833, 'colsample_bytree': 0.9892178301607012}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:25,156] Trial 12 finished with value: 0.0 and parameters: {'max_depth': 13, 'learning_rate': 0.2975600195137086, 'subsample': 0.6044183288391209, 'colsample_bytree': 0.9991435319704397}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:25,337] Trial 13 finished with value: 0.166667 and parameters: {'max_depth': 8, 'learning_rate': 0.20272277835134192, 'subsample': 0.9883666194917416, 'colsample_bytree': 0.9087771216320517}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:25,460] Trial 14 finished with value: 0.5 and parameters: {'max_depth': 15, 'learning_rate': 0.1137106609372309, 'subsample': 0.8478297950152254, 'colsample_bytree': 0.6140234706291662}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:25,575] Trial 15 finished with value: 0.166667 and parameters: {'max_depth': 9, 'learning_rate': 0.19959834239148347, 'subsample': 0.7590774855711031, 'colsample_bytree': 0.889473690625173}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:25,673] Trial 16 finished with value: 0.333333 and parameters: {'max_depth': 3, 'learning_rate': 0.1210881105577065, 'subsample': 0.9387264702638881, 'colsample_bytree': 0.9405182412210642}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:25,998] Trial 17 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.06621352171621475, 'subsample': 0.994543448541724, 'colsample_bytree': 0.8521133856387046}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:26,203] Trial 18 finished with value: 0.333333 and parameters: {'max_depth': 10, 'learning_rate': 0.29535892472744063, 'subsample': 0.9479876188698233, 'colsample_bytree': 0.6455332686868358}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:26,373] Trial 19 finished with value: 0.166667 and parameters: {'max_depth': 16, 'learning_rate': 0.21329978758158846, 'subsample': 0.7462050122087628, 'colsample_bytree': 0.7493790841029528}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:26,481] Trial 20 finished with value: 0.166667 and parameters: {'max_depth': 20, 'learning_rate': 0.17888203396665223, 'subsample': 0.8840416755511522, 'colsample_bytree': 0.8116520879621619}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:26,871] Trial 21 finished with value: 0.5 and parameters: {'max_depth': 7, 'learning_rate': 0.15378732715923546, 'subsample': 0.6518490879501068, 'colsample_bytree': 0.6558992622868771}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:26,985] Trial 22 finished with value: 0.5 and parameters: {'max_depth': 6, 'learning_rate': 0.15394896435933444, 'subsample': 0.6525916954935451, 'colsample_bytree': 0.6620985487280038}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:27,091] Trial 23 finished with value: 0.166667 and parameters: {'max_depth': 9, 'learning_rate': 0.26180872363378904, 'subsample': 0.7084931815684488, 'colsample_bytree': 0.7125037241179788}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:27,421] Trial 24 finished with value: 0.166667 and parameters: {'max_depth': 13, 'learning_rate': 0.06249396399822724, 'subsample': 0.6843445412222539, 'colsample_bytree': 0.9398768497026385}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:27,650] Trial 25 finished with value: 0.5 and parameters: {'max_depth': 3, 'learning_rate': 0.18309518586148885, 'subsample': 0.771907451869315, 'colsample_bytree': 0.6426202138980911}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:27,765] Trial 26 finished with value: 0.166667 and parameters: {'max_depth': 10, 'learning_rate': 0.2302753036972791, 'subsample': 0.6147800228416638, 'colsample_bytree': 0.7409898374947936}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:27,874] Trial 27 finished with value: 0.333333 and parameters: {'max_depth': 5, 'learning_rate': 0.2685958337535771, 'subsample': 0.9575897910604227, 'colsample_bytree': 0.6762074430699503}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:28,031] Trial 28 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.1258501195351585, 'subsample': 0.848246640962066, 'colsample_bytree': 0.6201663692245354}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:28,159] Trial 29 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.06861589360043117, 'subsample': 0.7899199408785584, 'colsample_bytree': 0.6969555107735678}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:28,403] Trial 30 finished with value: 0.166667 and parameters: {'max_depth': 8, 'learning_rate': 0.013626631317667975, 'subsample': 0.9050529733966948, 'colsample_bytree': 0.7292469211804592}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:28,709] Trial 31 finished with value: 0.333333 and parameters: {'max_depth': 5, 'learning_rate': 0.28306035279691616, 'subsample': 0.958693037323059, 'colsample_bytree': 0.6872522580469068}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:28,819] Trial 32 finished with value: 0.5 and parameters: {'max_depth': 4, 'learning_rate': 0.2525915131434707, 'subsample': 0.8208793856013875, 'colsample_bytree': 0.6733489936388218}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:28,926] Trial 33 finished with value: 0.166667 and parameters: {'max_depth': 7, 'learning_rate': 0.22397719584054782, 'subsample': 0.8956465547688025, 'colsample_bytree': 0.7849958591530818}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:29,064] Trial 34 finished with value: 0.5 and parameters: {'max_depth': 6, 'learning_rate': 0.2782088960037131, 'subsample': 0.9734251762127344, 'colsample_bytree': 0.631613490116903}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:29,178] Trial 35 finished with value: 0.333333 and parameters: {'max_depth': 14, 'learning_rate': 0.24103636291039662, 'subsample': 0.9984079815101182, 'colsample_bytree': 0.7129637406348572}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:29,338] Trial 36 finished with value: 0.333333 and parameters: {'max_depth': 18, 'learning_rate': 0.2999451349694376, 'subsample': 0.8600654090509289, 'colsample_bytree': 0.7684797322930672}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:29,439] Trial 37 finished with value: 0.166667 and parameters: {'max_depth': 18, 'learning_rate': 0.2588392936311003, 'subsample': 0.9243533954418702, 'colsample_bytree': 0.8343205509231919}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:29,572] Trial 38 finished with value: 0.333333 and parameters: {'max_depth': 10, 'learning_rate': 0.23474781506211442, 'subsample': 0.9653783556921075, 'colsample_bytree': 0.6006403379643224}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:29,728] Trial 39 finished with value: 0.166667 and parameters: {'max_depth': 13, 'learning_rate': 0.2788172652925841, 'subsample': 0.7135348563574814, 'colsample_bytree': 0.6888698598378429}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:29,839] Trial 40 finished with value: 0.166667 and parameters: {'max_depth': 15, 'learning_rate': 0.08495946949587492, 'subsample': 0.918101129305246, 'colsample_bytree': 0.9555646271027609}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:29,994] Trial 41 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.03516919900513146, 'subsample': 0.8091950785282395, 'colsample_bytree': 0.6283147489739365}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:30,106] Trial 42 finished with value: 0.666667 and parameters: {'max_depth': 9, 'learning_rate': 0.010387699839246395, 'subsample': 0.8299061501377768, 'colsample_bytree': 0.6653334587688825}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:30,207] Trial 43 finished with value: 0.666667 and parameters: {'max_depth': 8, 'learning_rate': 0.1341511351617739, 'subsample': 0.8328685630081004, 'colsample_bytree': 0.6683758178861171}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:30,383] Trial 44 finished with value: 0.5 and parameters: {'max_depth': 9, 'learning_rate': 0.1377574677406061, 'subsample': 0.7915821939615029, 'colsample_bytree': 0.6606501908173859}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:30,593] Trial 45 finished with value: 0.333333 and parameters: {'max_depth': 8, 'learning_rate': 0.0885613373972912, 'subsample': 0.8328057924270725, 'colsample_bytree': 0.7346995833138763}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:30,910] Trial 46 finished with value: 0.166667 and parameters: {'max_depth': 7, 'learning_rate': 0.16440576247148803, 'subsample': 0.8675238522633626, 'colsample_bytree': 0.8822872750072599}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:31,072] Trial 47 finished with value: 0.333333 and parameters: {'max_depth': 11, 'learning_rate': 0.04816684578476094, 'subsample': 0.7640820300365243, 'colsample_bytree': 0.700697946883622}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:31,186] Trial 48 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.10279370389735706, 'subsample': 0.7340832553672698, 'colsample_bytree': 0.6441024129864767}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:31,347] Trial 49 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.2054376166015185, 'subsample': 0.6673820026810825, 'colsample_bytree': 0.9813881711453444}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:31,476] Trial 50 finished with value: 0.166667 and parameters: {'max_depth': 10, 'learning_rate': 0.19152300987549653, 'subsample': 0.980412921136637, 'colsample_bytree': 0.7924647566139015}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:31,599] Trial 51 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.2456297839326427, 'subsample': 0.8360614232015153, 'colsample_bytree': 0.6743535731478076}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:31,707] Trial 52 finished with value: 0.5 and parameters: {'max_depth': 6, 'learning_rate': 0.21810768454971366, 'subsample': 0.8064892160845527, 'colsample_bytree': 0.6155385737875011}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:31,836] Trial 53 finished with value: 0.166667 and parameters: {'max_depth': 4, 'learning_rate': 0.13539057916279904, 'subsample': 0.938560894382292, 'colsample_bytree': 0.7231525476778915}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:31,977] Trial 54 finished with value: 0.333333 and parameters: {'max_depth': 19, 'learning_rate': 0.2667304722030698, 'subsample': 0.8960947491274106, 'colsample_bytree': 0.6515613459556057}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:32,157] Trial 55 finished with value: 0.666667 and parameters: {'max_depth': 7, 'learning_rate': 0.2897132701377296, 'subsample': 0.7850381817936956, 'colsample_bytree': 0.759169861731102}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:32,438] Trial 56 finished with value: 0.166667 and parameters: {'max_depth': 7, 'learning_rate': 0.28636411236994985, 'subsample': 0.615969545874879, 'colsample_bytree': 0.8076095148077617}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:32,542] Trial 57 finished with value: 0.5 and parameters: {'max_depth': 9, 'learning_rate': 0.16675693909153896, 'subsample': 0.7817049429371558, 'colsample_bytree': 0.7642178527107149}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:32,672] Trial 58 finished with value: 0.166667 and parameters: {'max_depth': 8, 'learning_rate': 0.29196112140636155, 'subsample': 0.6366885668496945, 'colsample_bytree': 0.7531736997179335}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:32,796] Trial 59 finished with value: 0.0 and parameters: {'max_depth': 14, 'learning_rate': 0.269594723856045, 'subsample': 0.6976399161892155, 'colsample_bytree': 0.9106319039895306}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:32,928] Trial 60 finished with value: 0.166667 and parameters: {'max_depth': 15, 'learning_rate': 0.2512595655276098, 'subsample': 0.745290790247809, 'colsample_bytree': 0.7096052342007722}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:33,051] Trial 61 finished with value: 0.333333 and parameters: {'max_depth': 5, 'learning_rate': 0.0011154377661921067, 'subsample': 0.8757515978664792, 'colsample_bytree': 0.6727049828264728}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:33,195] Trial 62 finished with value: 0.333333 and parameters: {'max_depth': 6, 'learning_rate': 0.021055094962214152, 'subsample': 0.8506597665446757, 'colsample_bytree': 0.6368924707461775}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:33,362] Trial 63 finished with value: 0.5 and parameters: {'max_depth': 7, 'learning_rate': 0.2711187646925527, 'subsample': 0.823649507133176, 'colsample_bytree': 0.6847032741431959}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:33,469] Trial 64 finished with value: 0.333333 and parameters: {'max_depth': 4, 'learning_rate': 0.2842558661973531, 'subsample': 0.9869871741081393, 'colsample_bytree': 0.6633915497817637}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:33,581] Trial 65 finished with value: 0.333333 and parameters: {'max_depth': 13, 'learning_rate': 0.2582865267063166, 'subsample': 0.9486414213867319, 'colsample_bytree': 0.6966396299918053}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:33,690] Trial 66 finished with value: 0.333333 and parameters: {'max_depth': 8, 'learning_rate': 0.28986251998007834, 'subsample': 0.8340013630127293, 'colsample_bytree': 0.8463416412992992}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:33,800] Trial 67 finished with value: 0.333333 and parameters: {'max_depth': 11, 'learning_rate': 0.10685332650947234, 'subsample': 0.9725490669836401, 'colsample_bytree': 0.6253345050744125}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:33,927] Trial 68 finished with value: 0.333333 and parameters: {'max_depth': 10, 'learning_rate': 0.23849962701361035, 'subsample': 0.8023122079876531, 'colsample_bytree': 0.656221770496735}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:34,035] Trial 69 finished with value: 0.166667 and parameters: {'max_depth': 6, 'learning_rate': 0.2995846158225724, 'subsample': 0.90481112858321, 'colsample_bytree': 0.7215369691228051}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:34,449] Trial 70 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.08441792998628622, 'subsample': 0.859370480257951, 'colsample_bytree': 0.6126373551154823}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:34,680] Trial 71 finished with value: 0.5 and parameters: {'max_depth': 9, 'learning_rate': 0.00387472207107433, 'subsample': 0.8176915407697438, 'colsample_bytree': 0.60539840119775}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:35,138] Trial 72 finished with value: 0.5 and parameters: {'max_depth': 10, 'learning_rate': 0.0530335910702464, 'subsample': 0.7780515491676161, 'colsample_bytree': 0.6425708995113214}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:35,460] Trial 73 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.029737933380007648, 'subsample': 0.8763165712285588, 'colsample_bytree': 0.683763988802128}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:35,698] Trial 74 finished with value: 0.5 and parameters: {'max_depth': 5, 'learning_rate': 0.014075955242667623, 'subsample': 0.8396829517837405, 'colsample_bytree': 0.6633717133468966}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:35,778] Trial 75 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.037340912963548994, 'subsample': 0.7586921531904726, 'colsample_bytree': 0.6310283583517927}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:36,162] Trial 76 finished with value: 0.333333 and parameters: {'max_depth': 7, 'learning_rate': 0.22417944177796226, 'subsample': 0.790634064102604, 'colsample_bytree': 0.747520530484623}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:36,429] Trial 77 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.278063706323243, 'subsample': 0.9948716706723237, 'colsample_bytree': 0.6499073940827745}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:36,554] Trial 78 finished with value: 0.5 and parameters: {'max_depth': 15, 'learning_rate': 0.0764336464954289, 'subsample': 0.8182634989424247, 'colsample_bytree': 0.6939292242467473}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:36,665] Trial 79 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.19236729458822335, 'subsample': 0.855488543335333, 'colsample_bytree': 0.7067309583935744}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:37,378] Trial 80 finished with value: 0.166667 and parameters: {'max_depth': 11, 'learning_rate': 0.12223444159191665, 'subsample': 0.9508005804552182, 'colsample_bytree': 0.8274094521524047}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:37,758] Trial 81 finished with value: 0.5 and parameters: {'max_depth': 14, 'learning_rate': 0.14888917504885896, 'subsample': 0.8885276009100591, 'colsample_bytree': 0.6106738432655467}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:37,813] Trial 82 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.11006225761815995, 'subsample': 0.8444330359438791, 'colsample_bytree': 0.6189740901573116}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:37,920] Trial 83 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.1307695307221806, 'subsample': 0.8655018190692874, 'colsample_bytree': 0.6384623972946313}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:38,023] Trial 84 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.09535791102495099, 'subsample': 0.8277458509844646, 'colsample_bytree': 0.6704026412158097}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:38,167] Trial 85 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.16889363227571083, 'subsample': 0.8255468041286232, 'colsample_bytree': 0.6688335741009871}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:38,274] Trial 86 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.16851503031250592, 'subsample': 0.8292825546209881, 'colsample_bytree': 0.6728661757686861}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:38,367] Trial 87 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.17085102531601945, 'subsample': 0.8242445308509417, 'colsample_bytree': 0.6728569021706157}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:38,498] Trial 88 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.1732508368312926, 'subsample': 0.8269068921502445, 'colsample_bytree': 0.6692888454899381}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:39,402] Trial 89 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.17223530581171126, 'subsample': 0.7988797224115143, 'colsample_bytree': 0.6673737697955263}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:39,529] Trial 90 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.14621011444757462, 'subsample': 0.8283699445566187, 'colsample_bytree': 0.6784987627318608}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:39,649] Trial 91 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.1705029566800348, 'subsample': 0.8113366652313051, 'colsample_bytree': 0.6680357562111918}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:39,793] Trial 92 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.15766845707187485, 'subsample': 0.7976144355329983, 'colsample_bytree': 0.6540563963747928}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:39,906] Trial 93 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.17956426208656745, 'subsample': 0.8118109403052991, 'colsample_bytree': 0.6692879733691677}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:40,030] Trial 94 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.17213637062053191, 'subsample': 0.7985676271701173, 'colsample_bytree': 0.6798007950369406}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:40,140] Trial 95 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.14421112160069718, 'subsample': 0.78361558841495, 'colsample_bytree': 0.6990711216101813}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:40,405] Trial 96 finished with value: 0.333333 and parameters: {'max_depth': 13, 'learning_rate': 0.192859069936493, 'subsample': 0.841899770285325, 'colsample_bytree': 0.6922314498159006}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:41,551] Trial 97 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.18279338491442382, 'subsample': 0.8269531988324436, 'colsample_bytree': 0.7145479803387128}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:41,662] Trial 98 finished with value: 0.5 and parameters: {'max_depth': 14, 'learning_rate': 0.15650506752979285, 'subsample': 0.7699479466480621, 'colsample_bytree': 0.6587966701369148}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:41,856] Trial 99 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.2063289425790064, 'subsample': 0.751858789511596, 'colsample_bytree': 0.6473077091290261}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:41,994] Trial 100 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.17216405936782392, 'subsample': 0.8169996021188833, 'colsample_bytree': 0.6689994887063619}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:42,120] Trial 101 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.14280848168030705, 'subsample': 0.829695355772566, 'colsample_bytree': 0.6744092863817363}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:42,226] Trial 102 finished with value: 0.666667 and parameters: {'max_depth': 11, 'learning_rate': 0.16298352374599423, 'subsample': 0.8277072221267612, 'colsample_bytree': 0.6807936037817569}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:42,351] Trial 103 finished with value: 0.333333 and parameters: {'max_depth': 13, 'learning_rate': 0.1500728714007101, 'subsample': 0.8510642604849253, 'colsample_bytree': 0.6882401205401831}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:42,507] Trial 104 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.19881587870585582, 'subsample': 0.7977695630825807, 'colsample_bytree': 0.6360908258646943}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:42,616] Trial 105 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.17627135458934837, 'subsample': 0.8060671947113697, 'colsample_bytree': 0.660334157349622}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:42,835] Trial 106 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.15903203843866323, 'subsample': 0.8344448939682831, 'colsample_bytree': 0.7022722355767368}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:42,956] Trial 107 finished with value: 0.5 and parameters: {'max_depth': 10, 'learning_rate': 0.1854815637565707, 'subsample': 0.8134928032741765, 'colsample_bytree': 0.680142301585473}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:43,078] Trial 108 finished with value: 0.333333 and parameters: {'max_depth': 13, 'learning_rate': 0.2128453988449311, 'subsample': 0.8412110047316796, 'colsample_bytree': 0.731103942766129}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:43,223] Trial 109 finished with value: 0.666667 and parameters: {'max_depth': 11, 'learning_rate': 0.11486196774265861, 'subsample': 0.7876610990703917, 'colsample_bytree': 0.6440532684035178}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:43,386] Trial 110 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.09396555520346621, 'subsample': 0.7758688825100187, 'colsample_bytree': 0.6508650695244209}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:43,531] Trial 111 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.17133454279754146, 'subsample': 0.7992919186092268, 'colsample_bytree': 0.6805803865662418}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:43,643] Trial 112 finished with value: 0.666667 and parameters: {'max_depth': 14, 'learning_rate': 0.16612435013098897, 'subsample': 0.8223585839063584, 'colsample_bytree': 0.6681479456176465}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:43,762] Trial 113 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.1868490568328931, 'subsample': 0.8046286073847746, 'colsample_bytree': 0.6749410685325393}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:43,889] Trial 114 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.14085451308738725, 'subsample': 0.867578092849547, 'colsample_bytree': 0.6887701694229871}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:44,015] Trial 115 finished with value: 0.5 and parameters: {'max_depth': 10, 'learning_rate': 0.1327989312153073, 'subsample': 0.7948793527337266, 'colsample_bytree': 0.6590187471939628}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:44,136] Trial 116 finished with value: 0.333333 and parameters: {'max_depth': 13, 'learning_rate': 0.1758081726749171, 'subsample': 0.7675267807774481, 'colsample_bytree': 0.7735322875542977}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:44,250] Trial 117 finished with value: 0.666667 and parameters: {'max_depth': 11, 'learning_rate': 0.15357027584766944, 'subsample': 0.8251625762543843, 'colsample_bytree': 0.626834807585348}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:44,385] Trial 118 finished with value: 0.333333 and parameters: {'max_depth': 14, 'learning_rate': 0.19866285670581885, 'subsample': 0.849954281147679, 'colsample_bytree': 0.7144939378167984}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:44,537] Trial 119 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.14750204492993108, 'subsample': 0.7836613651284272, 'colsample_bytree': 0.6643860258294664}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:44,649] Trial 120 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.12867038074585274, 'subsample': 0.83117972442089, 'colsample_bytree': 0.6797003934998757}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:44,789] Trial 121 finished with value: 0.666667 and parameters: {'max_depth': 11, 'learning_rate': 0.16125755793367555, 'subsample': 0.8230989126037349, 'colsample_bytree': 0.6835907022052887}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:44,918] Trial 122 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.16393146669937655, 'subsample': 0.8093338357451721, 'colsample_bytree': 0.6538948598394028}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:45,037] Trial 123 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.16919361812248532, 'subsample': 0.8386974777461186, 'colsample_bytree': 0.694756820320754}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:45,153] Trial 124 finished with value: 0.333333 and parameters: {'max_depth': 11, 'learning_rate': 0.16189403152359164, 'subsample': 0.8284725229045816, 'colsample_bytree': 0.705057977819367}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:45,268] Trial 125 finished with value: 0.333333 and parameters: {'max_depth': 13, 'learning_rate': 0.1786413695189706, 'subsample': 0.8580082318462711, 'colsample_bytree': 0.6761718817722051}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:45,483] Trial 126 finished with value: 0.5 and parameters: {'max_depth': 10, 'learning_rate': 0.18898739016670527, 'subsample': 0.8144555960283492, 'colsample_bytree': 0.6682319966326491}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:45,599] Trial 127 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.15322220250899604, 'subsample': 0.8455900647051038, 'colsample_bytree': 0.6370657149211909}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:45,739] Trial 128 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.05623812175485689, 'subsample': 0.793223155631641, 'colsample_bytree': 0.6868450228810926}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:45,859] Trial 129 finished with value: 0.5 and parameters: {'max_depth': 7, 'learning_rate': 0.11818367003993212, 'subsample': 0.8030101971353449, 'colsample_bytree': 0.6501052665386056}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:46,007] Trial 130 finished with value: 0.5 and parameters: {'max_depth': 9, 'learning_rate': 0.1371245990069021, 'subsample': 0.8194080077501052, 'colsample_bytree': 0.6574024380060359}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:46,139] Trial 131 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.17218549560231086, 'subsample': 0.7980171100423181, 'colsample_bytree': 0.6395862527878039}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:46,253] Trial 132 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.19968917177563927, 'subsample': 0.8328415442623084, 'colsample_bytree': 0.6328447710570154}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:46,365] Trial 133 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.16572009366183313, 'subsample': 0.7775673237430033, 'colsample_bytree': 0.6657077446251635}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:46,547] Trial 134 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.23040444249546577, 'subsample': 0.8068653230452518, 'colsample_bytree': 0.6234853792603503}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:46,662] Trial 135 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.17901200576276613, 'subsample': 0.787986602983347, 'colsample_bytree': 0.673562914831195}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:47,029] Trial 136 finished with value: 0.666667 and parameters: {'max_depth': 11, 'learning_rate': 0.2091448182639311, 'subsample': 0.81507918456705, 'colsample_bytree': 0.6467352426182618}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:47,170] Trial 137 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.19772391985593252, 'subsample': 0.8382245066379974, 'colsample_bytree': 0.6811857714534383}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:47,284] Trial 138 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.1582874093101996, 'subsample': 0.8231522380666051, 'colsample_bytree': 0.6608262595071349}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:47,464] Trial 139 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.14888421614015046, 'subsample': 0.7614118435618155, 'colsample_bytree': 0.6945310770023587}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:47,577] Trial 140 finished with value: 0.5 and parameters: {'max_depth': 14, 'learning_rate': 0.1827595997146818, 'subsample': 0.7241993696805918, 'colsample_bytree': 0.6530416275214621}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:47,693] Trial 141 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.1156785717522682, 'subsample': 0.7894991777743837, 'colsample_bytree': 0.6708188449508169}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:47,846] Trial 142 finished with value: 0.666667 and parameters: {'max_depth': 10, 'learning_rate': 0.12412771225833633, 'subsample': 0.7983010481213044, 'colsample_bytree': 0.6405665325929172}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:47,960] Trial 143 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.09857859770515238, 'subsample': 0.8105754340330524, 'colsample_bytree': 0.632482049284661}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:48,075] Trial 144 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.14105696146733004, 'subsample': 0.773275942239857, 'colsample_bytree': 0.644388336318612}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:48,192] Trial 145 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.1728932368965872, 'subsample': 0.7830805487734817, 'colsample_bytree': 0.6630860943597645}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:48,302] Trial 146 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.15811850163597457, 'subsample': 0.8264495080390806, 'colsample_bytree': 0.6780917879389737}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:48,472] Trial 147 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.10883148069637474, 'subsample': 0.8459066586405141, 'colsample_bytree': 0.6477776631043429}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:48,525] Trial 148 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.19369769828923514, 'subsample': 0.7994782853200062, 'colsample_bytree': 0.8656565752623593}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:48,673] Trial 149 finished with value: 0.333333 and parameters: {'max_depth': 8, 'learning_rate': 0.16700797551991442, 'subsample': 0.8328575712621831, 'colsample_bytree': 0.700320492493996}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:48,799] Trial 150 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.15278488954335254, 'subsample': 0.7530227899324374, 'colsample_bytree': 0.6571989661251858}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:48,922] Trial 151 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.17585200735134607, 'subsample': 0.803869497755208, 'colsample_bytree': 0.6833571476742305}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:49,074] Trial 152 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.17015177586175165, 'subsample': 0.7925843522175712, 'colsample_bytree': 0.6900634944746816}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:49,190] Trial 153 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.24712143033262268, 'subsample': 0.8165159533572627, 'colsample_bytree': 0.674095060176974}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:49,304] Trial 154 finished with value: 0.666667 and parameters: {'max_depth': 11, 'learning_rate': 0.1843543927887849, 'subsample': 0.797892901747587, 'colsample_bytree': 0.6803566486657352}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:49,479] Trial 155 finished with value: 0.666667 and parameters: {'max_depth': 14, 'learning_rate': 0.14668791705998302, 'subsample': 0.7863700498525593, 'colsample_bytree': 0.6638865462622553}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:49,596] Trial 156 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.21934982935213185, 'subsample': 0.8230998695047992, 'colsample_bytree': 0.6719886293179159}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:49,719] Trial 157 finished with value: 0.333333 and parameters: {'max_depth': 7, 'learning_rate': 0.0743252194653492, 'subsample': 0.8090569010989099, 'colsample_bytree': 0.7942948310114429}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:49,868] Trial 158 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.1622649561774734, 'subsample': 0.8394460961615807, 'colsample_bytree': 0.6881730607459499}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:49,980] Trial 159 finished with value: 0.333333 and parameters: {'max_depth': 11, 'learning_rate': 0.16904829615300465, 'subsample': 0.8547373405531629, 'colsample_bytree': 0.656271478972973}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:50,095] Trial 160 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.13215897554685604, 'subsample': 0.8646774220096209, 'colsample_bytree': 0.7067715500892778}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:50,212] Trial 161 finished with value: 0.5 and parameters: {'max_depth': 14, 'learning_rate': 0.1664866729882235, 'subsample': 0.8204237907067063, 'colsample_bytree': 0.666926441021802}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:50,337] Trial 162 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.17580174136047538, 'subsample': 0.8299266808688899, 'colsample_bytree': 0.6800955057413112}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:50,511] Trial 163 finished with value: 0.5 and parameters: {'max_depth': 15, 'learning_rate': 0.1626112498309817, 'subsample': 0.816941762561278, 'colsample_bytree': 0.6695203761210398}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:50,632] Trial 164 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.18222238622359013, 'subsample': 0.801661710565039, 'colsample_bytree': 0.6446506919002931}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:50,784] Trial 165 finished with value: 0.666667 and parameters: {'max_depth': 7, 'learning_rate': 0.1551488841780267, 'subsample': 0.8247164427331194, 'colsample_bytree': 0.6529766780355949}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:50,900] Trial 166 finished with value: 0.5 and parameters: {'max_depth': 14, 'learning_rate': 0.14202909690823884, 'subsample': 0.8090953484461367, 'colsample_bytree': 0.6652786595699025}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:51,018] Trial 167 finished with value: 0.0 and parameters: {'max_depth': 12, 'learning_rate': 0.1751427133788753, 'subsample': 0.8388848098956856, 'colsample_bytree': 0.8151514701947484}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:51,145] Trial 168 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.1895356418447947, 'subsample': 0.7811138734045907, 'colsample_bytree': 0.6924381062042269}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:51,265] Trial 169 finished with value: 0.5 and parameters: {'max_depth': 14, 'learning_rate': 0.16658686873400277, 'subsample': 0.7693188636219608, 'colsample_bytree': 0.6785508616964419}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:51,406] Trial 170 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.15891172073217372, 'subsample': 0.6764413241001815, 'colsample_bytree': 0.6338939315112901}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:51,548] Trial 171 finished with value: 0.666667 and parameters: {'max_depth': 6, 'learning_rate': 0.1483817805218768, 'subsample': 0.8278188982830772, 'colsample_bytree': 0.6596816483416769}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:51,663] Trial 172 finished with value: 0.666667 and parameters: {'max_depth': 11, 'learning_rate': 0.1528636810659595, 'subsample': 0.8168729607200985, 'colsample_bytree': 0.6286091431394275}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:51,814] Trial 173 finished with value: 0.666667 and parameters: {'max_depth': 11, 'learning_rate': 0.12600534792928475, 'subsample': 0.7933628958360809, 'colsample_bytree': 0.6044146863052847}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:51,922] Trial 174 finished with value: 0.5 and parameters: {'max_depth': 10, 'learning_rate': 0.15350347864417568, 'subsample': 0.8321875154932786, 'colsample_bytree': 0.6251683872925902}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:52,038] Trial 175 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.2555298991788244, 'subsample': 0.9260778937218305, 'colsample_bytree': 0.61778088987187}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:52,152] Trial 176 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.13602319408891764, 'subsample': 0.8461779628749315, 'colsample_bytree': 0.6484126721987924}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:52,264] Trial 177 finished with value: 0.666667 and parameters: {'max_depth': 10, 'learning_rate': 0.1727869432512783, 'subsample': 0.8237538968590019, 'colsample_bytree': 0.63941877933485}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:52,410] Trial 178 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.1631156888914171, 'subsample': 0.8066484729845422, 'colsample_bytree': 0.6701835056836725}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:52,538] Trial 179 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.17832389085794434, 'subsample': 0.83469342704482, 'colsample_bytree': 0.6840154770341228}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:52,676] Trial 180 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.10070992313542296, 'subsample': 0.8159707952217841, 'colsample_bytree': 0.658569128953752}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:52,823] Trial 181 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.14649114973505592, 'subsample': 0.7849972437563384, 'colsample_bytree': 0.6646040043506899}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:52,990] Trial 182 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.040560622484561076, 'subsample': 0.7762171913070341, 'colsample_bytree': 0.6756626089466954}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:53,142] Trial 183 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.15777836029814013, 'subsample': 0.799311054947607, 'colsample_bytree': 0.6663245432844644}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:53,260] Trial 184 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.14304705705618193, 'subsample': 0.7889542329818542, 'colsample_bytree': 0.6541308111883113}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:53,475] Trial 185 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.16696922704764292, 'subsample': 0.8256561180925737, 'colsample_bytree': 0.6427253270377996}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:53,595] Trial 186 finished with value: 0.666667 and parameters: {'max_depth': 8, 'learning_rate': 0.15066624730096823, 'subsample': 0.8070053835062521, 'colsample_bytree': 0.6751615777872408}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:53,707] Trial 187 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.11384964299805667, 'subsample': 0.7947378557862667, 'colsample_bytree': 0.6858683157527348}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:53,863] Trial 188 finished with value: 0.333333 and parameters: {'max_depth': 15, 'learning_rate': 0.169893127618904, 'subsample': 0.8497002476923021, 'colsample_bytree': 0.697290870237217}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:53,985] Trial 189 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.13513095133220207, 'subsample': 0.8125385292758303, 'colsample_bytree': 0.6632601706019092}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:54,101] Trial 190 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.18398064720909782, 'subsample': 0.8381201743495116, 'colsample_bytree': 0.9098572031985693}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:54,220] Trial 191 finished with value: 0.666667 and parameters: {'max_depth': 12, 'learning_rate': 0.1265081463253379, 'subsample': 0.8291342216273537, 'colsample_bytree': 0.6817183829416499}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:54,509] Trial 192 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.140279425714022, 'subsample': 0.8222430396050305, 'colsample_bytree': 0.6737934052270631}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:54,619] Trial 193 finished with value: 0.666667 and parameters: {'max_depth': 13, 'learning_rate': 0.12974374135985428, 'subsample': 0.8330383524687504, 'colsample_bytree': 0.670396373928368}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:54,732] Trial 194 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.2622295725273467, 'subsample': 0.7834892348080136, 'colsample_bytree': 0.6502723271469585}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:54,911] Trial 195 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.12081274173689953, 'subsample': 0.8447678855718528, 'colsample_bytree': 0.6888871183274508}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:55,027] Trial 196 finished with value: 0.5 and parameters: {'max_depth': 14, 'learning_rate': 0.1616185048625227, 'subsample': 0.8031473069354107, 'colsample_bytree': 0.6790736314215339}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:55,160] Trial 197 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.23685369452489663, 'subsample': 0.8182797897716402, 'colsample_bytree': 0.6601406628586535}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:55,277] Trial 198 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.14587026878307346, 'subsample': 0.8289442875520406, 'colsample_bytree': 0.6666164633375068}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:55,488] Trial 199 finished with value: 0.5 and parameters: {'max_depth': 10, 'learning_rate': 0.154750113404911, 'subsample': 0.8115356752194373, 'colsample_bytree': 0.636335413670184}. Best is trial 1 with value: 0.666667.\n",
      "[I 2025-06-03 18:12:55,489] A new study created in memory with name: no-name-5a67b6fc-4aa5-4662-aac2-4edeff34fa67\n",
      "[I 2025-06-03 18:12:55,681] Trial 0 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.13515107087727415, 'subsample': 0.9939856638731723, 'colsample_bytree': 0.7855024460017604}. Best is trial 0 with value: 0.5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 12, 'learning_rate': 0.2440960599328786, 'subsample': 0.9985831849755107, 'colsample_bytree': 0.6462111208311844}\n",
      "Best accuracy: 0.666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 18:12:55,869] Trial 1 finished with value: 0.333333 and parameters: {'max_depth': 14, 'learning_rate': 0.13902082207345445, 'subsample': 0.6981512894496695, 'colsample_bytree': 0.7805903017327613}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:55,981] Trial 2 finished with value: 0.166667 and parameters: {'max_depth': 7, 'learning_rate': 0.27923464843030527, 'subsample': 0.8793525893126386, 'colsample_bytree': 0.9022675947940715}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:56,100] Trial 3 finished with value: 0.333333 and parameters: {'max_depth': 6, 'learning_rate': 0.0160957649910347, 'subsample': 0.7219652507399246, 'colsample_bytree': 0.6247157246586825}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:56,207] Trial 4 finished with value: 0.333333 and parameters: {'max_depth': 14, 'learning_rate': 0.06439678723739226, 'subsample': 0.9612890438828625, 'colsample_bytree': 0.6449136766061}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:56,334] Trial 5 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.13657011397476923, 'subsample': 0.807624504590173, 'colsample_bytree': 0.9227429521170937}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:56,496] Trial 6 finished with value: 0.166667 and parameters: {'max_depth': 17, 'learning_rate': 0.1877510313663477, 'subsample': 0.881506892437567, 'colsample_bytree': 0.9473267181301631}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:56,736] Trial 7 finished with value: 0.166667 and parameters: {'max_depth': 10, 'learning_rate': 0.09238244076513098, 'subsample': 0.892305365567144, 'colsample_bytree': 0.9609020910088358}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:57,114] Trial 8 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.25754964952937726, 'subsample': 0.8155609975880429, 'colsample_bytree': 0.883472027689588}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:57,239] Trial 9 finished with value: 0.333333 and parameters: {'max_depth': 8, 'learning_rate': 0.0075475370150057345, 'subsample': 0.6459740711704782, 'colsample_bytree': 0.9210746460391901}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:57,355] Trial 10 finished with value: 0.5 and parameters: {'max_depth': 3, 'learning_rate': 0.20887400707279574, 'subsample': 0.9940969917290677, 'colsample_bytree': 0.7595176246704309}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:57,517] Trial 11 finished with value: 0.166667 and parameters: {'max_depth': 20, 'learning_rate': 0.12158876213988029, 'subsample': 0.7559266138309909, 'colsample_bytree': 0.8310649466244034}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:57,625] Trial 12 finished with value: 0.333333 and parameters: {'max_depth': 13, 'learning_rate': 0.17987101150066487, 'subsample': 0.6150359145946755, 'colsample_bytree': 0.7205865436593241}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:57,753] Trial 13 finished with value: 0.333333 and parameters: {'max_depth': 17, 'learning_rate': 0.09321624903680756, 'subsample': 0.8100500372834448, 'colsample_bytree': 0.8436356490260903}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:57,871] Trial 14 finished with value: 0.166667 and parameters: {'max_depth': 11, 'learning_rate': 0.22833936642492658, 'subsample': 0.9320276760690307, 'colsample_bytree': 0.7121452309813614}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:57,996] Trial 15 finished with value: 0.333333 and parameters: {'max_depth': 17, 'learning_rate': 0.15981827857972597, 'subsample': 0.833559850420265, 'colsample_bytree': 0.9936276040173861}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:58,122] Trial 16 finished with value: 0.166667 and parameters: {'max_depth': 15, 'learning_rate': 0.06200618263458127, 'subsample': 0.7639229066874216, 'colsample_bytree': 0.8484641415988514}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:58,230] Trial 17 finished with value: 0.5 and parameters: {'max_depth': 20, 'learning_rate': 0.1489995847496939, 'subsample': 0.996383686171371, 'colsample_bytree': 0.6924965887059382}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:58,335] Trial 18 finished with value: 0.166667 and parameters: {'max_depth': 12, 'learning_rate': 0.11096597203242076, 'subsample': 0.9432435947623489, 'colsample_bytree': 0.8018532889731592}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:58,533] Trial 19 finished with value: 0.333333 and parameters: {'max_depth': 10, 'learning_rate': 0.05634411707711938, 'subsample': 0.850206541276026, 'colsample_bytree': 0.753147046999679}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:58,640] Trial 20 finished with value: 0.333333 and parameters: {'max_depth': 16, 'learning_rate': 0.22718193901734618, 'subsample': 0.6719831434428842, 'colsample_bytree': 0.8826178800574153}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:58,759] Trial 21 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.2991831178328728, 'subsample': 0.771626533057557, 'colsample_bytree': 0.8716239300871053}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:58,871] Trial 22 finished with value: 0.333333 and parameters: {'max_depth': 5, 'learning_rate': 0.26767930789349104, 'subsample': 0.8109509259820143, 'colsample_bytree': 0.9291484410493374}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:58,988] Trial 23 finished with value: 0.166667 and parameters: {'max_depth': 12, 'learning_rate': 0.17603374974847835, 'subsample': 0.9077127598423878, 'colsample_bytree': 0.8065647660644529}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:59,116] Trial 24 finished with value: 0.333333 and parameters: {'max_depth': 8, 'learning_rate': 0.24203956636146218, 'subsample': 0.8453671353770088, 'colsample_bytree': 0.9972426207030757}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:59,231] Trial 25 finished with value: 0.333333 and parameters: {'max_depth': 4, 'learning_rate': 0.12777974514546245, 'subsample': 0.7406274346820203, 'colsample_bytree': 0.892009226806191}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:59,372] Trial 26 finished with value: 0.333333 and parameters: {'max_depth': 10, 'learning_rate': 0.1977589110668433, 'subsample': 0.7887688543598852, 'colsample_bytree': 0.8599144840614953}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:59,526] Trial 27 finished with value: 0.333333 and parameters: {'max_depth': 19, 'learning_rate': 0.15904082712748766, 'subsample': 0.6969519670273709, 'colsample_bytree': 0.9680951278789957}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:59,640] Trial 28 finished with value: 0.166667 and parameters: {'max_depth': 6, 'learning_rate': 0.10105291202340622, 'subsample': 0.8539285673524469, 'colsample_bytree': 0.8227468508110748}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:59,745] Trial 29 finished with value: 0.166667 and parameters: {'max_depth': 14, 'learning_rate': 0.13567893058328367, 'subsample': 0.7129407998296683, 'colsample_bytree': 0.7917124319384785}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:12:59,884] Trial 30 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.25024924078845273, 'subsample': 0.81605511548264, 'colsample_bytree': 0.9090778264983352}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:00,006] Trial 31 finished with value: 0.166667 and parameters: {'max_depth': 4, 'learning_rate': 0.20051279741728073, 'subsample': 0.9670854331765215, 'colsample_bytree': 0.7558440353872505}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:00,122] Trial 32 finished with value: 0.333333 and parameters: {'max_depth': 3, 'learning_rate': 0.2241078132384785, 'subsample': 0.9774098591167958, 'colsample_bytree': 0.7350956984887825}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:00,242] Trial 33 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.2734510889504198, 'subsample': 0.9979549588642532, 'colsample_bytree': 0.7677083657685769}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:00,477] Trial 34 finished with value: 0.166667 and parameters: {'max_depth': 7, 'learning_rate': 0.21326205319781436, 'subsample': 0.9119143831460452, 'colsample_bytree': 0.6628117127241773}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:00,603] Trial 35 finished with value: 0.333333 and parameters: {'max_depth': 3, 'learning_rate': 0.25698231765566204, 'subsample': 0.9659276953173673, 'colsample_bytree': 0.7782950665884442}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:00,759] Trial 36 finished with value: 0.166667 and parameters: {'max_depth': 11, 'learning_rate': 0.03361271564875595, 'subsample': 0.9299679341559665, 'colsample_bytree': 0.9420091946778816}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:00,907] Trial 37 finished with value: 0.166667 and parameters: {'max_depth': 6, 'learning_rate': 0.16749740816302833, 'subsample': 0.8857062589242506, 'colsample_bytree': 0.8191592193694216}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:01,025] Trial 38 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.14141679522102835, 'subsample': 0.864343406787098, 'colsample_bytree': 0.737874943718789}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:01,134] Trial 39 finished with value: 0.333333 and parameters: {'max_depth': 15, 'learning_rate': 0.1986060964489909, 'subsample': 0.9406510910834589, 'colsample_bytree': 0.691333225840862}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:01,251] Trial 40 finished with value: 0.166667 and parameters: {'max_depth': 13, 'learning_rate': 0.2951279129240144, 'subsample': 0.7901559642390253, 'colsample_bytree': 0.9095442286189174}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:01,365] Trial 41 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.14784673352153666, 'subsample': 0.9823207874903354, 'colsample_bytree': 0.6762594657708595}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:01,545] Trial 42 finished with value: 0.333333 and parameters: {'max_depth': 20, 'learning_rate': 0.11509097188767012, 'subsample': 0.9969517089988823, 'colsample_bytree': 0.6201016163715604}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:01,654] Trial 43 finished with value: 0.333333 and parameters: {'max_depth': 18, 'learning_rate': 0.18486534272041646, 'subsample': 0.9486587413529289, 'colsample_bytree': 0.6007387034478913}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:01,764] Trial 44 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.0783018582653677, 'subsample': 0.9981037038557223, 'colsample_bytree': 0.7242051090759817}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:01,908] Trial 45 finished with value: 0.333333 and parameters: {'max_depth': 18, 'learning_rate': 0.15491435654502578, 'subsample': 0.9116866957688026, 'colsample_bytree': 0.6949154922064944}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,016] Trial 46 finished with value: 0.166667 and parameters: {'max_depth': 7, 'learning_rate': 0.12658609835915022, 'subsample': 0.6301273268124776, 'colsample_bytree': 0.6440180714304232}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,125] Trial 47 finished with value: 0.166667 and parameters: {'max_depth': 15, 'learning_rate': 0.17157142267596795, 'subsample': 0.955769681428117, 'colsample_bytree': 0.9634059712727697}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,267] Trial 48 finished with value: 0.166667 and parameters: {'max_depth': 11, 'learning_rate': 0.08319776183304868, 'subsample': 0.8274293820624706, 'colsample_bytree': 0.8479871649977099}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,420] Trial 49 finished with value: 0.166667 and parameters: {'max_depth': 14, 'learning_rate': 0.10872558803324554, 'subsample': 0.740539379617648, 'colsample_bytree': 0.7077131245309082}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,549] Trial 50 finished with value: 0.333333 and parameters: {'max_depth': 5, 'learning_rate': 0.23786536533287989, 'subsample': 0.981987752702353, 'colsample_bytree': 0.791331491949254}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,666] Trial 51 finished with value: 0.333333 and parameters: {'max_depth': 12, 'learning_rate': 0.25407379705011307, 'subsample': 0.8198607894973922, 'colsample_bytree': 0.911940972807488}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,769] Trial 52 finished with value: 0.166667 and parameters: {'max_depth': 13, 'learning_rate': 0.2812371355036805, 'subsample': 0.7774060230930984, 'colsample_bytree': 0.9311977027377852}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,872] Trial 53 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.2514004827679746, 'subsample': 0.8004917805337276, 'colsample_bytree': 0.8964469220148988}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:02,980] Trial 54 finished with value: 0.166667 and parameters: {'max_depth': 10, 'learning_rate': 0.21163845924108743, 'subsample': 0.8640769682221928, 'colsample_bytree': 0.8388598153020277}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:03,099] Trial 55 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.2848946919478636, 'subsample': 0.8382999794493875, 'colsample_bytree': 0.8694838715913725}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:03,219] Trial 56 finished with value: 0.333333 and parameters: {'max_depth': 18, 'learning_rate': 0.26642811903752794, 'subsample': 0.7511993756573384, 'colsample_bytree': 0.9494052159110445}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:03,321] Trial 57 finished with value: 0.166667 and parameters: {'max_depth': 13, 'learning_rate': 0.14028521128270088, 'subsample': 0.9296133659869718, 'colsample_bytree': 0.9824487665789334}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:03,482] Trial 58 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.24201408464392501, 'subsample': 0.810994144911234, 'colsample_bytree': 0.8839843852110999}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:03,595] Trial 59 finished with value: 0.166667 and parameters: {'max_depth': 12, 'learning_rate': 0.16740914186562394, 'subsample': 0.974419935833237, 'colsample_bytree': 0.7595602215591346}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:03,730] Trial 60 finished with value: 0.166667 and parameters: {'max_depth': 15, 'learning_rate': 0.22003854182566776, 'subsample': 0.8965308380253373, 'colsample_bytree': 0.8120692594891895}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:03,832] Trial 61 finished with value: 0.5 and parameters: {'max_depth': 9, 'learning_rate': 0.262751126857145, 'subsample': 0.9992761249204969, 'colsample_bytree': 0.772832818949511}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:03,958] Trial 62 finished with value: 0.333333 and parameters: {'max_depth': 8, 'learning_rate': 0.27168780985556645, 'subsample': 0.9903479773657441, 'colsample_bytree': 0.7674862368699752}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:04,074] Trial 63 finished with value: 0.166667 and parameters: {'max_depth': 11, 'learning_rate': 0.2775133555288682, 'subsample': 0.9649805007835395, 'colsample_bytree': 0.741552465193082}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:04,212] Trial 64 finished with value: 0.0 and parameters: {'max_depth': 8, 'learning_rate': 0.2913007361934555, 'subsample': 0.6036572617164276, 'colsample_bytree': 0.7871613730654848}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:04,364] Trial 65 finished with value: 0.333333 and parameters: {'max_depth': 5, 'learning_rate': 0.14750599934491543, 'subsample': 0.9859577694423125, 'colsample_bytree': 0.8624374306829429}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:04,548] Trial 66 finished with value: 0.166667 and parameters: {'max_depth': 17, 'learning_rate': 0.1200171906813816, 'subsample': 0.9542722271397558, 'colsample_bytree': 0.826602759910658}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:04,790] Trial 67 finished with value: 0.166667 and parameters: {'max_depth': 7, 'learning_rate': 0.2350443943992785, 'subsample': 0.8717550482414708, 'colsample_bytree': 0.9207471940792744}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:04,926] Trial 68 finished with value: 0.333333 and parameters: {'max_depth': 4, 'learning_rate': 0.24931016669254624, 'subsample': 0.6625460859959441, 'colsample_bytree': 0.7487131093943385}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:05,042] Trial 69 finished with value: 0.166667 and parameters: {'max_depth': 10, 'learning_rate': 0.13411020227001522, 'subsample': 0.9716718142502798, 'colsample_bytree': 0.8029473153640471}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-06-03 18:13:05,152] Trial 70 finished with value: 0.666667 and parameters: {'max_depth': 6, 'learning_rate': 0.1612015582272011, 'subsample': 0.7838554302753529, 'colsample_bytree': 0.7226859522203684}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:05,261] Trial 71 finished with value: 0.5 and parameters: {'max_depth': 6, 'learning_rate': 0.1798159087827458, 'subsample': 0.7780628380711053, 'colsample_bytree': 0.7092843488661001}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:05,489] Trial 72 finished with value: 0.333333 and parameters: {'max_depth': 7, 'learning_rate': 0.19193000600160015, 'subsample': 0.7939696993361578, 'colsample_bytree': 0.6751031223747466}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:05,627] Trial 73 finished with value: 0.333333 and parameters: {'max_depth': 3, 'learning_rate': 0.1568367627521597, 'subsample': 0.7605853001444616, 'colsample_bytree': 0.7238231278488518}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:05,740] Trial 74 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.10023657235619346, 'subsample': 0.8034474939604808, 'colsample_bytree': 0.7657197261350411}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:05,849] Trial 75 finished with value: 0.166667 and parameters: {'max_depth': 4, 'learning_rate': 0.12877886581613973, 'subsample': 0.9402811013838224, 'colsample_bytree': 0.7311327070208232}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:05,953] Trial 76 finished with value: 0.5 and parameters: {'max_depth': 20, 'learning_rate': 0.21344661491390324, 'subsample': 0.8192280142354947, 'colsample_bytree': 0.748332767867142}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:06,070] Trial 77 finished with value: 0.333333 and parameters: {'max_depth': 5, 'learning_rate': 0.16614167472692964, 'subsample': 0.6973504554101475, 'colsample_bytree': 0.7835827431137361}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:06,187] Trial 78 finished with value: 0.166667 and parameters: {'max_depth': 6, 'learning_rate': 0.1466683140747682, 'subsample': 0.7262455445874566, 'colsample_bytree': 0.7016014106844837}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:06,297] Trial 79 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.231768777606071, 'subsample': 0.8384332174030656, 'colsample_bytree': 0.9362025974637981}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:06,506] Trial 80 finished with value: 0.5 and parameters: {'max_depth': 11, 'learning_rate': 0.20512711737831327, 'subsample': 0.7715909143908884, 'colsample_bytree': 0.6806837040291455}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:06,660] Trial 81 finished with value: 0.333333 and parameters: {'max_depth': 19, 'learning_rate': 0.1476234465602683, 'subsample': 0.9865588927458158, 'colsample_bytree': 0.6477412595587599}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:06,793] Trial 82 finished with value: 0.333333 and parameters: {'max_depth': 19, 'learning_rate': 0.1602759452299641, 'subsample': 0.9798726525644046, 'colsample_bytree': 0.6623897271694149}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:06,895] Trial 83 finished with value: 0.5 and parameters: {'max_depth': 20, 'learning_rate': 0.12302698290521503, 'subsample': 0.9940379972703767, 'colsample_bytree': 0.9526078115993654}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:07,244] Trial 84 finished with value: 0.166667 and parameters: {'max_depth': 18, 'learning_rate': 0.13878496343506144, 'subsample': 0.9729231464796612, 'colsample_bytree': 0.7177278356124431}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:07,366] Trial 85 finished with value: 0.166667 and parameters: {'max_depth': 17, 'learning_rate': 0.18613328372606497, 'subsample': 0.9209081628785998, 'colsample_bytree': 0.6854500453509154}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:07,554] Trial 86 finished with value: 0.333333 and parameters: {'max_depth': 16, 'learning_rate': 0.2599868722041539, 'subsample': 0.95904493433993, 'colsample_bytree': 0.6978782766949286}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:07,662] Trial 87 finished with value: 0.333333 and parameters: {'max_depth': 19, 'learning_rate': 0.13185990204240652, 'subsample': 0.9888551721248716, 'colsample_bytree': 0.9089948772603895}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:07,779] Trial 88 finished with value: 0.5 and parameters: {'max_depth': 20, 'learning_rate': 0.24565817628145886, 'subsample': 0.8244009174921121, 'colsample_bytree': 0.6624534002057462}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:07,898] Trial 89 finished with value: 0.5 and parameters: {'max_depth': 13, 'learning_rate': 0.2763416670446124, 'subsample': 0.7801099789448418, 'colsample_bytree': 0.880589879375071}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:08,004] Trial 90 finished with value: 0.166667 and parameters: {'max_depth': 14, 'learning_rate': 0.1118943920257558, 'subsample': 0.945958890400778, 'colsample_bytree': 0.8997062004117559}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:08,134] Trial 91 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.07895010217599996, 'subsample': 0.9989693600972794, 'colsample_bytree': 0.719440634947432}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:08,251] Trial 92 finished with value: 0.333333 and parameters: {'max_depth': 17, 'learning_rate': 0.03570644472335167, 'subsample': 0.9784421387284068, 'colsample_bytree': 0.7252725526807744}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:08,361] Trial 93 finished with value: 0.166667 and parameters: {'max_depth': 7, 'learning_rate': 0.05621834780983674, 'subsample': 0.9644219779818487, 'colsample_bytree': 0.7761403317612359}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:08,518] Trial 94 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.08428720241328627, 'subsample': 0.9924322148344711, 'colsample_bytree': 0.7589186797749801}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:08,651] Trial 95 finished with value: 0.333333 and parameters: {'max_depth': 15, 'learning_rate': 0.013542180449328478, 'subsample': 0.9821672775735327, 'colsample_bytree': 0.7937895542601469}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:08,774] Trial 96 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.17368630683964198, 'subsample': 0.8474990192456313, 'colsample_bytree': 0.6740892322260377}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:08,892] Trial 97 finished with value: 0.5 and parameters: {'max_depth': 12, 'learning_rate': 0.15287824355213103, 'subsample': 0.7875324211448732, 'colsample_bytree': 0.7371134020134955}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:09,002] Trial 98 finished with value: 0.333333 and parameters: {'max_depth': 10, 'learning_rate': 0.28772280082597335, 'subsample': 0.7503107677134497, 'colsample_bytree': 0.9218641857331337}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:09,147] Trial 99 finished with value: 0.333333 and parameters: {'max_depth': 9, 'learning_rate': 0.10578274285916647, 'subsample': 0.807088125986339, 'colsample_bytree': 0.811469337049805}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:09,257] Trial 100 finished with value: 0.166667 and parameters: {'max_depth': 6, 'learning_rate': 0.06946272382318762, 'subsample': 0.9690405168414686, 'colsample_bytree': 0.7447013856334556}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:09,384] Trial 101 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.2503186074953259, 'subsample': 0.8128576922307117, 'colsample_bytree': 0.8976502204112609}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:09,558] Trial 102 finished with value: 0.333333 and parameters: {'max_depth': 14, 'learning_rate': 0.265208900961953, 'subsample': 0.7976047273203676, 'colsample_bytree': 0.9201455877420631}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:09,675] Trial 103 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.2705947951582912, 'subsample': 0.997933212880477, 'colsample_bytree': 0.705119722470823}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:09,787] Trial 104 finished with value: 0.166667 and parameters: {'max_depth': 15, 'learning_rate': 0.25615422731319704, 'subsample': 0.8284948405407089, 'colsample_bytree': 0.8898146106326362}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:09,899] Trial 105 finished with value: 0.166667 and parameters: {'max_depth': 17, 'learning_rate': 0.21918989312957193, 'subsample': 0.8578295966415246, 'colsample_bytree': 0.8359743928700721}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:10,052] Trial 106 finished with value: 0.333333 and parameters: {'max_depth': 5, 'learning_rate': 0.16321560996134635, 'subsample': 0.769801512090521, 'colsample_bytree': 0.8555160576991606}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:10,179] Trial 107 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.11872420598357175, 'subsample': 0.7873833119585876, 'colsample_bytree': 0.6895331019694576}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:10,297] Trial 108 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.12135277665896071, 'subsample': 0.7845866120213997, 'colsample_bytree': 0.6882978747767784}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:10,410] Trial 109 finished with value: 0.666667 and parameters: {'max_depth': 19, 'learning_rate': 0.11971331677510903, 'subsample': 0.7878376686189081, 'colsample_bytree': 0.6558864157351234}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:10,593] Trial 110 finished with value: 0.333333 and parameters: {'max_depth': 18, 'learning_rate': 0.11627420557411437, 'subsample': 0.7844846557179911, 'colsample_bytree': 0.6394814705713882}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:10,714] Trial 111 finished with value: 0.666667 and parameters: {'max_depth': 20, 'learning_rate': 0.12385936856034176, 'subsample': 0.7953395841259043, 'colsample_bytree': 0.689053859690822}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:10,852] Trial 112 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.09340954687919906, 'subsample': 0.7906377576812877, 'colsample_bytree': 0.6896582037546867}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:10,975] Trial 113 finished with value: 0.5 and parameters: {'max_depth': 20, 'learning_rate': 0.14034006603797985, 'subsample': 0.7619868319718153, 'colsample_bytree': 0.6510261926393982}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:11,090] Trial 114 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.12534838950574348, 'subsample': 0.813869260098296, 'colsample_bytree': 0.65666085045333}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:11,200] Trial 115 finished with value: 0.5 and parameters: {'max_depth': 20, 'learning_rate': 0.11823761209893756, 'subsample': 0.8027266727858493, 'colsample_bytree': 0.7132943951446447}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:11,324] Trial 116 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.09898840026633372, 'subsample': 0.770672739442581, 'colsample_bytree': 0.6687691410478274}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:11,483] Trial 117 finished with value: 0.333333 and parameters: {'max_depth': 20, 'learning_rate': 0.13501111441421657, 'subsample': 0.7451180651469478, 'colsample_bytree': 0.6335373227352984}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:11,611] Trial 118 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.11115343602176236, 'subsample': 0.7967263759357864, 'colsample_bytree': 0.6146507311218634}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:11,725] Trial 119 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.10444466667156695, 'subsample': 0.8374521267516343, 'colsample_bytree': 0.6822509934025168}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:11,836] Trial 120 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.10650463576263633, 'subsample': 0.8354202220946891, 'colsample_bytree': 0.68326725700749}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:11,970] Trial 121 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.09408778135480042, 'subsample': 0.8334121728613484, 'colsample_bytree': 0.6967054663898687}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:12,089] Trial 122 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.10536383074922367, 'subsample': 0.8436606512777995, 'colsample_bytree': 0.6837927172576485}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:12,222] Trial 123 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.08938550651820573, 'subsample': 0.8325004999252269, 'colsample_bytree': 0.6980233287633576}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:12,368] Trial 124 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.13084924129465478, 'subsample': 0.8226769703152437, 'colsample_bytree': 0.6717965557346889}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:12,586] Trial 125 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.09567771831667245, 'subsample': 0.7831075250397297, 'colsample_bytree': 0.688069886802087}. Best is trial 70 with value: 0.666667.\n",
      "[I 2025-06-03 18:13:12,722] Trial 126 finished with value: 0.833333 and parameters: {'max_depth': 17, 'learning_rate': 0.12006703650790619, 'subsample': 0.8070135350499084, 'colsample_bytree': 0.6791514182630046}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:12,834] Trial 127 finished with value: 0.666667 and parameters: {'max_depth': 17, 'learning_rate': 0.12157051424071635, 'subsample': 0.8392315086334461, 'colsample_bytree': 0.6563969534869136}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:12,948] Trial 128 finished with value: 0.666667 and parameters: {'max_depth': 17, 'learning_rate': 0.12175662309732056, 'subsample': 0.8379270870501428, 'colsample_bytree': 0.6549279715377484}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:13,055] Trial 129 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.12130740373740893, 'subsample': 0.8559899488427187, 'colsample_bytree': 0.6657977759427394}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:13,169] Trial 130 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.10516058999212187, 'subsample': 0.8782217381977, 'colsample_bytree': 0.6555764589624682}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:13,296] Trial 131 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.11354317911473548, 'subsample': 0.8335888349242435, 'colsample_bytree': 0.6794455051497653}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:13,413] Trial 132 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.11352519898989187, 'subsample': 0.8374965140316133, 'colsample_bytree': 0.6804170596955805}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:13,576] Trial 133 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.11485107892968657, 'subsample': 0.8334625639626841, 'colsample_bytree': 0.6801861968345839}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:13,699] Trial 134 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.11240022880191596, 'subsample': 0.8372745850424439, 'colsample_bytree': 0.6801401011590806}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:13,834] Trial 135 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.11548924135689377, 'subsample': 0.8647323871974057, 'colsample_bytree': 0.6326253351093162}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:13,952] Trial 136 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.10129668822161934, 'subsample': 0.8441414838436226, 'colsample_bytree': 0.6937118721373149}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:14,081] Trial 137 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.12428698013068387, 'subsample': 0.8209043617998617, 'colsample_bytree': 0.6769959260021787}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:14,194] Trial 138 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.08822165832474302, 'subsample': 0.8331066119488437, 'colsample_bytree': 0.6547083348001818}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:14,321] Trial 139 finished with value: 0.666667 and parameters: {'max_depth': 19, 'learning_rate': 0.12010582958207938, 'subsample': 0.8512614507029093, 'colsample_bytree': 0.6423094071944551}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:14,461] Trial 140 finished with value: 0.333333 and parameters: {'max_depth': 17, 'learning_rate': 0.10753816079982124, 'subsample': 0.8287714386153681, 'colsample_bytree': 0.7033789415787781}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:14,619] Trial 141 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.11255224009553284, 'subsample': 0.8381067080442862, 'colsample_bytree': 0.6817208000928737}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:14,726] Trial 142 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.12794875760459012, 'subsample': 0.8371216482578401, 'colsample_bytree': 0.6675831528685062}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:14,881] Trial 143 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.0960317713022022, 'subsample': 0.8073964612471433, 'colsample_bytree': 0.6823168255937148}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:15,021] Trial 144 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.10329603467891198, 'subsample': 0.8161151485231383, 'colsample_bytree': 0.6614366626635987}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:15,134] Trial 145 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.11197553507118274, 'subsample': 0.8642795261594265, 'colsample_bytree': 0.6929600049402904}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:15,268] Trial 146 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.11584401156553834, 'subsample': 0.8481632475920834, 'colsample_bytree': 0.6770621951201407}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:15,457] Trial 147 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.12199744994557205, 'subsample': 0.8279824820688616, 'colsample_bytree': 0.6702509173180646}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:15,690] Trial 148 finished with value: 0.666667 and parameters: {'max_depth': 17, 'learning_rate': 0.12964154476302076, 'subsample': 0.8404868439122808, 'colsample_bytree': 0.6889346764298719}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:15,828] Trial 149 finished with value: 0.166667 and parameters: {'max_depth': 18, 'learning_rate': 0.14320588694540534, 'subsample': 0.8577400916337757, 'colsample_bytree': 0.7098342261607367}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:15,963] Trial 150 finished with value: 0.666667 and parameters: {'max_depth': 19, 'learning_rate': 0.1353705119204083, 'subsample': 0.7997388646567859, 'colsample_bytree': 0.698722075960769}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:16,079] Trial 151 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.0701143174180563, 'subsample': 0.833812291139971, 'colsample_bytree': 0.6502201128497185}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:16,189] Trial 152 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.08657567324194716, 'subsample': 0.8244512917185929, 'colsample_bytree': 0.6536191112570197}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:16,337] Trial 153 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.09176836444474822, 'subsample': 0.8089663401480865, 'colsample_bytree': 0.6588036372657137}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:16,438] Trial 154 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.10699710694704254, 'subsample': 0.8316515639212585, 'colsample_bytree': 0.6785797200030097}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:16,633] Trial 155 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.07888390536472582, 'subsample': 0.8171068758411607, 'colsample_bytree': 0.6700223859578134}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:16,748] Trial 156 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.09888452674451824, 'subsample': 0.8728826586796173, 'colsample_bytree': 0.628994660441168}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:16,861] Trial 157 finished with value: 0.333333 and parameters: {'max_depth': 18, 'learning_rate': 0.11315088027448005, 'subsample': 0.7938878406131524, 'colsample_bytree': 0.6410335294926526}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:16,978] Trial 158 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.11897763819565878, 'subsample': 0.848606545603883, 'colsample_bytree': 0.6869242866057491}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:17,408] Trial 159 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.10994560150655061, 'subsample': 0.8410291456287579, 'colsample_bytree': 0.6644223785354425}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:17,671] Trial 160 finished with value: 0.5 and parameters: {'max_depth': 19, 'learning_rate': 0.12620846261986945, 'subsample': 0.7750442199729889, 'colsample_bytree': 0.6178509661135355}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:17,843] Trial 161 finished with value: 0.666667 and parameters: {'max_depth': 19, 'learning_rate': 0.1205658850762093, 'subsample': 0.8548016925084905, 'colsample_bytree': 0.6453212785887342}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:17,951] Trial 162 finished with value: 0.666667 and parameters: {'max_depth': 19, 'learning_rate': 0.10023410092925128, 'subsample': 0.8510385429397576, 'colsample_bytree': 0.6372075303337393}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:18,072] Trial 163 finished with value: 0.666667 and parameters: {'max_depth': 20, 'learning_rate': 0.11989318252335146, 'subsample': 0.7869555770588611, 'colsample_bytree': 0.6756306846783569}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:18,184] Trial 164 finished with value: 0.666667 and parameters: {'max_depth': 18, 'learning_rate': 0.10815925226757743, 'subsample': 0.8328424415703839, 'colsample_bytree': 0.6474952129873179}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:18,294] Trial 165 finished with value: 0.333333 and parameters: {'max_depth': 19, 'learning_rate': 0.09145550446341583, 'subsample': 0.824621721364387, 'colsample_bytree': 0.7029589344151306}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:18,425] Trial 166 finished with value: 0.833333 and parameters: {'max_depth': 16, 'learning_rate': 0.13080191381075493, 'subsample': 0.8040602582491961, 'colsample_bytree': 0.6575347015974907}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:18,611] Trial 167 finished with value: 0.833333 and parameters: {'max_depth': 16, 'learning_rate': 0.13395789591213944, 'subsample': 0.808510815181727, 'colsample_bytree': 0.6609272373950286}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:18,749] Trial 168 finished with value: 0.666667 and parameters: {'max_depth': 17, 'learning_rate': 0.1356514404285899, 'subsample': 0.8078696812420662, 'colsample_bytree': 0.6823278751955304}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:18,860] Trial 169 finished with value: 0.666667 and parameters: {'max_depth': 16, 'learning_rate': 0.13001579612248448, 'subsample': 0.7980604275574978, 'colsample_bytree': 0.6928873322014855}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:18,978] Trial 170 finished with value: 0.666667 and parameters: {'max_depth': 16, 'learning_rate': 0.14118325823716088, 'subsample': 0.8154320436370966, 'colsample_bytree': 0.6634231434563033}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:19,122] Trial 171 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.12749835361426232, 'subsample': 0.7912556005410107, 'colsample_bytree': 0.6587207178054065}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:19,260] Trial 172 finished with value: 0.666667 and parameters: {'max_depth': 17, 'learning_rate': 0.11534109491489022, 'subsample': 0.7805480235921664, 'colsample_bytree': 0.6722053226035193}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:19,373] Trial 173 finished with value: 0.666667 and parameters: {'max_depth': 16, 'learning_rate': 0.1226563394642982, 'subsample': 0.8028436257586187, 'colsample_bytree': 0.6524344385469082}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:19,508] Trial 174 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.10254181663932635, 'subsample': 0.8198495816809868, 'colsample_bytree': 0.6826369098292963}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:19,677] Trial 175 finished with value: 0.5 and parameters: {'max_depth': 17, 'learning_rate': 0.11448166263212535, 'subsample': 0.7664275937402659, 'colsample_bytree': 0.6668094560491125}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:19,788] Trial 176 finished with value: 0.666667 and parameters: {'max_depth': 17, 'learning_rate': 0.13566524557512738, 'subsample': 0.8350208251703524, 'colsample_bytree': 0.6953442817807389}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:19,912] Trial 177 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.15339623396139576, 'subsample': 0.8444186411621439, 'colsample_bytree': 0.6759383041966471}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:20,073] Trial 178 finished with value: 0.5 and parameters: {'max_depth': 18, 'learning_rate': 0.10775125813898775, 'subsample': 0.8128608161419232, 'colsample_bytree': 0.6871467207009069}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:20,183] Trial 179 finished with value: 0.333333 and parameters: {'max_depth': 17, 'learning_rate': 0.13130286472570007, 'subsample': 0.8294644648908357, 'colsample_bytree': 0.7046457066549985}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:20,312] Trial 180 finished with value: 0.833333 and parameters: {'max_depth': 16, 'learning_rate': 0.12418313192965712, 'subsample': 0.8055224891460296, 'colsample_bytree': 0.6625432490161796}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:20,459] Trial 181 finished with value: 0.833333 and parameters: {'max_depth': 16, 'learning_rate': 0.12572298214988006, 'subsample': 0.8030387925354916, 'colsample_bytree': 0.6561810059210138}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:20,677] Trial 182 finished with value: 0.5 and parameters: {'max_depth': 15, 'learning_rate': 0.12364105494875803, 'subsample': 0.7927907780906579, 'colsample_bytree': 0.6624035545249359}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:20,808] Trial 183 finished with value: 0.833333 and parameters: {'max_depth': 16, 'learning_rate': 0.12544332167051134, 'subsample': 0.8039798498735686, 'colsample_bytree': 0.6736286785280866}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:20,942] Trial 184 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.12781069959110197, 'subsample': 0.8009277995949474, 'colsample_bytree': 0.6691181765782691}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:21,071] Trial 185 finished with value: 0.666667 and parameters: {'max_depth': 16, 'learning_rate': 0.14318426149605123, 'subsample': 0.7858473049972401, 'colsample_bytree': 0.6566621556248138}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:21,188] Trial 186 finished with value: 0.833333 and parameters: {'max_depth': 15, 'learning_rate': 0.11899784672637881, 'subsample': 0.8052879761966457, 'colsample_bytree': 0.6743080986631137}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:21,308] Trial 187 finished with value: 0.5 and parameters: {'max_depth': 15, 'learning_rate': 0.13482967684719033, 'subsample': 0.8043883886766438, 'colsample_bytree': 0.645051934105325}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:21,435] Trial 188 finished with value: 0.666667 and parameters: {'max_depth': 16, 'learning_rate': 0.12345469456379947, 'subsample': 0.7795598147300565, 'colsample_bytree': 0.6709249364283237}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:21,852] Trial 189 finished with value: 0.5 and parameters: {'max_depth': 15, 'learning_rate': 0.11833301837477718, 'subsample': 0.7932017423088646, 'colsample_bytree': 0.6914200394167608}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:21,986] Trial 190 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.13197876072881787, 'subsample': 0.808868219225366, 'colsample_bytree': 0.6244091548942506}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:22,108] Trial 191 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.11674736360768968, 'subsample': 0.8204912032976722, 'colsample_bytree': 0.6758422367539326}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:22,242] Trial 192 finished with value: 0.833333 and parameters: {'max_depth': 15, 'learning_rate': 0.12593191290990266, 'subsample': 0.7997465948391221, 'colsample_bytree': 0.683683166871436}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:22,381] Trial 193 finished with value: 0.333333 and parameters: {'max_depth': 15, 'learning_rate': 0.1256978102582293, 'subsample': 0.7996674586491382, 'colsample_bytree': 0.71500039769048}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:22,514] Trial 194 finished with value: 0.666667 and parameters: {'max_depth': 15, 'learning_rate': 0.1452063928905973, 'subsample': 0.7852365822336668, 'colsample_bytree': 0.6862223239863626}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:22,701] Trial 195 finished with value: 0.666667 and parameters: {'max_depth': 14, 'learning_rate': 0.13806302628844275, 'subsample': 0.8102808578390978, 'colsample_bytree': 0.6627331849129666}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:22,831] Trial 196 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.12315200742356024, 'subsample': 0.7943738125733582, 'colsample_bytree': 0.6983022503562669}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:22,948] Trial 197 finished with value: 0.5 and parameters: {'max_depth': 16, 'learning_rate': 0.10700133251447894, 'subsample': 0.7754467334159045, 'colsample_bytree': 0.6548580080290279}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:23,095] Trial 198 finished with value: 0.833333 and parameters: {'max_depth': 15, 'learning_rate': 0.12837330579008288, 'subsample': 0.803909057966361, 'colsample_bytree': 0.6741792885837137}. Best is trial 126 with value: 0.833333.\n",
      "[I 2025-06-03 18:13:23,206] Trial 199 finished with value: 0.833333 and parameters: {'max_depth': 14, 'learning_rate': 0.13022554677250056, 'subsample': 0.8036770889832663, 'colsample_bytree': 0.6723660436130288}. Best is trial 126 with value: 0.833333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 17, 'learning_rate': 0.12006703650790619, 'subsample': 0.8070135350499084, 'colsample_bytree': 0.6791514182630046}\n",
      "Best accuracy: 0.833333\n"
     ]
    }
   ],
   "source": [
    "# ====== 1. labeling ======\n",
    "\n",
    "def to_soft_labels(y, grand_truth):\n",
    "    num_classes = grand_truth.shape[1]\n",
    "    soft_labels = np.zeros((y.size, num_classes))\n",
    "    for i, label in enumerate(y):\n",
    "        soft_labels[i,:] = grand_truth[label]\n",
    "    return soft_labels\n",
    "\n",
    "label_GC = to_soft_labels(y_xgb, grand_truth=np.array([[1.,0,0],[0,1.,0],[0,0,1.]]))\n",
    "overlap_w = 0.05\n",
    "label_SFC = to_soft_labels(y_xgb, grand_truth=np.array([[1.-overlap_w,overlap_w,0],[overlap_w,1.-2*overlap_w,overlap_w],[0,overlap_w,1.-overlap_w]]))\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid, GC_train, GC_valid, SFC_train, SFC_valid = train_test_split(\n",
    "    X_xgb, y_xgb, label_GC,label_SFC, test_size=0.05, random_state=42, stratify=y_xgb\n",
    ")\n",
    "\n",
    "# DMatrix construction\n",
    "dtrain_GC = xgb.DMatrix(X_train)\n",
    "dvalid_GC = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "dtrain_SFC = xgb.DMatrix(X_train)\n",
    "dvalid_SFC = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "\n",
    "\n",
    "# ====== 2. custom loss function ======\n",
    "\n",
    "def make_soft_ce(soft_labels):\n",
    "    def soft_ce(preds, dtrain):\n",
    "        num_class = soft_labels.shape[1]\n",
    "        preds = preds.reshape(-1, num_class)\n",
    "        probs = softmax(preds, axis=1)\n",
    "        grad = probs - soft_labels\n",
    "        hess = probs * (1 - probs)\n",
    "        return grad.ravel(), hess.ravel()\n",
    "    return soft_ce\n",
    "\n",
    "\n",
    "\n",
    "# ====== 3. accuracy ======\n",
    "\n",
    "def custom_eval_accuracy(preds, dtrain):\n",
    "    num_class = preds.shape[1]\n",
    "    preds = preds.reshape(-1, num_class)\n",
    "    labels = dtrain.get_label().astype(int)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    acc = (y_pred == labels).mean()\n",
    "    return 'accuracy', acc\n",
    "\n",
    "# ====== 4. Optuna tuning ======\n",
    "\n",
    "def objective_GC(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'num_class': 3,\n",
    "        'objective': 'multi:softprob',  # dummy loss fun\n",
    "        'verbosity': 0,\n",
    "    }\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain_GC,\n",
    "        num_boost_round=100,\n",
    "        evals=[(dvalid_GC, \"valid\")],\n",
    "        obj=make_soft_ce(GC_train),\n",
    "        feval=custom_eval_accuracy,\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    return bst.best_score  # accuracy\n",
    "\n",
    "def objective_SFC(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'num_class': 3,\n",
    "        'objective': 'multi:softprob',  # dummy loss fun\n",
    "        'verbosity': 0,\n",
    "    }\n",
    "    \n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain_SFC,\n",
    "        num_boost_round=100,\n",
    "        evals=[(dvalid_SFC, \"valid\")],\n",
    "        obj=make_soft_ce(SFC_train),\n",
    "        feval=custom_eval_accuracy,\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    return bst.best_score  # accuracy\n",
    "\n",
    "study_GC = optuna.create_study(direction=\"maximize\")\n",
    "study_GC.optimize(objective_GC, n_trials=200)\n",
    "print(\"Best params:\", study_GC.best_params)\n",
    "print(\"Best accuracy:\", study_GC.best_value)\n",
    "\n",
    "study_SFC = optuna.create_study(direction=\"maximize\")\n",
    "study_SFC.optimize(objective_SFC, n_trials=200)\n",
    "print(\"Best params:\", study_SFC.best_params)\n",
    "print(\"Best accuracy:\", study_SFC.best_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5414eb47-97b7-476d-968a-f7ff24a29adb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (GC): {'max_depth': 12, 'learning_rate': 0.2440960599328786, 'subsample': 0.9985831849755107, 'colsample_bytree': 0.6462111208311844, 'num_class': 3, 'objective': 'multi:softprob', 'verbosity': 0}\n",
      "Best hyperparameters (SFC): {'max_depth': 17, 'learning_rate': 0.12006703650790619, 'subsample': 0.8070135350499084, 'colsample_bytree': 0.6791514182630046, 'num_class': 3, 'objective': 'multi:softprob', 'verbosity': 0}\n",
      "[0]\tvalid-mlogloss:0.96453\tvalid-accuracy:0.63636\n",
      "[1]\tvalid-mlogloss:0.97764\tvalid-accuracy:0.72727\n",
      "[2]\tvalid-mlogloss:1.00667\tvalid-accuracy:0.72727\n",
      "[3]\tvalid-mlogloss:1.05318\tvalid-accuracy:0.72727\n",
      "[4]\tvalid-mlogloss:1.05295\tvalid-accuracy:0.72727\n",
      "[5]\tvalid-mlogloss:1.06374\tvalid-accuracy:0.63636\n",
      "[6]\tvalid-mlogloss:1.08301\tvalid-accuracy:0.72727\n",
      "[7]\tvalid-mlogloss:1.13381\tvalid-accuracy:0.72727\n",
      "[8]\tvalid-mlogloss:1.13278\tvalid-accuracy:0.72727\n",
      "[9]\tvalid-mlogloss:1.11400\tvalid-accuracy:0.72727\n",
      "[0]\tvalid-mlogloss:1.09169\tvalid-accuracy:0.54546\n",
      "[1]\tvalid-mlogloss:1.10604\tvalid-accuracy:0.36364\n",
      "[2]\tvalid-mlogloss:1.08328\tvalid-accuracy:0.63636\n",
      "[3]\tvalid-mlogloss:1.07737\tvalid-accuracy:0.63636\n",
      "[4]\tvalid-mlogloss:1.07059\tvalid-accuracy:0.54546\n",
      "[5]\tvalid-mlogloss:1.06094\tvalid-accuracy:0.54546\n",
      "[6]\tvalid-mlogloss:1.04558\tvalid-accuracy:0.63636\n",
      "[7]\tvalid-mlogloss:1.04397\tvalid-accuracy:0.72727\n",
      "[8]\tvalid-mlogloss:1.02112\tvalid-accuracy:0.72727\n",
      "[9]\tvalid-mlogloss:1.00431\tvalid-accuracy:0.72727\n",
      "[10]\tvalid-mlogloss:1.01830\tvalid-accuracy:0.72727\n",
      "[0]\tvalid-mlogloss:1.00764\tvalid-accuracy:0.36364\n",
      "[1]\tvalid-mlogloss:1.00649\tvalid-accuracy:0.45454\n",
      "[2]\tvalid-mlogloss:0.98218\tvalid-accuracy:0.45454\n",
      "[3]\tvalid-mlogloss:0.90528\tvalid-accuracy:0.45454\n",
      "[4]\tvalid-mlogloss:0.90409\tvalid-accuracy:0.45454\n",
      "[5]\tvalid-mlogloss:0.95534\tvalid-accuracy:0.54546\n",
      "[6]\tvalid-mlogloss:0.93072\tvalid-accuracy:0.54546\n",
      "[7]\tvalid-mlogloss:0.98072\tvalid-accuracy:0.54546\n",
      "[8]\tvalid-mlogloss:0.98326\tvalid-accuracy:0.54546\n",
      "[9]\tvalid-mlogloss:0.96274\tvalid-accuracy:0.45454\n",
      "[0]\tvalid-mlogloss:1.05470\tvalid-accuracy:0.54546\n",
      "[1]\tvalid-mlogloss:1.03179\tvalid-accuracy:0.45454\n",
      "[2]\tvalid-mlogloss:0.98011\tvalid-accuracy:0.63636\n",
      "[3]\tvalid-mlogloss:0.98665\tvalid-accuracy:0.54546\n",
      "[4]\tvalid-mlogloss:0.98718\tvalid-accuracy:0.54546\n",
      "[5]\tvalid-mlogloss:0.97815\tvalid-accuracy:0.45454\n",
      "[6]\tvalid-mlogloss:0.95677\tvalid-accuracy:0.45454\n",
      "[7]\tvalid-mlogloss:0.93120\tvalid-accuracy:0.45454\n",
      "[8]\tvalid-mlogloss:0.90849\tvalid-accuracy:0.45454\n",
      "[9]\tvalid-mlogloss:0.90161\tvalid-accuracy:0.45454\n",
      "[10]\tvalid-mlogloss:0.91834\tvalid-accuracy:0.45454\n",
      "[0]\tvalid-mlogloss:0.96508\tvalid-accuracy:0.54546\n",
      "[1]\tvalid-mlogloss:0.96165\tvalid-accuracy:0.45454\n",
      "[2]\tvalid-mlogloss:0.97433\tvalid-accuracy:0.54546\n",
      "[3]\tvalid-mlogloss:0.99430\tvalid-accuracy:0.54546\n",
      "[4]\tvalid-mlogloss:1.01541\tvalid-accuracy:0.54546\n",
      "[5]\tvalid-mlogloss:1.04424\tvalid-accuracy:0.54546\n",
      "[6]\tvalid-mlogloss:1.05483\tvalid-accuracy:0.54546\n",
      "[7]\tvalid-mlogloss:1.04209\tvalid-accuracy:0.54546\n",
      "[8]\tvalid-mlogloss:1.04452\tvalid-accuracy:0.54546\n",
      "[9]\tvalid-mlogloss:1.07357\tvalid-accuracy:0.54546\n",
      "[10]\tvalid-mlogloss:1.06009\tvalid-accuracy:0.54546\n",
      "[11]\tvalid-mlogloss:1.07697\tvalid-accuracy:0.54546\n",
      "[0]\tvalid-mlogloss:1.09269\tvalid-accuracy:0.36364\n",
      "[1]\tvalid-mlogloss:1.08964\tvalid-accuracy:0.36364\n",
      "[2]\tvalid-mlogloss:1.05391\tvalid-accuracy:0.36364\n",
      "[3]\tvalid-mlogloss:0.98677\tvalid-accuracy:0.54546\n",
      "[4]\tvalid-mlogloss:0.97800\tvalid-accuracy:0.45454\n",
      "[5]\tvalid-mlogloss:0.92748\tvalid-accuracy:0.63636\n",
      "[6]\tvalid-mlogloss:0.94287\tvalid-accuracy:0.63636\n",
      "[7]\tvalid-mlogloss:0.95244\tvalid-accuracy:0.63636\n",
      "[8]\tvalid-mlogloss:0.95353\tvalid-accuracy:0.45454\n",
      "[9]\tvalid-mlogloss:0.93248\tvalid-accuracy:0.54546\n",
      "[0]\tvalid-mlogloss:0.98583\tvalid-accuracy:0.45454\n",
      "[1]\tvalid-mlogloss:0.91277\tvalid-accuracy:0.54546\n",
      "[2]\tvalid-mlogloss:0.84593\tvalid-accuracy:0.72727\n",
      "[3]\tvalid-mlogloss:0.85121\tvalid-accuracy:0.72727\n",
      "[4]\tvalid-mlogloss:0.78716\tvalid-accuracy:0.72727\n",
      "[5]\tvalid-mlogloss:0.81871\tvalid-accuracy:0.63636\n",
      "[6]\tvalid-mlogloss:0.81972\tvalid-accuracy:0.63636\n",
      "[7]\tvalid-mlogloss:0.81715\tvalid-accuracy:0.63636\n",
      "[8]\tvalid-mlogloss:0.82141\tvalid-accuracy:0.63636\n",
      "[9]\tvalid-mlogloss:0.81490\tvalid-accuracy:0.72727\n",
      "[10]\tvalid-mlogloss:0.79397\tvalid-accuracy:0.72727\n",
      "[0]\tvalid-mlogloss:1.06308\tvalid-accuracy:0.45454\n",
      "[1]\tvalid-mlogloss:1.03221\tvalid-accuracy:0.45454\n",
      "[2]\tvalid-mlogloss:1.01711\tvalid-accuracy:0.54546\n",
      "[3]\tvalid-mlogloss:0.98250\tvalid-accuracy:0.54546\n",
      "[4]\tvalid-mlogloss:0.93898\tvalid-accuracy:0.54546\n",
      "[5]\tvalid-mlogloss:0.91679\tvalid-accuracy:0.63636\n",
      "[6]\tvalid-mlogloss:0.92274\tvalid-accuracy:0.63636\n",
      "[7]\tvalid-mlogloss:0.92770\tvalid-accuracy:0.54546\n",
      "[8]\tvalid-mlogloss:0.91580\tvalid-accuracy:0.54546\n",
      "[9]\tvalid-mlogloss:0.89140\tvalid-accuracy:0.63636\n",
      "[0]\tvalid-mlogloss:0.95423\tvalid-accuracy:0.63636\n",
      "[1]\tvalid-mlogloss:0.91192\tvalid-accuracy:0.63636\n",
      "[2]\tvalid-mlogloss:0.88464\tvalid-accuracy:0.72727\n",
      "[3]\tvalid-mlogloss:0.90332\tvalid-accuracy:0.72727\n",
      "[4]\tvalid-mlogloss:0.90494\tvalid-accuracy:0.72727\n",
      "[5]\tvalid-mlogloss:0.87785\tvalid-accuracy:0.63636\n",
      "[6]\tvalid-mlogloss:0.90749\tvalid-accuracy:0.63636\n",
      "[7]\tvalid-mlogloss:0.91643\tvalid-accuracy:0.63636\n",
      "[8]\tvalid-mlogloss:0.91554\tvalid-accuracy:0.63636\n",
      "[9]\tvalid-mlogloss:0.89173\tvalid-accuracy:0.63636\n",
      "[0]\tvalid-mlogloss:1.00511\tvalid-accuracy:0.72727\n",
      "[1]\tvalid-mlogloss:0.94337\tvalid-accuracy:0.63636\n",
      "[2]\tvalid-mlogloss:0.91233\tvalid-accuracy:0.72727\n",
      "[3]\tvalid-mlogloss:0.91555\tvalid-accuracy:0.63636\n",
      "[4]\tvalid-mlogloss:0.91461\tvalid-accuracy:0.63636\n",
      "[5]\tvalid-mlogloss:0.89287\tvalid-accuracy:0.63636\n",
      "[6]\tvalid-mlogloss:0.86775\tvalid-accuracy:0.72727\n",
      "[7]\tvalid-mlogloss:0.85711\tvalid-accuracy:0.72727\n",
      "[8]\tvalid-mlogloss:0.84223\tvalid-accuracy:0.72727\n",
      "[9]\tvalid-mlogloss:0.84954\tvalid-accuracy:0.63636\n",
      "[10]\tvalid-mlogloss:0.85225\tvalid-accuracy:0.63636\n",
      "[11]\tvalid-mlogloss:0.85270\tvalid-accuracy:0.63636\n",
      "[0]\tvalid-mlogloss:1.08173\tvalid-accuracy:0.36364\n",
      "[1]\tvalid-mlogloss:1.09775\tvalid-accuracy:0.27273\n",
      "[2]\tvalid-mlogloss:1.01528\tvalid-accuracy:0.54546\n",
      "[3]\tvalid-mlogloss:1.01587\tvalid-accuracy:0.54546\n",
      "[4]\tvalid-mlogloss:0.93632\tvalid-accuracy:0.54546\n",
      "[5]\tvalid-mlogloss:0.90380\tvalid-accuracy:0.54546\n",
      "[6]\tvalid-mlogloss:0.89490\tvalid-accuracy:0.63636\n",
      "[7]\tvalid-mlogloss:0.91375\tvalid-accuracy:0.63636\n",
      "[8]\tvalid-mlogloss:0.92616\tvalid-accuracy:0.54546\n",
      "[9]\tvalid-mlogloss:0.93574\tvalid-accuracy:0.63636\n",
      "[10]\tvalid-mlogloss:0.94264\tvalid-accuracy:0.63636\n",
      "[0]\tvalid-mlogloss:1.01910\tvalid-accuracy:0.54546\n",
      "[1]\tvalid-mlogloss:0.98127\tvalid-accuracy:0.72727\n",
      "[2]\tvalid-mlogloss:0.93711\tvalid-accuracy:0.72727\n",
      "[3]\tvalid-mlogloss:0.89667\tvalid-accuracy:0.63636\n",
      "[4]\tvalid-mlogloss:0.86492\tvalid-accuracy:0.72727\n",
      "[5]\tvalid-mlogloss:0.85204\tvalid-accuracy:0.72727\n",
      "[6]\tvalid-mlogloss:0.84130\tvalid-accuracy:0.72727\n",
      "[7]\tvalid-mlogloss:0.82635\tvalid-accuracy:0.72727\n",
      "[8]\tvalid-mlogloss:0.80781\tvalid-accuracy:0.63636\n",
      "[9]\tvalid-mlogloss:0.79574\tvalid-accuracy:0.72727\n",
      "[10]\tvalid-mlogloss:0.80985\tvalid-accuracy:0.72727\n",
      "[0]\tvalid-mlogloss:1.01100\tvalid-accuracy:0.54546\n",
      "[1]\tvalid-mlogloss:0.98923\tvalid-accuracy:0.54546\n",
      "[2]\tvalid-mlogloss:1.01401\tvalid-accuracy:0.54546\n",
      "[3]\tvalid-mlogloss:0.97158\tvalid-accuracy:0.45454\n",
      "[4]\tvalid-mlogloss:0.98001\tvalid-accuracy:0.63636\n",
      "[5]\tvalid-mlogloss:1.03249\tvalid-accuracy:0.63636\n",
      "[6]\tvalid-mlogloss:1.05974\tvalid-accuracy:0.72727\n",
      "[7]\tvalid-mlogloss:1.05618\tvalid-accuracy:0.72727\n",
      "[8]\tvalid-mlogloss:1.06803\tvalid-accuracy:0.72727\n",
      "[9]\tvalid-mlogloss:1.10717\tvalid-accuracy:0.72727\n",
      "[10]\tvalid-mlogloss:1.11625\tvalid-accuracy:0.63636\n",
      "[11]\tvalid-mlogloss:1.12784\tvalid-accuracy:0.63636\n",
      "[12]\tvalid-mlogloss:1.15847\tvalid-accuracy:0.72727\n",
      "[13]\tvalid-mlogloss:1.18351\tvalid-accuracy:0.72727\n",
      "[0]\tvalid-mlogloss:1.09518\tvalid-accuracy:0.36364\n",
      "[1]\tvalid-mlogloss:1.08196\tvalid-accuracy:0.54546\n",
      "[2]\tvalid-mlogloss:1.02897\tvalid-accuracy:0.63636\n",
      "[3]\tvalid-mlogloss:1.03763\tvalid-accuracy:0.63636\n",
      "[4]\tvalid-mlogloss:1.02464\tvalid-accuracy:0.72727\n",
      "[5]\tvalid-mlogloss:1.02615\tvalid-accuracy:0.63636\n",
      "[6]\tvalid-mlogloss:1.01890\tvalid-accuracy:0.63636\n",
      "[7]\tvalid-mlogloss:1.02689\tvalid-accuracy:0.63636\n",
      "[8]\tvalid-mlogloss:1.02460\tvalid-accuracy:0.63636\n",
      "[9]\tvalid-mlogloss:1.00448\tvalid-accuracy:0.63636\n",
      "[0]\tvalid-mlogloss:0.97424\tvalid-accuracy:0.63636\n",
      "[1]\tvalid-mlogloss:0.86079\tvalid-accuracy:0.72727\n",
      "[2]\tvalid-mlogloss:0.81843\tvalid-accuracy:0.63636\n",
      "[3]\tvalid-mlogloss:0.75363\tvalid-accuracy:0.72727\n",
      "[4]\tvalid-mlogloss:0.71900\tvalid-accuracy:0.81818\n",
      "[5]\tvalid-mlogloss:0.67764\tvalid-accuracy:0.81818\n",
      "[6]\tvalid-mlogloss:0.64438\tvalid-accuracy:0.81818\n",
      "[7]\tvalid-mlogloss:0.60545\tvalid-accuracy:0.81818\n",
      "[8]\tvalid-mlogloss:0.60366\tvalid-accuracy:0.81818\n",
      "[9]\tvalid-mlogloss:0.57908\tvalid-accuracy:0.72727\n",
      "[10]\tvalid-mlogloss:0.55128\tvalid-accuracy:0.81818\n",
      "[0]\tvalid-mlogloss:1.04849\tvalid-accuracy:0.63636\n",
      "[1]\tvalid-mlogloss:0.98693\tvalid-accuracy:0.63636\n",
      "[2]\tvalid-mlogloss:0.94127\tvalid-accuracy:0.63636\n",
      "[3]\tvalid-mlogloss:0.91536\tvalid-accuracy:0.72727\n",
      "[4]\tvalid-mlogloss:0.85249\tvalid-accuracy:0.81818\n",
      "[5]\tvalid-mlogloss:0.81557\tvalid-accuracy:0.72727\n",
      "[6]\tvalid-mlogloss:0.80084\tvalid-accuracy:0.81818\n",
      "[7]\tvalid-mlogloss:0.78200\tvalid-accuracy:0.81818\n",
      "[8]\tvalid-mlogloss:0.75072\tvalid-accuracy:0.81818\n",
      "[9]\tvalid-mlogloss:0.74261\tvalid-accuracy:0.81818\n",
      "[10]\tvalid-mlogloss:0.73381\tvalid-accuracy:0.81818\n",
      "[0]\tvalid-mlogloss:0.94068\tvalid-accuracy:0.70000\n",
      "[1]\tvalid-mlogloss:0.85298\tvalid-accuracy:0.80000\n",
      "[2]\tvalid-mlogloss:0.83276\tvalid-accuracy:0.70000\n",
      "[3]\tvalid-mlogloss:0.84262\tvalid-accuracy:0.70000\n",
      "[4]\tvalid-mlogloss:0.84697\tvalid-accuracy:0.70000\n",
      "[5]\tvalid-mlogloss:0.84278\tvalid-accuracy:0.70000\n",
      "[6]\tvalid-mlogloss:0.86282\tvalid-accuracy:0.50000\n",
      "[7]\tvalid-mlogloss:0.89114\tvalid-accuracy:0.50000\n",
      "[8]\tvalid-mlogloss:0.93153\tvalid-accuracy:0.50000\n",
      "[9]\tvalid-mlogloss:0.92767\tvalid-accuracy:0.50000\n",
      "[10]\tvalid-mlogloss:0.93243\tvalid-accuracy:0.50000\n",
      "[11]\tvalid-mlogloss:0.92527\tvalid-accuracy:0.50000\n",
      "[12]\tvalid-mlogloss:0.91485\tvalid-accuracy:0.50000\n",
      "[13]\tvalid-mlogloss:0.92656\tvalid-accuracy:0.50000\n",
      "[14]\tvalid-mlogloss:0.91316\tvalid-accuracy:0.50000\n",
      "[15]\tvalid-mlogloss:0.89704\tvalid-accuracy:0.60000\n",
      "[0]\tvalid-mlogloss:1.03431\tvalid-accuracy:0.60000\n",
      "[1]\tvalid-mlogloss:1.00435\tvalid-accuracy:0.60000\n",
      "[2]\tvalid-mlogloss:0.94493\tvalid-accuracy:0.50000\n",
      "[3]\tvalid-mlogloss:0.89241\tvalid-accuracy:0.70000\n",
      "[4]\tvalid-mlogloss:0.87062\tvalid-accuracy:0.70000\n",
      "[5]\tvalid-mlogloss:0.86562\tvalid-accuracy:0.80000\n",
      "[6]\tvalid-mlogloss:0.86699\tvalid-accuracy:0.70000\n",
      "[7]\tvalid-mlogloss:0.86392\tvalid-accuracy:0.80000\n",
      "[8]\tvalid-mlogloss:0.83847\tvalid-accuracy:0.70000\n",
      "[9]\tvalid-mlogloss:0.80608\tvalid-accuracy:0.80000\n",
      "[10]\tvalid-mlogloss:0.81174\tvalid-accuracy:0.80000\n",
      "[11]\tvalid-mlogloss:0.79125\tvalid-accuracy:0.80000\n",
      "[12]\tvalid-mlogloss:0.79958\tvalid-accuracy:0.80000\n",
      "[0]\tvalid-mlogloss:0.97253\tvalid-accuracy:0.80000\n",
      "[1]\tvalid-mlogloss:0.80254\tvalid-accuracy:0.80000\n",
      "[2]\tvalid-mlogloss:0.78188\tvalid-accuracy:0.80000\n",
      "[3]\tvalid-mlogloss:0.79605\tvalid-accuracy:0.60000\n",
      "[4]\tvalid-mlogloss:0.80850\tvalid-accuracy:0.50000\n",
      "[5]\tvalid-mlogloss:0.80055\tvalid-accuracy:0.60000\n",
      "[6]\tvalid-mlogloss:0.74262\tvalid-accuracy:0.60000\n",
      "[7]\tvalid-mlogloss:0.74357\tvalid-accuracy:0.60000\n",
      "[8]\tvalid-mlogloss:0.70266\tvalid-accuracy:0.70000\n",
      "[9]\tvalid-mlogloss:0.68391\tvalid-accuracy:0.80000\n",
      "[10]\tvalid-mlogloss:0.68607\tvalid-accuracy:0.80000\n",
      "[11]\tvalid-mlogloss:0.69304\tvalid-accuracy:0.70000\n",
      "[12]\tvalid-mlogloss:0.71881\tvalid-accuracy:0.70000\n",
      "[13]\tvalid-mlogloss:0.72332\tvalid-accuracy:0.70000\n",
      "[0]\tvalid-mlogloss:1.03894\tvalid-accuracy:0.70000\n",
      "[1]\tvalid-mlogloss:1.00528\tvalid-accuracy:0.60000\n",
      "[2]\tvalid-mlogloss:0.95812\tvalid-accuracy:0.70000\n",
      "[3]\tvalid-mlogloss:0.95600\tvalid-accuracy:0.60000\n",
      "[4]\tvalid-mlogloss:0.96198\tvalid-accuracy:0.70000\n",
      "[5]\tvalid-mlogloss:0.93939\tvalid-accuracy:0.50000\n",
      "[6]\tvalid-mlogloss:0.91495\tvalid-accuracy:0.50000\n",
      "[7]\tvalid-mlogloss:0.91914\tvalid-accuracy:0.40000\n",
      "[8]\tvalid-mlogloss:0.91735\tvalid-accuracy:0.40000\n",
      "[9]\tvalid-mlogloss:0.90548\tvalid-accuracy:0.50000\n",
      "[10]\tvalid-mlogloss:0.89490\tvalid-accuracy:0.60000\n",
      "[11]\tvalid-mlogloss:0.88611\tvalid-accuracy:0.60000\n",
      "[12]\tvalid-mlogloss:0.87636\tvalid-accuracy:0.50000\n",
      "[13]\tvalid-mlogloss:0.88189\tvalid-accuracy:0.50000\n",
      "[14]\tvalid-mlogloss:0.88950\tvalid-accuracy:0.50000\n",
      "[15]\tvalid-mlogloss:0.89463\tvalid-accuracy:0.50000\n",
      "[16]\tvalid-mlogloss:0.90216\tvalid-accuracy:0.50000\n",
      "[17]\tvalid-mlogloss:0.90212\tvalid-accuracy:0.50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV0</th>\n",
       "      <th>CV1</th>\n",
       "      <th>CV2</th>\n",
       "      <th>CV3</th>\n",
       "      <th>CV4</th>\n",
       "      <th>CV5</th>\n",
       "      <th>CV6</th>\n",
       "      <th>CV7</th>\n",
       "      <th>CV8</th>\n",
       "      <th>CV9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GC</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFC</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CV0       CV1       CV2       CV3       CV4       CV5       CV6  \\\n",
       "GC   0.727273  0.454545  0.545455  0.727273  0.636364  0.545455  0.727273   \n",
       "SFC  0.727273  0.454545  0.454545  0.545455  0.636364  0.727273  0.636364   \n",
       "\n",
       "          CV7  CV8  CV9  \n",
       "GC   0.818182  0.7  0.7  \n",
       "SFC  0.818182  0.8  0.5  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- reevalation based on best hyperparameters ---\n",
    "best_params_GC = study_GC.best_params.copy()  # 例: study は optuna.create_study() の結果\n",
    "best_params_GC.update({\n",
    "    'num_class': 3,\n",
    "    'objective': 'multi:softprob',\n",
    "    'verbosity': 0\n",
    "})\n",
    "\n",
    "best_params_SFC = study_SFC.best_params.copy()  # 例: study は optuna.create_study() の結果\n",
    "best_params_SFC.update({\n",
    "    'num_class': 3,\n",
    "    'objective': 'multi:softprob',\n",
    "    'verbosity': 0\n",
    "})\n",
    "\n",
    "print(\"Best hyperparameters (GC):\", best_params_GC)\n",
    "print(\"Best hyperparameters (SFC):\", best_params_SFC)\n",
    "\n",
    "N_CV = 10\n",
    "cv = list(StratifiedKFold(n_splits = N_CV, shuffle = True, random_state = 42).split(X_xgb, y_xgb))\n",
    "feature_names = [f\"feature{i+1}\" for i in range(X_xgb.shape[1])]\n",
    "CV_names = [f\"CV{i}\" for i in range(N_CV)]\n",
    "df_importance_GC = pd.DataFrame(columns=CV_names, index=feature_names)\n",
    "df_acc = pd.DataFrame(columns=CV_names, index=['GC','SFC'])\n",
    "df_importance_SFC = pd.DataFrame(columns=CV_names, index=feature_names)\n",
    "df_importance_Diff = pd.DataFrame(columns=CV_names, index=feature_names)\n",
    "\n",
    "label_GC = to_soft_labels(y_xgb, grand_truth=np.array([[1.,0,0],[0,1.,0],[0,0,1.]]))\n",
    "overlap_w = 0.05\n",
    "label_SFC = to_soft_labels(y_xgb, grand_truth=np.array([[1.-overlap_w,overlap_w,0],[overlap_w,1.-2*overlap_w,overlap_w],[0,overlap_w,1.-overlap_w]]))\n",
    "\n",
    "for nfold, (train_index, valid_index) in enumerate(cv):\n",
    "    X_tr, y_tr = X_xgb[train_index], y_xgb[train_index]\n",
    "    X_va, y_va = X_xgb[valid_index], y_xgb[valid_index]\n",
    "    label_GC_tr, label_GC_va = label_GC[train_index], label_GC[valid_index]\n",
    "    label_SFC_tr, label_SFC_va = label_SFC[train_index], label_SFC[valid_index]\n",
    "    dtrain = xgb.DMatrix(X_tr,feature_names=feature_names)\n",
    "    dvalid = xgb.DMatrix(X_va, label=y_va,feature_names=feature_names)\n",
    "    \n",
    "    bst_GC_final = xgb.train(\n",
    "        best_params_GC,\n",
    "        dtrain,\n",
    "        num_boost_round=100,\n",
    "        evals=[(dvalid, \"valid\")],\n",
    "        obj=make_soft_ce(label_GC_tr),\n",
    "        feval=custom_eval_accuracy,\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "\n",
    "    bst_SFC_final = xgb.train(\n",
    "        best_params_SFC,\n",
    "        dtrain,\n",
    "        num_boost_round=100,\n",
    "        evals=[(dvalid, \"valid\")],\n",
    "        obj=make_soft_ce(label_SFC_tr),\n",
    "        feval=custom_eval_accuracy,\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "\n",
    "    # class probs（after softmax）\n",
    "    probs_GC = bst_GC_final.predict(dvalid)  # shape: (n_samples, num_class)\n",
    "    probs_SFC = bst_SFC_final.predict(dvalid)  # shape: (n_samples, num_class)\n",
    "\n",
    "    # class pred（class with highest prob）\n",
    "    y_preds_GC = np.argmax(probs_GC, axis=1)\n",
    "    y_preds_SFC = np.argmax(probs_SFC, axis=1)\n",
    "    \n",
    "    acc_GC = accuracy_score(y_va, y_preds_GC)\n",
    "    acc_SFC = accuracy_score(y_va, y_preds_SFC)\n",
    "\n",
    "    # gain features\n",
    "    cols = list(df_20dims.drop('patient number', axis = 1).columns)\n",
    "    f_importance_GC = pd.DataFrame([bst_GC_final.get_score(importance_type='gain')]).T.to_numpy().ravel()\n",
    "    f_importance_GC = f_importance_GC / np.sum(f_importance_GC)\n",
    "    f_importance_SFC = pd.DataFrame([bst_SFC_final.get_score(importance_type='gain')]).T.to_numpy().ravel()\n",
    "    f_importance_SFC = f_importance_SFC / np.sum(f_importance_SFC)\n",
    "    # after - before gain\n",
    "    df_importance_subtracted = f_importance_SFC - f_importance_GC\n",
    "    df_importance_subtracted = df_importance_subtracted / np.sum(np.abs(df_importance_subtracted))\n",
    "    df_importance_subtracted = pd.DataFrame({'feature':feature_names , 'importance':df_importance_subtracted})\n",
    "    \n",
    "    df_acc.at['GC',CV_names[nfold]] = acc_GC\n",
    "    df_acc.at['SFC',CV_names[nfold]] = acc_SFC\n",
    "    df_importance_GC[CV_names[nfold]] = f_importance_SFC\n",
    "    df_importance_SFC[CV_names[nfold]] = f_importance_SFC\n",
    "    df_importance_Diff[CV_names[nfold]] = f_importance_SFC - f_importance_GC\n",
    "\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf5f66f0-ec5a-4041-ae82-4e6c1b473964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV0</th>\n",
       "      <th>CV7</th>\n",
       "      <th>CV8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GC</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFC</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CV0       CV7  CV8\n",
       "GC   0.727273  0.818182  0.7\n",
       "SFC  0.727273  0.818182  0.8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_th = 2./3.\n",
    "df_acc.loc[:,(df_acc>=acc_th).sum(axis=0)==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fe7f48d-7807-4bb4-b471-324c6bbd5037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_importance_Diff_rank = pd.DataFrame(index = df_importance_Diff.index)\n",
    "for col in df_importance_Diff.columns:\n",
    "    rank = df_importance_Diff[col].rank(method=\"min\" , ascending=False)\n",
    "    df_importance_Diff_rank[col] = rank\n",
    "df_importance_Diff_rank\n",
    "print(((df_acc>=acc_th).sum(axis=0)==2).sum())\n",
    "df_importance_Diff_rank['rank_sum']=df_importance_Diff_rank.loc[:,(df_acc>=acc_th).sum(axis=0)==2].sum(axis=1)\n",
    "\n",
    "\n",
    "# high acc CV only\n",
    "df_acc.loc[:,(df_acc>=acc_th).sum(axis=0)==2]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(feature_names, df_importance_Diff_rank['rank_sum'])\n",
    "plt.xlabel(\"Importance_diff (SFC-GC) rank sum\")\n",
    "plt.title(\"Feature Importances (XGBoost) rank sum\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61d790d7-d974-42cf-be4f-30c0d789c80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV0</th>\n",
       "      <th>CV7</th>\n",
       "      <th>CV8</th>\n",
       "      <th>rank_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature16</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature13</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature20</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature19</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature15</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature8</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature11</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature7</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature9</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature17</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature12</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature18</th>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature10</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CV0  CV7  CV8  rank_sum\n",
       "feature16    5    2    1         8\n",
       "feature14    4    1    8        13\n",
       "feature13    1   12    2        15\n",
       "feature20    6    6    4        16\n",
       "feature19    2    4   12        18\n",
       "feature15    8   13    6        27\n",
       "feature8    18    5    5        28\n",
       "feature11    3    9   16        28\n",
       "feature2     9   19    3        31\n",
       "feature4    14   10    7        31\n",
       "feature6    10    7   15        32\n",
       "feature7    12   11   10        33\n",
       "feature1     7   15   14        36\n",
       "feature9    17    3   19        39\n",
       "feature17   11    8   20        39\n",
       "feature5    13   20   11        44\n",
       "feature3    15   16   13        44\n",
       "feature12   19   18    9        46\n",
       "feature18   16   14   18        48\n",
       "feature10   20   17   17        54"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list= list(df_acc.loc[:,(df_acc>=acc_th).sum(axis=0)==2].columns)\n",
    "col_list.append('rank_sum')\n",
    "df_importance_Diff_rank.loc[:,col_list].sort_values('rank_sum').astype('int')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
